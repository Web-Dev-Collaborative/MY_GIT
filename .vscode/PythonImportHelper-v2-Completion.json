[
    {
        "label": "Style",
        "importPath": "pygments.style",
        "description": "pygments.style",
        "isExtraImport": true,
        "detail": "pygments.style",
        "documentation": {}
    },
    {
        "label": "Keyword",
        "importPath": "pygments.token",
        "description": "pygments.token",
        "isExtraImport": true,
        "detail": "pygments.token",
        "documentation": {}
    },
    {
        "label": "Name",
        "importPath": "pygments.token",
        "description": "pygments.token",
        "isExtraImport": true,
        "detail": "pygments.token",
        "documentation": {}
    },
    {
        "label": "Comment",
        "importPath": "pygments.token",
        "description": "pygments.token",
        "isExtraImport": true,
        "detail": "pygments.token",
        "documentation": {}
    },
    {
        "label": "String",
        "importPath": "pygments.token",
        "description": "pygments.token",
        "isExtraImport": true,
        "detail": "pygments.token",
        "documentation": {}
    },
    {
        "label": "Error",
        "importPath": "pygments.token",
        "description": "pygments.token",
        "isExtraImport": true,
        "detail": "pygments.token",
        "documentation": {}
    },
    {
        "label": "Text",
        "importPath": "pygments.token",
        "description": "pygments.token",
        "isExtraImport": true,
        "detail": "pygments.token",
        "documentation": {}
    },
    {
        "label": "\\",
        "importPath": "pygments.token",
        "description": "pygments.token",
        "isExtraImport": true,
        "detail": "pygments.token",
        "documentation": {}
    },
    {
        "label": "highlight",
        "importPath": "pygments",
        "description": "pygments",
        "isExtraImport": true,
        "detail": "pygments",
        "documentation": {}
    },
    {
        "label": "highlight",
        "importPath": "pygments",
        "description": "pygments",
        "isExtraImport": true,
        "detail": "pygments",
        "documentation": {}
    },
    {
        "label": "highlight",
        "importPath": "pygments",
        "description": "pygments",
        "isExtraImport": true,
        "detail": "pygments",
        "documentation": {}
    },
    {
        "label": "guess_lexer",
        "importPath": "pygments.lexers",
        "description": "pygments.lexers",
        "isExtraImport": true,
        "detail": "pygments.lexers",
        "documentation": {}
    },
    {
        "label": "get_lexer_by_name",
        "importPath": "pygments.lexers",
        "description": "pygments.lexers",
        "isExtraImport": true,
        "detail": "pygments.lexers",
        "documentation": {}
    },
    {
        "label": "get_lexer_by_name",
        "importPath": "pygments.lexers",
        "description": "pygments.lexers",
        "isExtraImport": true,
        "detail": "pygments.lexers",
        "documentation": {}
    },
    {
        "label": "Terminal256Formatter",
        "importPath": "pygments.formatters",
        "description": "pygments.formatters",
        "isExtraImport": true,
        "detail": "pygments.formatters",
        "documentation": {}
    },
    {
        "label": "TerminalFormatter",
        "importPath": "pygments.formatters",
        "description": "pygments.formatters",
        "isExtraImport": true,
        "detail": "pygments.formatters",
        "documentation": {}
    },
    {
        "label": "HtmlFormatter",
        "importPath": "pygments.formatters",
        "description": "pygments.formatters",
        "isExtraImport": true,
        "detail": "pygments.formatters",
        "documentation": {}
    },
    {
        "label": "tabulate",
        "importPath": "tabulate",
        "description": "tabulate",
        "isExtraImport": true,
        "detail": "tabulate",
        "documentation": {}
    },
    {
        "label": "fg",
        "importPath": "colored",
        "description": "colored",
        "isExtraImport": true,
        "detail": "colored",
        "documentation": {}
    },
    {
        "label": "bg",
        "importPath": "colored",
        "description": "colored",
        "isExtraImport": true,
        "detail": "colored",
        "documentation": {}
    },
    {
        "label": "attr",
        "importPath": "colored",
        "description": "colored",
        "isExtraImport": true,
        "detail": "colored",
        "documentation": {}
    },
    {
        "label": "subprocess",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "subprocess",
        "description": "subprocess",
        "detail": "subprocess",
        "documentation": {}
    },
    {
        "label": "call",
        "importPath": "subprocess",
        "description": "subprocess",
        "isExtraImport": true,
        "detail": "subprocess",
        "documentation": {}
    },
    {
        "label": "check_call",
        "importPath": "subprocess",
        "description": "subprocess",
        "isExtraImport": true,
        "detail": "subprocess",
        "documentation": {}
    },
    {
        "label": "sys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys",
        "description": "sys",
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "argv",
        "importPath": "sys",
        "description": "sys",
        "isExtraImport": true,
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "print_function",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "division",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "print_function",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "print_function",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "print_function",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "print_function",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "print_function",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "absolute_import",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "division",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "print_function",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "loads",
        "importPath": "json",
        "description": "json",
        "isExtraImport": true,
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "tempfile",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "tempfile",
        "description": "tempfile",
        "detail": "tempfile",
        "documentation": {}
    },
    {
        "label": "unittest",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "unittest",
        "description": "unittest",
        "detail": "unittest",
        "documentation": {}
    },
    {
        "label": "tarfile",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "tarfile",
        "description": "tarfile",
        "detail": "tarfile",
        "documentation": {}
    },
    {
        "label": "math",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "math",
        "description": "math",
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "ceil",
        "importPath": "math",
        "description": "math",
        "isExtraImport": true,
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "sqrt",
        "importPath": "math",
        "description": "math",
        "isExtraImport": true,
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "ceil",
        "importPath": "math",
        "description": "math",
        "isExtraImport": true,
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "ceil",
        "importPath": "math",
        "description": "math",
        "isExtraImport": true,
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "sqrt",
        "importPath": "math",
        "description": "math",
        "isExtraImport": true,
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "sqrt",
        "importPath": "math",
        "description": "math",
        "isExtraImport": true,
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "itertools",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "itertools",
        "description": "itertools",
        "detail": "itertools",
        "documentation": {}
    },
    {
        "label": "combinations",
        "importPath": "itertools",
        "description": "itertools",
        "isExtraImport": true,
        "detail": "itertools",
        "documentation": {}
    },
    {
        "label": "chain",
        "importPath": "itertools",
        "description": "itertools",
        "isExtraImport": true,
        "detail": "itertools",
        "documentation": {}
    },
    {
        "label": "chain",
        "importPath": "itertools",
        "description": "itertools",
        "isExtraImport": true,
        "detail": "itertools",
        "documentation": {}
    },
    {
        "label": "chain",
        "importPath": "itertools",
        "description": "itertools",
        "isExtraImport": true,
        "detail": "itertools",
        "documentation": {}
    },
    {
        "label": "mul",
        "importPath": "operator",
        "description": "operator",
        "isExtraImport": true,
        "detail": "operator",
        "documentation": {}
    },
    {
        "label": "random",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "random",
        "description": "random",
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "randint",
        "importPath": "random",
        "description": "random",
        "isExtraImport": true,
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "randint",
        "importPath": "random",
        "description": "random",
        "isExtraImport": true,
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "uniform",
        "importPath": "random",
        "description": "random",
        "isExtraImport": true,
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "randint",
        "importPath": "random",
        "description": "random",
        "isExtraImport": true,
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "uniform",
        "importPath": "random",
        "description": "random",
        "isExtraImport": true,
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "randint",
        "importPath": "random",
        "description": "random",
        "isExtraImport": true,
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "uniform",
        "importPath": "random",
        "description": "random",
        "isExtraImport": true,
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "randint",
        "importPath": "random",
        "description": "random",
        "isExtraImport": true,
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "randint",
        "importPath": "random",
        "description": "random",
        "isExtraImport": true,
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "randint",
        "importPath": "random",
        "description": "random",
        "isExtraImport": true,
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "randint",
        "importPath": "random",
        "description": "random",
        "isExtraImport": true,
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "randint",
        "importPath": "random",
        "description": "random",
        "isExtraImport": true,
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "randint",
        "importPath": "random",
        "description": "random",
        "isExtraImport": true,
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "uniform",
        "importPath": "random",
        "description": "random",
        "isExtraImport": true,
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "shuffle",
        "importPath": "random",
        "description": "random",
        "isExtraImport": true,
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "sample",
        "importPath": "random",
        "description": "random",
        "isExtraImport": true,
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "randint",
        "importPath": "random",
        "description": "random",
        "isExtraImport": true,
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "randint",
        "importPath": "random",
        "description": "random",
        "isExtraImport": true,
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "randint",
        "importPath": "random",
        "description": "random",
        "isExtraImport": true,
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "randint",
        "importPath": "random",
        "description": "random",
        "isExtraImport": true,
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "randint",
        "importPath": "random",
        "description": "random",
        "isExtraImport": true,
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "randint",
        "importPath": "random",
        "description": "random",
        "isExtraImport": true,
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "uniform",
        "importPath": "random",
        "description": "random",
        "isExtraImport": true,
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "randint",
        "importPath": "random",
        "description": "random",
        "isExtraImport": true,
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "uniform",
        "importPath": "random",
        "description": "random",
        "isExtraImport": true,
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "randint",
        "importPath": "random",
        "description": "random",
        "isExtraImport": true,
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "randint",
        "importPath": "random",
        "description": "random",
        "isExtraImport": true,
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "choice",
        "importPath": "random",
        "description": "random",
        "isExtraImport": true,
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "randint",
        "importPath": "random",
        "description": "random",
        "isExtraImport": true,
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "uniform",
        "importPath": "random",
        "description": "random",
        "isExtraImport": true,
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "randint",
        "importPath": "random",
        "description": "random",
        "isExtraImport": true,
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "randint",
        "importPath": "random",
        "description": "random",
        "isExtraImport": true,
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "randint",
        "importPath": "random",
        "description": "random",
        "isExtraImport": true,
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "randint",
        "importPath": "random",
        "description": "random",
        "isExtraImport": true,
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "randint",
        "importPath": "random",
        "description": "random",
        "isExtraImport": true,
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "seed",
        "importPath": "random",
        "description": "random",
        "isExtraImport": true,
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "randint",
        "importPath": "random",
        "description": "random",
        "isExtraImport": true,
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "randint",
        "importPath": "random",
        "description": "random",
        "isExtraImport": true,
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "uniform",
        "importPath": "random",
        "description": "random",
        "isExtraImport": true,
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "randint",
        "importPath": "random",
        "description": "random",
        "isExtraImport": true,
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "sample",
        "importPath": "random",
        "description": "random",
        "isExtraImport": true,
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "psutil",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "psutil",
        "description": "psutil",
        "detail": "psutil",
        "documentation": {}
    },
    {
        "label": "pafy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pafy",
        "description": "pafy",
        "detail": "pafy",
        "documentation": {}
    },
    {
        "label": "ABCMeta",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "abstractmethod",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "abstractmethod",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "abstractmethod",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "abstractmethod",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "csv",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "csv",
        "description": "csv",
        "detail": "csv",
        "documentation": {}
    },
    {
        "label": "boto3",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "boto3",
        "description": "boto3",
        "detail": "boto3",
        "documentation": {}
    },
    {
        "label": "pandas",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pandas",
        "description": "pandas",
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "DeepMoji",
        "importPath": "deepmoji",
        "description": "deepmoji",
        "isExtraImport": true,
        "detail": "deepmoji",
        "documentation": {}
    },
    {
        "label": "string",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "string",
        "description": "string",
        "detail": "string",
        "documentation": {}
    },
    {
        "label": "Template",
        "importPath": "string",
        "description": "string",
        "isExtraImport": true,
        "detail": "string",
        "documentation": {}
    },
    {
        "label": "WordCloud",
        "importPath": "wordcloud",
        "description": "wordcloud",
        "isExtraImport": true,
        "detail": "wordcloud",
        "documentation": {}
    },
    {
        "label": "WordCloud",
        "importPath": "wordcloud",
        "description": "wordcloud",
        "isExtraImport": true,
        "detail": "wordcloud",
        "documentation": {}
    },
    {
        "label": "collections",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "collections",
        "description": "collections",
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "Counter",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "Counter",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "Counter",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "Counter",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "OrderedDict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "Counter",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "matplotlib.pyplot",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib.pyplot",
        "description": "matplotlib.pyplot",
        "detail": "matplotlib.pyplot",
        "documentation": {}
    },
    {
        "label": "base64",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "base64",
        "description": "base64",
        "detail": "base64",
        "documentation": {}
    },
    {
        "label": "b85decode",
        "importPath": "base64",
        "description": "base64",
        "isExtraImport": true,
        "detail": "base64",
        "documentation": {}
    },
    {
        "label": "shutil",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "shutil",
        "description": "shutil",
        "detail": "shutil",
        "documentation": {}
    },
    {
        "label": "copytree",
        "importPath": "shutil",
        "description": "shutil",
        "isExtraImport": true,
        "detail": "shutil",
        "documentation": {}
    },
    {
        "label": "move",
        "importPath": "shutil",
        "description": "shutil",
        "isExtraImport": true,
        "detail": "shutil",
        "documentation": {}
    },
    {
        "label": "pkgutil",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pkgutil",
        "description": "pkgutil",
        "detail": "pkgutil",
        "documentation": {}
    },
    {
        "label": "os.path",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os.path",
        "description": "os.path",
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "exists",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "pardir",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "requests",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "requests",
        "description": "requests",
        "detail": "requests",
        "documentation": {}
    },
    {
        "label": "HTTPError",
        "importPath": "requests",
        "description": "requests",
        "isExtraImport": true,
        "detail": "requests",
        "documentation": {}
    },
    {
        "label": "get",
        "importPath": "requests",
        "description": "requests",
        "isExtraImport": true,
        "detail": "requests",
        "documentation": {}
    },
    {
        "label": "BeautifulSoup",
        "importPath": "bs4",
        "description": "bs4",
        "isExtraImport": true,
        "detail": "bs4",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "chdir",
        "importPath": "os",
        "description": "os",
        "isExtraImport": true,
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "makedirs",
        "importPath": "os",
        "description": "os",
        "isExtraImport": true,
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "removedirs",
        "importPath": "os",
        "description": "os",
        "isExtraImport": true,
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "rename",
        "importPath": "os",
        "description": "os",
        "isExtraImport": true,
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "PathLike",
        "importPath": "os",
        "description": "os",
        "isExtraImport": true,
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "re",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "re",
        "description": "re",
        "detail": "re",
        "documentation": {}
    },
    {
        "label": "PDFParser",
        "importPath": "pdfminer.pdfparser",
        "description": "pdfminer.pdfparser",
        "isExtraImport": true,
        "detail": "pdfminer.pdfparser",
        "documentation": {}
    },
    {
        "label": "PDFDocument",
        "importPath": "pdfminer.pdfdocument",
        "description": "pdfminer.pdfdocument",
        "isExtraImport": true,
        "detail": "pdfminer.pdfdocument",
        "documentation": {}
    },
    {
        "label": "argparse",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "argparse",
        "description": "argparse",
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "ArgumentParser",
        "importPath": "argparse",
        "description": "argparse",
        "isExtraImport": true,
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "ArgumentTypeError",
        "importPath": "argparse",
        "description": "argparse",
        "isExtraImport": true,
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "app",
        "importPath": "absl",
        "description": "absl",
        "isExtraImport": true,
        "detail": "absl",
        "documentation": {}
    },
    {
        "label": "flags",
        "importPath": "absl",
        "description": "absl",
        "isExtraImport": true,
        "detail": "absl",
        "documentation": {}
    },
    {
        "label": "flags",
        "importPath": "absl",
        "description": "absl",
        "isExtraImport": true,
        "detail": "absl",
        "documentation": {}
    },
    {
        "label": "tensorflow_docs",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "tensorflow_docs",
        "description": "tensorflow_docs",
        "detail": "tensorflow_docs",
        "documentation": {}
    },
    {
        "label": "api_generator",
        "importPath": "tensorflow_docs",
        "description": "tensorflow_docs",
        "isExtraImport": true,
        "detail": "tensorflow_docs",
        "documentation": {}
    },
    {
        "label": "generate_lib",
        "importPath": "tensorflow_docs.api_generator",
        "description": "tensorflow_docs.api_generator",
        "isExtraImport": true,
        "detail": "tensorflow_docs.api_generator",
        "documentation": {}
    },
    {
        "label": "public_api",
        "importPath": "tensorflow_docs.api_generator",
        "description": "tensorflow_docs.api_generator",
        "isExtraImport": true,
        "detail": "tensorflow_docs.api_generator",
        "documentation": {}
    },
    {
        "label": "parser",
        "importPath": "tensorflow_docs.api_generator",
        "description": "tensorflow_docs.api_generator",
        "isExtraImport": true,
        "detail": "tensorflow_docs.api_generator",
        "documentation": {}
    },
    {
        "label": "parser",
        "importPath": "tensorflow_docs.api_generator",
        "description": "tensorflow_docs.api_generator",
        "isExtraImport": true,
        "detail": "tensorflow_docs.api_generator",
        "documentation": {}
    },
    {
        "label": "parser",
        "importPath": "tensorflow_docs.api_generator",
        "description": "tensorflow_docs.api_generator",
        "isExtraImport": true,
        "detail": "tensorflow_docs.api_generator",
        "documentation": {}
    },
    {
        "label": "pretty_docs",
        "importPath": "tensorflow_docs.api_generator",
        "description": "tensorflow_docs.api_generator",
        "isExtraImport": true,
        "detail": "tensorflow_docs.api_generator",
        "documentation": {}
    },
    {
        "label": "public_api",
        "importPath": "tensorflow_docs.api_generator",
        "description": "tensorflow_docs.api_generator",
        "isExtraImport": true,
        "detail": "tensorflow_docs.api_generator",
        "documentation": {}
    },
    {
        "label": "doc_controls",
        "importPath": "tensorflow_docs.api_generator",
        "description": "tensorflow_docs.api_generator",
        "isExtraImport": true,
        "detail": "tensorflow_docs.api_generator",
        "documentation": {}
    },
    {
        "label": "doc_generator_visitor",
        "importPath": "tensorflow_docs.api_generator",
        "description": "tensorflow_docs.api_generator",
        "isExtraImport": true,
        "detail": "tensorflow_docs.api_generator",
        "documentation": {}
    },
    {
        "label": "generate_lib",
        "importPath": "tensorflow_docs.api_generator",
        "description": "tensorflow_docs.api_generator",
        "isExtraImport": true,
        "detail": "tensorflow_docs.api_generator",
        "documentation": {}
    },
    {
        "label": "doc_controls",
        "importPath": "tensorflow_docs.api_generator",
        "description": "tensorflow_docs.api_generator",
        "isExtraImport": true,
        "detail": "tensorflow_docs.api_generator",
        "documentation": {}
    },
    {
        "label": "doc_generator_visitor",
        "importPath": "tensorflow_docs.api_generator",
        "description": "tensorflow_docs.api_generator",
        "isExtraImport": true,
        "detail": "tensorflow_docs.api_generator",
        "documentation": {}
    },
    {
        "label": "parser",
        "importPath": "tensorflow_docs.api_generator",
        "description": "tensorflow_docs.api_generator",
        "isExtraImport": true,
        "detail": "tensorflow_docs.api_generator",
        "documentation": {}
    },
    {
        "label": "pretty_docs",
        "importPath": "tensorflow_docs.api_generator",
        "description": "tensorflow_docs.api_generator",
        "isExtraImport": true,
        "detail": "tensorflow_docs.api_generator",
        "documentation": {}
    },
    {
        "label": "public_api",
        "importPath": "tensorflow_docs.api_generator",
        "description": "tensorflow_docs.api_generator",
        "isExtraImport": true,
        "detail": "tensorflow_docs.api_generator",
        "documentation": {}
    },
    {
        "label": "traverse",
        "importPath": "tensorflow_docs.api_generator",
        "description": "tensorflow_docs.api_generator",
        "isExtraImport": true,
        "detail": "tensorflow_docs.api_generator",
        "documentation": {}
    },
    {
        "label": "generate_lib",
        "importPath": "tensorflow_docs.api_generator",
        "description": "tensorflow_docs.api_generator",
        "isExtraImport": true,
        "detail": "tensorflow_docs.api_generator",
        "documentation": {}
    },
    {
        "label": "parser",
        "importPath": "tensorflow_docs.api_generator",
        "description": "tensorflow_docs.api_generator",
        "isExtraImport": true,
        "detail": "tensorflow_docs.api_generator",
        "documentation": {}
    },
    {
        "label": "doc_controls",
        "importPath": "tensorflow_docs.api_generator",
        "description": "tensorflow_docs.api_generator",
        "isExtraImport": true,
        "detail": "tensorflow_docs.api_generator",
        "documentation": {}
    },
    {
        "label": "doc_generator_visitor",
        "importPath": "tensorflow_docs.api_generator",
        "description": "tensorflow_docs.api_generator",
        "isExtraImport": true,
        "detail": "tensorflow_docs.api_generator",
        "documentation": {}
    },
    {
        "label": "public_api",
        "importPath": "tensorflow_docs.api_generator",
        "description": "tensorflow_docs.api_generator",
        "isExtraImport": true,
        "detail": "tensorflow_docs.api_generator",
        "documentation": {}
    },
    {
        "label": "doc_controls",
        "importPath": "tensorflow_docs.api_generator",
        "description": "tensorflow_docs.api_generator",
        "isExtraImport": true,
        "detail": "tensorflow_docs.api_generator",
        "documentation": {}
    },
    {
        "label": "parser",
        "importPath": "tensorflow_docs.api_generator",
        "description": "tensorflow_docs.api_generator",
        "isExtraImport": true,
        "detail": "tensorflow_docs.api_generator",
        "documentation": {}
    },
    {
        "label": "doc_controls",
        "importPath": "tensorflow_docs.api_generator",
        "description": "tensorflow_docs.api_generator",
        "isExtraImport": true,
        "detail": "tensorflow_docs.api_generator",
        "documentation": {}
    },
    {
        "label": "parser",
        "importPath": "tensorflow_docs.api_generator",
        "description": "tensorflow_docs.api_generator",
        "isExtraImport": true,
        "detail": "tensorflow_docs.api_generator",
        "documentation": {}
    },
    {
        "label": "parser",
        "importPath": "tensorflow_docs.api_generator",
        "description": "tensorflow_docs.api_generator",
        "isExtraImport": true,
        "detail": "tensorflow_docs.api_generator",
        "documentation": {}
    },
    {
        "label": "pretty_docs",
        "importPath": "tensorflow_docs.api_generator",
        "description": "tensorflow_docs.api_generator",
        "isExtraImport": true,
        "detail": "tensorflow_docs.api_generator",
        "documentation": {}
    },
    {
        "label": "doc_controls",
        "importPath": "tensorflow_docs.api_generator",
        "description": "tensorflow_docs.api_generator",
        "isExtraImport": true,
        "detail": "tensorflow_docs.api_generator",
        "documentation": {}
    },
    {
        "label": "doc_generator_visitor",
        "importPath": "tensorflow_docs.api_generator",
        "description": "tensorflow_docs.api_generator",
        "isExtraImport": true,
        "detail": "tensorflow_docs.api_generator",
        "documentation": {}
    },
    {
        "label": "public_api",
        "importPath": "tensorflow_docs.api_generator",
        "description": "tensorflow_docs.api_generator",
        "isExtraImport": true,
        "detail": "tensorflow_docs.api_generator",
        "documentation": {}
    },
    {
        "label": "test_module2",
        "importPath": "tensorflow_docs.api_generator",
        "description": "tensorflow_docs.api_generator",
        "isExtraImport": true,
        "detail": "tensorflow_docs.api_generator",
        "documentation": {}
    },
    {
        "label": "test_module1",
        "importPath": "tensorflow_docs.api_generator",
        "description": "tensorflow_docs.api_generator",
        "isExtraImport": true,
        "detail": "tensorflow_docs.api_generator",
        "documentation": {}
    },
    {
        "label": "test_module2",
        "importPath": "tensorflow_docs.api_generator",
        "description": "tensorflow_docs.api_generator",
        "isExtraImport": true,
        "detail": "tensorflow_docs.api_generator",
        "documentation": {}
    },
    {
        "label": "traverse",
        "importPath": "tensorflow_docs.api_generator",
        "description": "tensorflow_docs.api_generator",
        "isExtraImport": true,
        "detail": "tensorflow_docs.api_generator",
        "documentation": {}
    },
    {
        "label": "enum_type_wrapper",
        "importPath": "google.protobuf.internal",
        "description": "google.protobuf.internal",
        "isExtraImport": true,
        "detail": "google.protobuf.internal",
        "documentation": {}
    },
    {
        "label": "descriptor",
        "importPath": "google.protobuf",
        "description": "google.protobuf",
        "isExtraImport": true,
        "detail": "google.protobuf",
        "documentation": {}
    },
    {
        "label": "message",
        "importPath": "google.protobuf",
        "description": "google.protobuf",
        "isExtraImport": true,
        "detail": "google.protobuf",
        "documentation": {}
    },
    {
        "label": "reflection",
        "importPath": "google.protobuf",
        "description": "google.protobuf",
        "isExtraImport": true,
        "detail": "google.protobuf",
        "documentation": {}
    },
    {
        "label": "symbol_database",
        "importPath": "google.protobuf",
        "description": "google.protobuf",
        "isExtraImport": true,
        "detail": "google.protobuf",
        "documentation": {}
    },
    {
        "label": "timestamp_pb2",
        "importPath": "google.protobuf",
        "description": "google.protobuf",
        "isExtraImport": true,
        "detail": "google.protobuf",
        "documentation": {}
    },
    {
        "label": "timestamp_pb2",
        "importPath": "google.protobuf",
        "description": "google.protobuf",
        "isExtraImport": true,
        "detail": "google.protobuf",
        "documentation": {}
    },
    {
        "label": "ast",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "ast",
        "description": "ast",
        "detail": "ast",
        "documentation": {}
    },
    {
        "label": "inspect",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "inspect",
        "description": "inspect",
        "detail": "inspect",
        "documentation": {}
    },
    {
        "label": "textwrap",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "textwrap",
        "description": "textwrap",
        "detail": "textwrap",
        "documentation": {}
    },
    {
        "label": "typing",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "typing",
        "description": "typing",
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "TypeVar",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Sequence",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Type",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "NamedTuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "NamedTuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Sequence",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Pattern",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "NamedTuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Set",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Set",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterator",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Type",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "NamedTuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Type",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "DefaultDict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "TypeVar",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Type",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "NamedTuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Type",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "astor",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "astor",
        "description": "astor",
        "detail": "astor",
        "documentation": {}
    },
    {
        "label": "api_report_generated_pb2",
        "importPath": "tensorflow_docs.api_generator.report.schema",
        "description": "tensorflow_docs.api_generator.report.schema",
        "isExtraImport": true,
        "detail": "tensorflow_docs.api_generator.report.schema",
        "documentation": {}
    },
    {
        "label": "api_report_generated_pb2",
        "importPath": "tensorflow_docs.api_generator.report.schema",
        "description": "tensorflow_docs.api_generator.report.schema",
        "isExtraImport": true,
        "detail": "tensorflow_docs.api_generator.report.schema",
        "documentation": {}
    },
    {
        "label": "api_report_generated_pb2",
        "importPath": "tensorflow_docs.api_generator.report.schema",
        "description": "tensorflow_docs.api_generator.report.schema",
        "isExtraImport": true,
        "detail": "tensorflow_docs.api_generator.report.schema",
        "documentation": {}
    },
    {
        "label": "absltest",
        "importPath": "absl.testing",
        "description": "absl.testing",
        "isExtraImport": true,
        "detail": "absl.testing",
        "documentation": {}
    },
    {
        "label": "absltest",
        "importPath": "absl.testing",
        "description": "absl.testing",
        "isExtraImport": true,
        "detail": "absl.testing",
        "documentation": {}
    },
    {
        "label": "absltest",
        "importPath": "absl.testing",
        "description": "absl.testing",
        "isExtraImport": true,
        "detail": "absl.testing",
        "documentation": {}
    },
    {
        "label": "absltest",
        "importPath": "absl.testing",
        "description": "absl.testing",
        "isExtraImport": true,
        "detail": "absl.testing",
        "documentation": {}
    },
    {
        "label": "absltest",
        "importPath": "absl.testing",
        "description": "absl.testing",
        "isExtraImport": true,
        "detail": "absl.testing",
        "documentation": {}
    },
    {
        "label": "parameterized",
        "importPath": "absl.testing",
        "description": "absl.testing",
        "isExtraImport": true,
        "detail": "absl.testing",
        "documentation": {}
    },
    {
        "label": "absltest",
        "importPath": "absl.testing",
        "description": "absl.testing",
        "isExtraImport": true,
        "detail": "absl.testing",
        "documentation": {}
    },
    {
        "label": "absltest",
        "importPath": "absl.testing",
        "description": "absl.testing",
        "isExtraImport": true,
        "detail": "absl.testing",
        "documentation": {}
    },
    {
        "label": "absltest",
        "importPath": "absl.testing",
        "description": "absl.testing",
        "isExtraImport": true,
        "detail": "absl.testing",
        "documentation": {}
    },
    {
        "label": "absltest",
        "importPath": "absl.testing",
        "description": "absl.testing",
        "isExtraImport": true,
        "detail": "absl.testing",
        "documentation": {}
    },
    {
        "label": "utils",
        "importPath": "tensorflow_docs.api_generator.report",
        "description": "tensorflow_docs.api_generator.report",
        "isExtraImport": true,
        "detail": "tensorflow_docs.api_generator.report",
        "documentation": {}
    },
    {
        "label": "linter",
        "importPath": "tensorflow_docs.api_generator.report",
        "description": "tensorflow_docs.api_generator.report",
        "isExtraImport": true,
        "detail": "tensorflow_docs.api_generator.report",
        "documentation": {}
    },
    {
        "label": "utils",
        "importPath": "tensorflow_docs.api_generator.report",
        "description": "tensorflow_docs.api_generator.report",
        "isExtraImport": true,
        "detail": "tensorflow_docs.api_generator.report",
        "documentation": {}
    },
    {
        "label": "types",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "types",
        "description": "types",
        "detail": "types",
        "documentation": {}
    },
    {
        "label": "fnmatch",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "fnmatch",
        "description": "fnmatch",
        "detail": "fnmatch",
        "documentation": {}
    },
    {
        "label": "pathlib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pathlib",
        "description": "pathlib",
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "yaml",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "yaml",
        "description": "yaml",
        "detail": "yaml",
        "documentation": {}
    },
    {
        "label": "enum",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "enum",
        "description": "enum",
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "Enum",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "Enum",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "auto",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "functools",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "functools",
        "description": "functools",
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "html",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "html",
        "description": "html",
        "detail": "html",
        "documentation": {}
    },
    {
        "label": "dataclasses",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "dataclasses",
        "description": "dataclasses",
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "Message",
        "importPath": "google.protobuf.message",
        "description": "google.protobuf.message",
        "isExtraImport": true,
        "detail": "google.protobuf.message",
        "documentation": {}
    },
    {
        "label": "Message",
        "importPath": "google.protobuf.message",
        "description": "google.protobuf.message",
        "isExtraImport": true,
        "detail": "google.protobuf.message",
        "documentation": {}
    },
    {
        "label": "attr",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "attr",
        "description": "attr",
        "detail": "attr",
        "documentation": {}
    },
    {
        "label": "importlib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "importlib",
        "description": "importlib",
        "detail": "importlib",
        "documentation": {}
    },
    {
        "label": "logging",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "logging",
        "description": "logging",
        "detail": "logging",
        "documentation": {}
    },
    {
        "label": "hashlib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "hashlib",
        "description": "hashlib",
        "detail": "hashlib",
        "documentation": {}
    },
    {
        "label": "fail",
        "importPath": "tensorflow_docs.tools.nblint.decorator",
        "description": "tensorflow_docs.tools.nblint.decorator",
        "isExtraImport": true,
        "detail": "tensorflow_docs.tools.nblint.decorator",
        "documentation": {}
    },
    {
        "label": "lint",
        "importPath": "tensorflow_docs.tools.nblint.decorator",
        "description": "tensorflow_docs.tools.nblint.decorator",
        "isExtraImport": true,
        "detail": "tensorflow_docs.tools.nblint.decorator",
        "documentation": {}
    },
    {
        "label": "Options",
        "importPath": "tensorflow_docs.tools.nblint.decorator",
        "description": "tensorflow_docs.tools.nblint.decorator",
        "isExtraImport": true,
        "detail": "tensorflow_docs.tools.nblint.decorator",
        "documentation": {}
    },
    {
        "label": "fail",
        "importPath": "tensorflow_docs.tools.nblint.decorator",
        "description": "tensorflow_docs.tools.nblint.decorator",
        "isExtraImport": true,
        "detail": "tensorflow_docs.tools.nblint.decorator",
        "documentation": {}
    },
    {
        "label": "lint",
        "importPath": "tensorflow_docs.tools.nblint.decorator",
        "description": "tensorflow_docs.tools.nblint.decorator",
        "isExtraImport": true,
        "detail": "tensorflow_docs.tools.nblint.decorator",
        "documentation": {}
    },
    {
        "label": "Options",
        "importPath": "tensorflow_docs.tools.nblint.decorator",
        "description": "tensorflow_docs.tools.nblint.decorator",
        "isExtraImport": true,
        "detail": "tensorflow_docs.tools.nblint.decorator",
        "documentation": {}
    },
    {
        "label": "fail",
        "importPath": "tensorflow_docs.tools.nblint.decorator",
        "description": "tensorflow_docs.tools.nblint.decorator",
        "isExtraImport": true,
        "detail": "tensorflow_docs.tools.nblint.decorator",
        "documentation": {}
    },
    {
        "label": "lint",
        "importPath": "tensorflow_docs.tools.nblint.decorator",
        "description": "tensorflow_docs.tools.nblint.decorator",
        "isExtraImport": true,
        "detail": "tensorflow_docs.tools.nblint.decorator",
        "documentation": {}
    },
    {
        "label": "Options",
        "importPath": "tensorflow_docs.tools.nblint.decorator",
        "description": "tensorflow_docs.tools.nblint.decorator",
        "isExtraImport": true,
        "detail": "tensorflow_docs.tools.nblint.decorator",
        "documentation": {}
    },
    {
        "label": "urllib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "urllib",
        "description": "urllib",
        "detail": "urllib",
        "documentation": {}
    },
    {
        "label": "fix",
        "importPath": "tensorflow_docs.tools.nblint",
        "description": "tensorflow_docs.tools.nblint",
        "isExtraImport": true,
        "detail": "tensorflow_docs.tools.nblint",
        "documentation": {}
    },
    {
        "label": "fix",
        "importPath": "tensorflow_docs.tools.nblint",
        "description": "tensorflow_docs.tools.nblint",
        "isExtraImport": true,
        "detail": "tensorflow_docs.tools.nblint",
        "documentation": {}
    },
    {
        "label": "decorator",
        "importPath": "tensorflow_docs.tools.nblint",
        "description": "tensorflow_docs.tools.nblint",
        "isExtraImport": true,
        "detail": "tensorflow_docs.tools.nblint",
        "documentation": {}
    },
    {
        "label": "is_button_cell_re",
        "importPath": "tensorflow_docs.tools.nblint.style.tensorflow",
        "description": "tensorflow_docs.tools.nblint.style.tensorflow",
        "isExtraImport": true,
        "detail": "tensorflow_docs.tools.nblint.style.tensorflow",
        "documentation": {}
    },
    {
        "label": "split_doc_path",
        "importPath": "tensorflow_docs.tools.nblint.style.tensorflow",
        "description": "tensorflow_docs.tools.nblint.style.tensorflow",
        "isExtraImport": true,
        "detail": "tensorflow_docs.tools.nblint.style.tensorflow",
        "documentation": {}
    },
    {
        "label": "io",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "io",
        "description": "io",
        "detail": "io",
        "documentation": {}
    },
    {
        "label": "traceback",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "traceback",
        "description": "traceback",
        "detail": "traceback",
        "documentation": {}
    },
    {
        "label": "notebook_utils",
        "importPath": "tensorflow_docs.tools.nbfmt",
        "description": "tensorflow_docs.tools.nbfmt",
        "isExtraImport": true,
        "detail": "tensorflow_docs.tools.nbfmt",
        "documentation": {}
    },
    {
        "label": "mimetypes",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "mimetypes",
        "description": "mimetypes",
        "detail": "mimetypes",
        "documentation": {}
    },
    {
        "label": "IPython.display",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "IPython.display",
        "description": "IPython.display",
        "detail": "IPython.display",
        "documentation": {}
    },
    {
        "label": "tensorflow_docs.vis.webp_animation",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "tensorflow_docs.vis.webp_animation",
        "description": "tensorflow_docs.vis.webp_animation",
        "detail": "tensorflow_docs.vis.webp_animation",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "PIL.Image",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "PIL.Image",
        "description": "PIL.Image",
        "detail": "PIL.Image",
        "documentation": {}
    },
    {
        "label": "embed",
        "importPath": "tensorflow_docs.vis",
        "description": "tensorflow_docs.vis",
        "isExtraImport": true,
        "detail": "tensorflow_docs.vis",
        "documentation": {}
    },
    {
        "label": "webp_animation",
        "importPath": "tensorflow_docs.vis",
        "description": "tensorflow_docs.vis",
        "isExtraImport": true,
        "detail": "tensorflow_docs.vis",
        "documentation": {}
    },
    {
        "label": "webp",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "webp",
        "description": "webp",
        "detail": "webp",
        "documentation": {}
    },
    {
        "label": "find_packages",
        "importPath": "setuptools",
        "description": "setuptools",
        "isExtraImport": true,
        "detail": "setuptools",
        "documentation": {}
    },
    {
        "label": "setup",
        "importPath": "setuptools",
        "description": "setuptools",
        "isExtraImport": true,
        "detail": "setuptools",
        "documentation": {}
    },
    {
        "label": "pyld",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pyld",
        "description": "pyld",
        "detail": "pyld",
        "documentation": {}
    },
    {
        "label": "rdflib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "rdflib",
        "description": "rdflib",
        "detail": "rdflib",
        "documentation": {}
    },
    {
        "label": "Graph",
        "importPath": "rdflib",
        "description": "rdflib",
        "isExtraImport": true,
        "detail": "rdflib",
        "documentation": {}
    },
    {
        "label": "URIRef",
        "importPath": "rdflib",
        "description": "rdflib",
        "isExtraImport": true,
        "detail": "rdflib",
        "documentation": {}
    },
    {
        "label": "BNode",
        "importPath": "rdflib",
        "description": "rdflib",
        "isExtraImport": true,
        "detail": "rdflib",
        "documentation": {}
    },
    {
        "label": "Literal",
        "importPath": "rdflib",
        "description": "rdflib",
        "isExtraImport": true,
        "detail": "rdflib",
        "documentation": {}
    },
    {
        "label": "Namespace",
        "importPath": "rdflib",
        "description": "rdflib",
        "isExtraImport": true,
        "detail": "rdflib",
        "documentation": {}
    },
    {
        "label": "plugin",
        "importPath": "rdflib",
        "description": "rdflib",
        "isExtraImport": true,
        "detail": "rdflib",
        "documentation": {}
    },
    {
        "label": "essentia",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "essentia",
        "description": "essentia",
        "detail": "essentia",
        "documentation": {}
    },
    {
        "label": "uuid",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "uuid",
        "description": "uuid",
        "detail": "uuid",
        "documentation": {}
    },
    {
        "label": "ffmpeg",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "ffmpeg",
        "description": "ffmpeg",
        "detail": "ffmpeg",
        "documentation": {}
    },
    {
        "label": "warnings",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "warnings",
        "description": "warnings",
        "detail": "warnings",
        "documentation": {}
    },
    {
        "label": "MusicExtractor",
        "importPath": "essentia.standard",
        "description": "essentia.standard",
        "isExtraImport": true,
        "detail": "essentia.standard",
        "documentation": {}
    },
    {
        "label": "FreesoundExtractor",
        "importPath": "essentia.standard",
        "description": "essentia.standard",
        "isExtraImport": true,
        "detail": "essentia.standard",
        "documentation": {}
    },
    {
        "label": "MonoLoader",
        "importPath": "essentia.standard",
        "description": "essentia.standard",
        "isExtraImport": true,
        "detail": "essentia.standard",
        "documentation": {}
    },
    {
        "label": "MonoWriter",
        "importPath": "essentia.standard",
        "description": "essentia.standard",
        "isExtraImport": true,
        "detail": "essentia.standard",
        "documentation": {}
    },
    {
        "label": "Serializer",
        "importPath": "rdflib.serializer",
        "description": "rdflib.serializer",
        "isExtraImport": true,
        "detail": "rdflib.serializer",
        "documentation": {}
    },
    {
        "label": "RDF",
        "importPath": "rdflib.namespace",
        "description": "rdflib.namespace",
        "isExtraImport": true,
        "detail": "rdflib.namespace",
        "documentation": {}
    },
    {
        "label": "timbral_models",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "timbral_models",
        "description": "timbral_models",
        "detail": "timbral_models",
        "documentation": {}
    },
    {
        "label": "newSolver",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "ObjVal",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "SolVal",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "SolVal",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "ObjVal",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "newSolver",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "ObjVal",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "SolVal",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "newSolver",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "ObjVal",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "SolVal",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "newSolver",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "ObjVal",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "SolVal",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "newSolver",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "SolVal",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "ObjVal",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "newSolver",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "ObjVal",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "SolVal",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "newSolver",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "SolVal",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "ObjVal",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "newSolver",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "SolVal",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "ObjVal",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "newSolver",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "ObjVal",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "SolVal",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "newSolver",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "SolVal",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "ObjVal",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "newSolver",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "ObjVal",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "SolVal",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "newSolver",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "ObjVal",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "SolVal",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "newSolver",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "ObjVal",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "SolVal",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "newSolver",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "ObjVal",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "SolVal",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "ObjVal",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "SolVal",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "newSolver",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "ObjVal",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "SolVal",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "newSolver",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "ObjVal",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "SolVal",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "newSolver",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "SolVal",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "newSolver",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "ObjVal",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "SolVal",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "newSolver",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "ObjVal",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "SolVal",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "newSolver",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "SolVal",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "k_out_of_n",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "reify",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "reify_force",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "reify_raise",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "ObjVal",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "SolVal",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "newSolver",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "ObjVal",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "SolVal",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "newSolver",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "SolVal",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "ObjVal",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "ObjVal",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "SolVal",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "newSolver",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "pairs",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "ObjVal",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "SolVal",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "newSolver",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "SolVal",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "ObjVal",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "newSolver",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "k_out_of_n",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "reify",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "newSolver",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "SolVal",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "newSolver",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "ObjVal",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "SolVal",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "SolVal",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "SolVal",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "ObjVal",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "SolVal",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "ObjVal",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "SolVal",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "ObjVal",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "SolVal",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "ObjVal",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "SolVal",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "ObjVal",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "newSolver",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "ObjVal",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "SolVal",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "newSolver",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "ObjVal",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "SolVal",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "newSolver",
        "importPath": "my_or_tools",
        "description": "my_or_tools",
        "isExtraImport": true,
        "detail": "my_or_tools",
        "documentation": {}
    },
    {
        "label": "pywraplp",
        "importPath": "ortools.linear_solver",
        "description": "ortools.linear_solver",
        "isExtraImport": true,
        "detail": "ortools.linear_solver",
        "documentation": {}
    },
    {
        "label": "pywraplp",
        "importPath": "ortools.linear_solver",
        "description": "ortools.linear_solver",
        "isExtraImport": true,
        "detail": "ortools.linear_solver",
        "documentation": {}
    },
    {
        "label": "pywraplp",
        "importPath": "ortools.linear_solver",
        "description": "ortools.linear_solver",
        "isExtraImport": true,
        "detail": "ortools.linear_solver",
        "documentation": {}
    },
    {
        "label": "pywraplp",
        "importPath": "ortools.linear_solver",
        "description": "ortools.linear_solver",
        "isExtraImport": true,
        "detail": "ortools.linear_solver",
        "documentation": {}
    },
    {
        "label": "pywraplp",
        "importPath": "ortools.linear_solver",
        "description": "ortools.linear_solver",
        "isExtraImport": true,
        "detail": "ortools.linear_solver",
        "documentation": {}
    },
    {
        "label": "pywraplp",
        "importPath": "ortools.linear_solver",
        "description": "ortools.linear_solver",
        "isExtraImport": true,
        "detail": "ortools.linear_solver",
        "documentation": {}
    },
    {
        "label": "pywraplp",
        "importPath": "ortools.linear_solver",
        "description": "ortools.linear_solver",
        "isExtraImport": true,
        "detail": "ortools.linear_solver",
        "documentation": {}
    },
    {
        "label": "pywraplp",
        "importPath": "ortools.linear_solver",
        "description": "ortools.linear_solver",
        "isExtraImport": true,
        "detail": "ortools.linear_solver",
        "documentation": {}
    },
    {
        "label": "pywraplp",
        "importPath": "ortools.linear_solver",
        "description": "ortools.linear_solver",
        "isExtraImport": true,
        "detail": "ortools.linear_solver",
        "documentation": {}
    },
    {
        "label": "pywraplp",
        "importPath": "ortools.linear_solver",
        "description": "ortools.linear_solver",
        "isExtraImport": true,
        "detail": "ortools.linear_solver",
        "documentation": {}
    },
    {
        "label": "pywraplp",
        "importPath": "ortools.linear_solver",
        "description": "ortools.linear_solver",
        "isExtraImport": true,
        "detail": "ortools.linear_solver",
        "documentation": {}
    },
    {
        "label": "pywraplp",
        "importPath": "ortools.linear_solver",
        "description": "ortools.linear_solver",
        "isExtraImport": true,
        "detail": "ortools.linear_solver",
        "documentation": {}
    },
    {
        "label": "transship_dist",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "transship_dist",
        "description": "transship_dist",
        "detail": "transship_dist",
        "documentation": {}
    },
    {
        "label": "sosn",
        "importPath": "my_or_tools_c",
        "description": "my_or_tools_c",
        "isExtraImport": true,
        "detail": "my_or_tools_c",
        "documentation": {}
    },
    {
        "label": "k_out_of_n",
        "importPath": "my_or_tools_c",
        "description": "my_or_tools_c",
        "isExtraImport": true,
        "detail": "my_or_tools_c",
        "documentation": {}
    },
    {
        "label": "sosn",
        "importPath": "my_or_tools_c",
        "description": "my_or_tools_c",
        "isExtraImport": true,
        "detail": "my_or_tools_c",
        "documentation": {}
    },
    {
        "label": "bounds_on_box",
        "importPath": "my_or_tools_c",
        "description": "my_or_tools_c",
        "isExtraImport": true,
        "detail": "my_or_tools_c",
        "documentation": {}
    },
    {
        "label": "bounds_on_box",
        "importPath": "my_or_tools_c",
        "description": "my_or_tools_c",
        "isExtraImport": true,
        "detail": "my_or_tools_c",
        "documentation": {}
    },
    {
        "label": "bounds_on_box",
        "importPath": "my_or_tools_c",
        "description": "my_or_tools_c",
        "isExtraImport": true,
        "detail": "my_or_tools_c",
        "documentation": {}
    },
    {
        "label": "reify_force",
        "importPath": "my_or_tools_c",
        "description": "my_or_tools_c",
        "isExtraImport": true,
        "detail": "my_or_tools_c",
        "documentation": {}
    },
    {
        "label": "reify_raise",
        "importPath": "my_or_tools_c",
        "description": "my_or_tools_c",
        "isExtraImport": true,
        "detail": "my_or_tools_c",
        "documentation": {}
    },
    {
        "label": "reify",
        "importPath": "my_or_tools_c",
        "description": "my_or_tools_c",
        "isExtraImport": true,
        "detail": "my_or_tools_c",
        "documentation": {}
    },
    {
        "label": "sosn",
        "importPath": "my_or_tools_c",
        "description": "my_or_tools_c",
        "isExtraImport": true,
        "detail": "my_or_tools_c",
        "documentation": {}
    },
    {
        "label": "maximax",
        "importPath": "my_or_tools_c",
        "description": "my_or_tools_c",
        "isExtraImport": true,
        "detail": "my_or_tools_c",
        "documentation": {}
    },
    {
        "label": "bounds_on_box",
        "importPath": "my_or_tools_c",
        "description": "my_or_tools_c",
        "isExtraImport": true,
        "detail": "my_or_tools_c",
        "documentation": {}
    },
    {
        "label": "reify_force",
        "importPath": "my_or_tools_c",
        "description": "my_or_tools_c",
        "isExtraImport": true,
        "detail": "my_or_tools_c",
        "documentation": {}
    },
    {
        "label": "solve_maxrook",
        "importPath": "puzzle",
        "description": "puzzle",
        "isExtraImport": true,
        "detail": "puzzle",
        "documentation": {}
    },
    {
        "label": "solve_maxrook",
        "importPath": "puzzle",
        "description": "puzzle",
        "isExtraImport": true,
        "detail": "puzzle",
        "documentation": {}
    },
    {
        "label": "solve_maxpiece",
        "importPath": "puzzle",
        "description": "puzzle",
        "isExtraImport": true,
        "detail": "puzzle",
        "documentation": {}
    },
    {
        "label": "solve_sudoku",
        "importPath": "puzzle",
        "description": "puzzle",
        "isExtraImport": true,
        "detail": "puzzle",
        "documentation": {}
    },
    {
        "label": "solve_smm",
        "importPath": "puzzle",
        "description": "puzzle",
        "isExtraImport": true,
        "detail": "puzzle",
        "documentation": {}
    },
    {
        "label": "solve_lady_or_tiger",
        "importPath": "puzzle",
        "description": "puzzle",
        "isExtraImport": true,
        "detail": "puzzle",
        "documentation": {}
    },
    {
        "label": "time",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "time",
        "description": "time",
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "time",
        "importPath": "time",
        "description": "time",
        "isExtraImport": true,
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "time",
        "importPath": "time",
        "description": "time",
        "isExtraImport": true,
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "time",
        "importPath": "time",
        "description": "time",
        "isExtraImport": true,
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "sleep",
        "importPath": "time",
        "description": "time",
        "isExtraImport": true,
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "copy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "copy",
        "description": "copy",
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "time,",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "time.",
        "description": "time.",
        "detail": "time.",
        "documentation": {}
    },
    {
        "label": "gen_data",
        "importPath": "bin_packing",
        "description": "bin_packing",
        "isExtraImport": true,
        "detail": "bin_packing",
        "documentation": {}
    },
    {
        "label": "solve_model",
        "importPath": "bin_packing",
        "description": "bin_packing",
        "isExtraImport": true,
        "detail": "bin_packing",
        "documentation": {}
    },
    {
        "label": "gen_data_content",
        "importPath": "blend_multi",
        "description": "blend_multi",
        "isExtraImport": true,
        "detail": "blend_multi",
        "documentation": {}
    },
    {
        "label": "gen_data_target",
        "importPath": "blend_multi",
        "description": "blend_multi",
        "isExtraImport": true,
        "detail": "blend_multi",
        "documentation": {}
    },
    {
        "label": "gen_data_cost",
        "importPath": "blend_multi",
        "description": "blend_multi",
        "isExtraImport": true,
        "detail": "blend_multi",
        "documentation": {}
    },
    {
        "label": "gen_data_inventory",
        "importPath": "blend_multi",
        "description": "blend_multi",
        "isExtraImport": true,
        "detail": "blend_multi",
        "documentation": {}
    },
    {
        "label": "solve_model",
        "importPath": "blend_multi",
        "description": "blend_multi",
        "isExtraImport": true,
        "detail": "blend_multi",
        "documentation": {}
    },
    {
        "label": "gen_features",
        "importPath": "features",
        "description": "features",
        "isExtraImport": true,
        "detail": "features",
        "documentation": {}
    },
    {
        "label": "solve_classification",
        "importPath": "features",
        "description": "features",
        "isExtraImport": true,
        "detail": "features",
        "documentation": {}
    },
    {
        "label": "solve_margins_classification",
        "importPath": "margins",
        "description": "margins",
        "isExtraImport": true,
        "detail": "margins",
        "documentation": {}
    },
    {
        "label": "tableutils",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "tableutils",
        "description": "tableutils",
        "detail": "tableutils",
        "documentation": {}
    },
    {
        "label": "printmat",
        "importPath": "tableutils",
        "description": "tableutils",
        "isExtraImport": true,
        "detail": "tableutils",
        "documentation": {}
    },
    {
        "label": "wrapmat",
        "importPath": "tableutils",
        "description": "tableutils",
        "isExtraImport": true,
        "detail": "tableutils",
        "documentation": {}
    },
    {
        "label": "formatmat",
        "importPath": "tableutils",
        "description": "tableutils",
        "isExtraImport": true,
        "detail": "tableutils",
        "documentation": {}
    },
    {
        "label": "solve_coexistence",
        "importPath": "coexistence",
        "description": "coexistence",
        "isExtraImport": true,
        "detail": "coexistence",
        "documentation": {}
    },
    {
        "label": "gen_data",
        "importPath": "curve_fit",
        "description": "curve_fit",
        "isExtraImport": true,
        "detail": "curve_fit",
        "documentation": {}
    },
    {
        "label": "solve_model",
        "importPath": "curve_fit",
        "description": "curve_fit",
        "isExtraImport": true,
        "detail": "curve_fit",
        "documentation": {}
    },
    {
        "label": "gen_data",
        "importPath": "cutting_stock",
        "description": "cutting_stock",
        "isExtraImport": true,
        "detail": "cutting_stock",
        "documentation": {}
    },
    {
        "label": "solve_model",
        "importPath": "cutting_stock",
        "description": "cutting_stock",
        "isExtraImport": true,
        "detail": "cutting_stock",
        "documentation": {}
    },
    {
        "label": "solve_large_model",
        "importPath": "cutting_stock",
        "description": "cutting_stock",
        "isExtraImport": true,
        "detail": "cutting_stock",
        "documentation": {}
    },
    {
        "label": "gen_diet_problem",
        "importPath": "diet_problem",
        "description": "diet_problem",
        "isExtraImport": true,
        "detail": "diet_problem",
        "documentation": {}
    },
    {
        "label": "solve_diet",
        "importPath": "diet_problem",
        "description": "diet_problem",
        "isExtraImport": true,
        "detail": "diet_problem",
        "documentation": {}
    },
    {
        "label": "gen_dcost",
        "importPath": "facility_location",
        "description": "facility_location",
        "isExtraImport": true,
        "detail": "facility_location",
        "documentation": {}
    },
    {
        "label": "gen_fcost",
        "importPath": "facility_location",
        "description": "facility_location",
        "isExtraImport": true,
        "detail": "facility_location",
        "documentation": {}
    },
    {
        "label": "solve_model",
        "importPath": "facility_location",
        "description": "facility_location",
        "isExtraImport": true,
        "detail": "facility_location",
        "documentation": {}
    },
    {
        "label": "gen_raw",
        "importPath": "gas_blend",
        "description": "gas_blend",
        "isExtraImport": true,
        "detail": "gas_blend",
        "documentation": {}
    },
    {
        "label": "gen_refined",
        "importPath": "gas_blend",
        "description": "gas_blend",
        "isExtraImport": true,
        "detail": "gas_blend",
        "documentation": {}
    },
    {
        "label": "solve_gas",
        "importPath": "gas_blend",
        "description": "gas_blend",
        "isExtraImport": true,
        "detail": "gas_blend",
        "documentation": {}
    },
    {
        "label": "gen_data",
        "importPath": "job_shop",
        "description": "job_shop",
        "isExtraImport": true,
        "detail": "job_shop",
        "documentation": {}
    },
    {
        "label": "solve_model",
        "importPath": "job_shop",
        "description": "job_shop",
        "isExtraImport": true,
        "detail": "job_shop",
        "documentation": {}
    },
    {
        "label": "gen_data",
        "importPath": "maxflow",
        "description": "maxflow",
        "isExtraImport": true,
        "detail": "maxflow",
        "documentation": {}
    },
    {
        "label": "solve_model",
        "importPath": "maxflow",
        "description": "maxflow",
        "isExtraImport": true,
        "detail": "maxflow",
        "documentation": {}
    },
    {
        "label": "gen_data",
        "importPath": "mincost",
        "description": "mincost",
        "isExtraImport": true,
        "detail": "mincost",
        "documentation": {}
    },
    {
        "label": "solve_model",
        "importPath": "mincost",
        "description": "mincost",
        "isExtraImport": true,
        "detail": "mincost",
        "documentation": {}
    },
    {
        "label": "gen_data",
        "importPath": "multi_commodity_flow",
        "description": "multi_commodity_flow",
        "isExtraImport": true,
        "detail": "multi_commodity_flow",
        "documentation": {}
    },
    {
        "label": "solve_model",
        "importPath": "multi_commodity_flow",
        "description": "multi_commodity_flow",
        "isExtraImport": true,
        "detail": "multi_commodity_flow",
        "documentation": {}
    },
    {
        "label": "solve_all_pairs",
        "importPath": "multi_commodity_flow",
        "description": "multi_commodity_flow",
        "isExtraImport": true,
        "detail": "multi_commodity_flow",
        "documentation": {}
    },
    {
        "label": "shortest_path",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "shortest_path",
        "description": "shortest_path",
        "detail": "shortest_path",
        "documentation": {}
    },
    {
        "label": "gen_data",
        "importPath": "shortest_path",
        "description": "shortest_path",
        "isExtraImport": true,
        "detail": "shortest_path",
        "documentation": {}
    },
    {
        "label": "solve_model",
        "importPath": "shortest_path",
        "description": "shortest_path",
        "isExtraImport": true,
        "detail": "shortest_path",
        "documentation": {}
    },
    {
        "label": "solve_all_pairs",
        "importPath": "shortest_path",
        "description": "shortest_path",
        "isExtraImport": true,
        "detail": "shortest_path",
        "documentation": {}
    },
    {
        "label": "solve_tree_model",
        "importPath": "shortest_path",
        "description": "shortest_path",
        "isExtraImport": true,
        "detail": "shortest_path",
        "documentation": {}
    },
    {
        "label": "critical_tasks",
        "importPath": "shortest_path",
        "description": "shortest_path",
        "isExtraImport": true,
        "detail": "shortest_path",
        "documentation": {}
    },
    {
        "label": "gen_data",
        "importPath": "piecewise",
        "description": "piecewise",
        "isExtraImport": true,
        "detail": "piecewise",
        "documentation": {}
    },
    {
        "label": "minimize_piecewise_linear_convex",
        "importPath": "piecewise",
        "description": "piecewise",
        "isExtraImport": true,
        "detail": "piecewise",
        "documentation": {}
    },
    {
        "label": "minimize_non_linear",
        "importPath": "piecewise",
        "description": "piecewise",
        "isExtraImport": true,
        "detail": "piecewise",
        "documentation": {}
    },
    {
        "label": "verbose_minimize_non_linear",
        "importPath": "piecewise",
        "description": "piecewise",
        "isExtraImport": true,
        "detail": "piecewise",
        "documentation": {}
    },
    {
        "label": "minimize_piecewise_linear",
        "importPath": "piecewise_ncvx",
        "description": "piecewise_ncvx",
        "isExtraImport": true,
        "detail": "piecewise_ncvx",
        "documentation": {}
    },
    {
        "label": "gen_data",
        "importPath": "project_management",
        "description": "project_management",
        "isExtraImport": true,
        "detail": "project_management",
        "documentation": {}
    },
    {
        "label": "solve_model",
        "importPath": "project_management",
        "description": "project_management",
        "isExtraImport": true,
        "detail": "project_management",
        "documentation": {}
    },
    {
        "label": "solve_model_clp",
        "importPath": "project_management",
        "description": "project_management",
        "isExtraImport": true,
        "detail": "project_management",
        "documentation": {}
    },
    {
        "label": "gen_data",
        "importPath": "set_cover",
        "description": "set_cover",
        "isExtraImport": true,
        "detail": "set_cover",
        "documentation": {}
    },
    {
        "label": "solve_model",
        "importPath": "set_cover",
        "description": "set_cover",
        "isExtraImport": true,
        "detail": "set_cover",
        "documentation": {}
    },
    {
        "label": "gen_data",
        "importPath": "set_packing",
        "description": "set_packing",
        "isExtraImport": true,
        "detail": "set_packing",
        "documentation": {}
    },
    {
        "label": "solve_model",
        "importPath": "set_packing",
        "description": "set_packing",
        "isExtraImport": true,
        "detail": "set_packing",
        "documentation": {}
    },
    {
        "label": "gen_data",
        "importPath": "sports_timetabling",
        "description": "sports_timetabling",
        "isExtraImport": true,
        "detail": "sports_timetabling",
        "documentation": {}
    },
    {
        "label": "solve_model",
        "importPath": "sports_timetabling",
        "description": "sports_timetabling",
        "isExtraImport": true,
        "detail": "sports_timetabling",
        "documentation": {}
    },
    {
        "label": "solve_model_big",
        "importPath": "sports_timetabling",
        "description": "sports_timetabling",
        "isExtraImport": true,
        "detail": "sports_timetabling",
        "documentation": {}
    },
    {
        "label": "gen_data",
        "importPath": "staffing",
        "description": "staffing",
        "isExtraImport": true,
        "detail": "staffing",
        "documentation": {}
    },
    {
        "label": "solve_model",
        "importPath": "staffing",
        "description": "staffing",
        "isExtraImport": true,
        "detail": "staffing",
        "documentation": {}
    },
    {
        "label": "gen_section",
        "importPath": "staff_scheduling",
        "description": "staff_scheduling",
        "isExtraImport": true,
        "detail": "staff_scheduling",
        "documentation": {}
    },
    {
        "label": "gen_instructor",
        "importPath": "staff_scheduling",
        "description": "staff_scheduling",
        "isExtraImport": true,
        "detail": "staff_scheduling",
        "documentation": {}
    },
    {
        "label": "gen_pairs",
        "importPath": "staff_scheduling",
        "description": "staff_scheduling",
        "isExtraImport": true,
        "detail": "staff_scheduling",
        "documentation": {}
    },
    {
        "label": "solve_model",
        "importPath": "staff_scheduling",
        "description": "staff_scheduling",
        "isExtraImport": true,
        "detail": "staff_scheduling",
        "documentation": {}
    },
    {
        "label": "gen_sets",
        "importPath": "staff_scheduling",
        "description": "staff_scheduling",
        "isExtraImport": true,
        "detail": "staff_scheduling",
        "documentation": {}
    },
    {
        "label": "gen_data",
        "importPath": "tsp",
        "description": "tsp",
        "isExtraImport": true,
        "detail": "tsp",
        "documentation": {}
    },
    {
        "label": "solve_model",
        "importPath": "tsp",
        "description": "tsp",
        "isExtraImport": true,
        "detail": "tsp",
        "documentation": {}
    },
    {
        "label": "solve_model_eliminate",
        "importPath": "tsp",
        "description": "tsp",
        "isExtraImport": true,
        "detail": "tsp",
        "documentation": {}
    },
    {
        "label": "solve_model_p",
        "importPath": "tsp",
        "description": "tsp",
        "isExtraImport": true,
        "detail": "tsp",
        "documentation": {}
    },
    {
        "label": "solve_model_star",
        "importPath": "tsp",
        "description": "tsp",
        "isExtraImport": true,
        "detail": "tsp",
        "documentation": {}
    },
    {
        "label": "asyncio",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "asyncio",
        "description": "asyncio",
        "detail": "asyncio",
        "documentation": {}
    },
    {
        "label": "sqlite3",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sqlite3",
        "description": "sqlite3",
        "detail": "sqlite3",
        "documentation": {}
    },
    {
        "label": "seaborn",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "seaborn",
        "description": "seaborn",
        "detail": "seaborn",
        "documentation": {}
    },
    {
        "label": "random,",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "random.",
        "description": "random.",
        "detail": "random.",
        "documentation": {}
    },
    {
        "label": "ghlib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "ghlib",
        "description": "ghlib",
        "detail": "ghlib",
        "documentation": {}
    },
    {
        "label": "jiralib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "jiralib",
        "description": "jiralib",
        "detail": "jiralib",
        "documentation": {}
    },
    {
        "label": "util",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "util",
        "description": "util",
        "detail": "util",
        "documentation": {}
    },
    {
        "label": "Sync",
        "importPath": "sync",
        "description": "sync",
        "isExtraImport": true,
        "detail": "sync",
        "documentation": {}
    },
    {
        "label": "DIRECTION_G2J",
        "importPath": "sync",
        "description": "sync",
        "isExtraImport": true,
        "detail": "sync",
        "documentation": {}
    },
    {
        "label": "DIRECTION_J2G",
        "importPath": "sync",
        "description": "sync",
        "isExtraImport": true,
        "detail": "sync",
        "documentation": {}
    },
    {
        "label": "DIRECTION_BOTH",
        "importPath": "sync",
        "description": "sync",
        "isExtraImport": true,
        "detail": "sync",
        "documentation": {}
    },
    {
        "label": "server",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "server",
        "description": "server",
        "detail": "server",
        "documentation": {}
    },
    {
        "label": "JIRA",
        "importPath": "jira",
        "description": "jira",
        "isExtraImport": true,
        "detail": "jira",
        "documentation": {}
    },
    {
        "label": "Flask",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "request",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "jsonify",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "default_handler",
        "importPath": "flask.logging",
        "description": "flask.logging",
        "isExtraImport": true,
        "detail": "flask.logging",
        "documentation": {}
    },
    {
        "label": "hmac",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "hmac",
        "description": "hmac",
        "detail": "hmac",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "threading",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "threading",
        "description": "threading",
        "detail": "threading",
        "documentation": {}
    },
    {
        "label": "LanguageParser",
        "importPath": "parsers.language_parser",
        "description": "parsers.language_parser",
        "isExtraImport": true,
        "detail": "parsers.language_parser",
        "documentation": {}
    },
    {
        "label": "match_from_span",
        "importPath": "parsers.language_parser",
        "description": "parsers.language_parser",
        "isExtraImport": true,
        "detail": "parsers.language_parser",
        "documentation": {}
    },
    {
        "label": "tokenize_code",
        "importPath": "parsers.language_parser",
        "description": "parsers.language_parser",
        "isExtraImport": true,
        "detail": "parsers.language_parser",
        "documentation": {}
    },
    {
        "label": "LanguageParser",
        "importPath": "parsers.language_parser",
        "description": "parsers.language_parser",
        "isExtraImport": true,
        "detail": "parsers.language_parser",
        "documentation": {}
    },
    {
        "label": "match_from_span",
        "importPath": "parsers.language_parser",
        "description": "parsers.language_parser",
        "isExtraImport": true,
        "detail": "parsers.language_parser",
        "documentation": {}
    },
    {
        "label": "tokenize_code",
        "importPath": "parsers.language_parser",
        "description": "parsers.language_parser",
        "isExtraImport": true,
        "detail": "parsers.language_parser",
        "documentation": {}
    },
    {
        "label": "traverse_type",
        "importPath": "parsers.language_parser",
        "description": "parsers.language_parser",
        "isExtraImport": true,
        "detail": "parsers.language_parser",
        "documentation": {}
    },
    {
        "label": "previous_sibling",
        "importPath": "parsers.language_parser",
        "description": "parsers.language_parser",
        "isExtraImport": true,
        "detail": "parsers.language_parser",
        "documentation": {}
    },
    {
        "label": "node_parent",
        "importPath": "parsers.language_parser",
        "description": "parsers.language_parser",
        "isExtraImport": true,
        "detail": "parsers.language_parser",
        "documentation": {}
    },
    {
        "label": "LanguageParser",
        "importPath": "parsers.language_parser",
        "description": "parsers.language_parser",
        "isExtraImport": true,
        "detail": "parsers.language_parser",
        "documentation": {}
    },
    {
        "label": "match_from_span",
        "importPath": "parsers.language_parser",
        "description": "parsers.language_parser",
        "isExtraImport": true,
        "detail": "parsers.language_parser",
        "documentation": {}
    },
    {
        "label": "tokenize_code",
        "importPath": "parsers.language_parser",
        "description": "parsers.language_parser",
        "isExtraImport": true,
        "detail": "parsers.language_parser",
        "documentation": {}
    },
    {
        "label": "traverse_type",
        "importPath": "parsers.language_parser",
        "description": "parsers.language_parser",
        "isExtraImport": true,
        "detail": "parsers.language_parser",
        "documentation": {}
    },
    {
        "label": "LanguageParser",
        "importPath": "parsers.language_parser",
        "description": "parsers.language_parser",
        "isExtraImport": true,
        "detail": "parsers.language_parser",
        "documentation": {}
    },
    {
        "label": "match_from_span",
        "importPath": "parsers.language_parser",
        "description": "parsers.language_parser",
        "isExtraImport": true,
        "detail": "parsers.language_parser",
        "documentation": {}
    },
    {
        "label": "tokenize_code",
        "importPath": "parsers.language_parser",
        "description": "parsers.language_parser",
        "isExtraImport": true,
        "detail": "parsers.language_parser",
        "documentation": {}
    },
    {
        "label": "traverse_type",
        "importPath": "parsers.language_parser",
        "description": "parsers.language_parser",
        "isExtraImport": true,
        "detail": "parsers.language_parser",
        "documentation": {}
    },
    {
        "label": "LanguageParser",
        "importPath": "parsers.language_parser",
        "description": "parsers.language_parser",
        "isExtraImport": true,
        "detail": "parsers.language_parser",
        "documentation": {}
    },
    {
        "label": "match_from_span",
        "importPath": "parsers.language_parser",
        "description": "parsers.language_parser",
        "isExtraImport": true,
        "detail": "parsers.language_parser",
        "documentation": {}
    },
    {
        "label": "tokenize_code",
        "importPath": "parsers.language_parser",
        "description": "parsers.language_parser",
        "isExtraImport": true,
        "detail": "parsers.language_parser",
        "documentation": {}
    },
    {
        "label": "traverse_type",
        "importPath": "parsers.language_parser",
        "description": "parsers.language_parser",
        "isExtraImport": true,
        "detail": "parsers.language_parser",
        "documentation": {}
    },
    {
        "label": "LanguageParser",
        "importPath": "parsers.language_parser",
        "description": "parsers.language_parser",
        "isExtraImport": true,
        "detail": "parsers.language_parser",
        "documentation": {}
    },
    {
        "label": "match_from_span",
        "importPath": "parsers.language_parser",
        "description": "parsers.language_parser",
        "isExtraImport": true,
        "detail": "parsers.language_parser",
        "documentation": {}
    },
    {
        "label": "tokenize_code",
        "importPath": "parsers.language_parser",
        "description": "parsers.language_parser",
        "isExtraImport": true,
        "detail": "parsers.language_parser",
        "documentation": {}
    },
    {
        "label": "LanguageParser",
        "importPath": "parsers.language_parser",
        "description": "parsers.language_parser",
        "isExtraImport": true,
        "detail": "parsers.language_parser",
        "documentation": {}
    },
    {
        "label": "tokenize_docstring",
        "importPath": "parsers.language_parser",
        "description": "parsers.language_parser",
        "isExtraImport": true,
        "detail": "parsers.language_parser",
        "documentation": {}
    },
    {
        "label": "get_docstring_summary",
        "importPath": "parsers.commentutils",
        "description": "parsers.commentutils",
        "isExtraImport": true,
        "detail": "parsers.commentutils",
        "documentation": {}
    },
    {
        "label": "strip_c_style_comment_delimiters",
        "importPath": "parsers.commentutils",
        "description": "parsers.commentutils",
        "isExtraImport": true,
        "detail": "parsers.commentutils",
        "documentation": {}
    },
    {
        "label": "get_docstring_summary",
        "importPath": "parsers.commentutils",
        "description": "parsers.commentutils",
        "isExtraImport": true,
        "detail": "parsers.commentutils",
        "documentation": {}
    },
    {
        "label": "strip_c_style_comment_delimiters",
        "importPath": "parsers.commentutils",
        "description": "parsers.commentutils",
        "isExtraImport": true,
        "detail": "parsers.commentutils",
        "documentation": {}
    },
    {
        "label": "strip_c_style_comment_delimiters",
        "importPath": "parsers.commentutils",
        "description": "parsers.commentutils",
        "isExtraImport": true,
        "detail": "parsers.commentutils",
        "documentation": {}
    },
    {
        "label": "get_docstring_summary",
        "importPath": "parsers.commentutils",
        "description": "parsers.commentutils",
        "isExtraImport": true,
        "detail": "parsers.commentutils",
        "documentation": {}
    },
    {
        "label": "strip_c_style_comment_delimiters",
        "importPath": "parsers.commentutils",
        "description": "parsers.commentutils",
        "isExtraImport": true,
        "detail": "parsers.commentutils",
        "documentation": {}
    },
    {
        "label": "get_docstring_summary",
        "importPath": "parsers.commentutils",
        "description": "parsers.commentutils",
        "isExtraImport": true,
        "detail": "parsers.commentutils",
        "documentation": {}
    },
    {
        "label": "get_docstring_summary",
        "importPath": "parsers.commentutils",
        "description": "parsers.commentutils",
        "isExtraImport": true,
        "detail": "parsers.commentutils",
        "documentation": {}
    },
    {
        "label": "get_docstring_summary",
        "importPath": "parsers.commentutils",
        "description": "parsers.commentutils",
        "isExtraImport": true,
        "detail": "parsers.commentutils",
        "documentation": {}
    },
    {
        "label": "glob",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "glob",
        "description": "glob",
        "detail": "glob",
        "documentation": {}
    },
    {
        "label": "pickle",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pickle",
        "description": "pickle",
        "detail": "pickle",
        "documentation": {}
    },
    {
        "label": "dask.distributed",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "dask.distributed",
        "description": "dask.distributed",
        "detail": "dask.distributed",
        "documentation": {}
    },
    {
        "label": "Client",
        "importPath": "dask.distributed",
        "description": "dask.distributed",
        "isExtraImport": true,
        "detail": "dask.distributed",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "LANGUAGE_METADATA",
        "importPath": "language_data",
        "description": "language_data",
        "isExtraImport": true,
        "detail": "language_data",
        "documentation": {}
    },
    {
        "label": "LANGUAGE_METADATA",
        "importPath": "language_data",
        "description": "language_data",
        "isExtraImport": true,
        "detail": "language_data",
        "documentation": {}
    },
    {
        "label": "LANGUAGE_METADATA",
        "importPath": "language_data",
        "description": "language_data",
        "isExtraImport": true,
        "detail": "language_data",
        "documentation": {}
    },
    {
        "label": "LANGUAGE_METADATA",
        "importPath": "language_data",
        "description": "language_data",
        "isExtraImport": true,
        "detail": "language_data",
        "documentation": {}
    },
    {
        "label": "download",
        "importPath": "utils",
        "description": "utils",
        "isExtraImport": true,
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "download",
        "importPath": "utils",
        "description": "utils",
        "isExtraImport": true,
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "get_sha",
        "importPath": "utils",
        "description": "utils",
        "isExtraImport": true,
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "flatten",
        "importPath": "utils",
        "description": "utils",
        "isExtraImport": true,
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "remap_nwo",
        "importPath": "utils",
        "description": "utils",
        "isExtraImport": true,
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "walk",
        "importPath": "utils",
        "description": "utils",
        "isExtraImport": true,
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "GoParser",
        "importPath": "parsers.go_parser",
        "description": "parsers.go_parser",
        "isExtraImport": true,
        "detail": "parsers.go_parser",
        "documentation": {}
    },
    {
        "label": "JavaParser",
        "importPath": "parsers.java_parser",
        "description": "parsers.java_parser",
        "isExtraImport": true,
        "detail": "parsers.java_parser",
        "documentation": {}
    },
    {
        "label": "JavascriptParser",
        "importPath": "parsers.javascript_parser",
        "description": "parsers.javascript_parser",
        "isExtraImport": true,
        "detail": "parsers.javascript_parser",
        "documentation": {}
    },
    {
        "label": "PhpParser",
        "importPath": "parsers.php_parser",
        "description": "parsers.php_parser",
        "isExtraImport": true,
        "detail": "parsers.php_parser",
        "documentation": {}
    },
    {
        "label": "PythonParser",
        "importPath": "parsers.python_parser",
        "description": "parsers.python_parser",
        "isExtraImport": true,
        "detail": "parsers.python_parser",
        "documentation": {}
    },
    {
        "label": "RubyParser",
        "importPath": "parsers.ruby_parser",
        "description": "parsers.ruby_parser",
        "isExtraImport": true,
        "detail": "parsers.ruby_parser",
        "documentation": {}
    },
    {
        "label": "docopt",
        "importPath": "docopt",
        "description": "docopt",
        "isExtraImport": true,
        "detail": "docopt",
        "documentation": {}
    },
    {
        "label": "docopt",
        "importPath": "docopt",
        "description": "docopt",
        "isExtraImport": true,
        "detail": "docopt",
        "documentation": {}
    },
    {
        "label": "docopt",
        "importPath": "docopt",
        "description": "docopt",
        "isExtraImport": true,
        "detail": "docopt",
        "documentation": {}
    },
    {
        "label": "docopt",
        "importPath": "docopt",
        "description": "docopt",
        "isExtraImport": true,
        "detail": "docopt",
        "documentation": {}
    },
    {
        "label": "docopt",
        "importPath": "docopt",
        "description": "docopt",
        "isExtraImport": true,
        "detail": "docopt",
        "documentation": {}
    },
    {
        "label": "docopt",
        "importPath": "docopt",
        "description": "docopt",
        "isExtraImport": true,
        "detail": "docopt",
        "documentation": {}
    },
    {
        "label": "docopt",
        "importPath": "docopt",
        "description": "docopt",
        "isExtraImport": true,
        "detail": "docopt",
        "documentation": {}
    },
    {
        "label": "docopt",
        "importPath": "docopt",
        "description": "docopt",
        "isExtraImport": true,
        "detail": "docopt",
        "documentation": {}
    },
    {
        "label": "docopt",
        "importPath": "docopt",
        "description": "docopt",
        "isExtraImport": true,
        "detail": "docopt",
        "documentation": {}
    },
    {
        "label": "docopt",
        "importPath": "docopt",
        "description": "docopt",
        "isExtraImport": true,
        "detail": "docopt",
        "documentation": {}
    },
    {
        "label": "docopt",
        "importPath": "docopt",
        "description": "docopt",
        "isExtraImport": true,
        "detail": "docopt",
        "documentation": {}
    },
    {
        "label": "docopt",
        "importPath": "docopt",
        "description": "docopt",
        "isExtraImport": true,
        "detail": "docopt",
        "documentation": {}
    },
    {
        "label": "docopt",
        "importPath": "docopt",
        "description": "docopt",
        "isExtraImport": true,
        "detail": "docopt",
        "documentation": {}
    },
    {
        "label": "docopt",
        "importPath": "docopt",
        "description": "docopt",
        "isExtraImport": true,
        "detail": "docopt",
        "documentation": {}
    },
    {
        "label": "Language",
        "importPath": "tree_sitter",
        "description": "tree_sitter",
        "isExtraImport": true,
        "detail": "tree_sitter",
        "documentation": {}
    },
    {
        "label": "Language",
        "importPath": "tree_sitter",
        "description": "tree_sitter",
        "isExtraImport": true,
        "detail": "tree_sitter",
        "documentation": {}
    },
    {
        "label": "Parser",
        "importPath": "tree_sitter",
        "description": "tree_sitter",
        "isExtraImport": true,
        "detail": "tree_sitter",
        "documentation": {}
    },
    {
        "label": "Language",
        "importPath": "tree_sitter",
        "description": "tree_sitter",
        "isExtraImport": true,
        "detail": "tree_sitter",
        "documentation": {}
    },
    {
        "label": "Language",
        "importPath": "tree_sitter",
        "description": "tree_sitter",
        "isExtraImport": true,
        "detail": "tree_sitter",
        "documentation": {}
    },
    {
        "label": "DataProcessor",
        "importPath": "process",
        "description": "process",
        "isExtraImport": true,
        "detail": "process",
        "documentation": {}
    },
    {
        "label": "DataProcessor",
        "importPath": "process",
        "description": "process",
        "isExtraImport": true,
        "detail": "process",
        "documentation": {}
    },
    {
        "label": "multiprocessing",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "multiprocessing",
        "description": "multiprocessing",
        "detail": "multiprocessing",
        "documentation": {}
    },
    {
        "label": "Pool",
        "importPath": "multiprocessing",
        "description": "multiprocessing",
        "isExtraImport": true,
        "detail": "multiprocessing",
        "documentation": {}
    },
    {
        "label": "Pool",
        "importPath": "multiprocessing",
        "description": "multiprocessing",
        "isExtraImport": true,
        "detail": "multiprocessing",
        "documentation": {}
    },
    {
        "label": "Pool",
        "importPath": "multiprocessing",
        "description": "multiprocessing",
        "isExtraImport": true,
        "detail": "multiprocessing",
        "documentation": {}
    },
    {
        "label": "Pool",
        "importPath": "multiprocessing",
        "description": "multiprocessing",
        "isExtraImport": true,
        "detail": "multiprocessing",
        "documentation": {}
    },
    {
        "label": "cpu_count",
        "importPath": "multiprocessing",
        "description": "multiprocessing",
        "isExtraImport": true,
        "detail": "multiprocessing",
        "documentation": {}
    },
    {
        "label": "DuplicateDetector",
        "importPath": "dpu_utils.codeutils.deduplication",
        "description": "dpu_utils.codeutils.deduplication",
        "isExtraImport": true,
        "detail": "dpu_utils.codeutils.deduplication",
        "documentation": {}
    },
    {
        "label": "DuplicateDetector",
        "importPath": "dpu_utils.codeutils.deduplication",
        "description": "dpu_utils.codeutils.deduplication",
        "isExtraImport": true,
        "detail": "dpu_utils.codeutils.deduplication",
        "documentation": {}
    },
    {
        "label": "gzip",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "gzip",
        "description": "gzip",
        "detail": "gzip",
        "documentation": {}
    },
    {
        "label": "parso",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "parso",
        "description": "parso",
        "detail": "parso",
        "documentation": {}
    },
    {
        "label": "RichPath",
        "importPath": "dpu_utils.utils",
        "description": "dpu_utils.utils",
        "isExtraImport": true,
        "detail": "dpu_utils.utils",
        "documentation": {}
    },
    {
        "label": "run_and_debug",
        "importPath": "dpu_utils.utils",
        "description": "dpu_utils.utils",
        "isExtraImport": true,
        "detail": "dpu_utils.utils",
        "documentation": {}
    },
    {
        "label": "RichPath",
        "importPath": "dpu_utils.utils",
        "description": "dpu_utils.utils",
        "isExtraImport": true,
        "detail": "dpu_utils.utils",
        "documentation": {}
    },
    {
        "label": "run_and_debug",
        "importPath": "dpu_utils.utils",
        "description": "dpu_utils.utils",
        "isExtraImport": true,
        "detail": "dpu_utils.utils",
        "documentation": {}
    },
    {
        "label": "RichPath",
        "importPath": "dpu_utils.utils",
        "description": "dpu_utils.utils",
        "isExtraImport": true,
        "detail": "dpu_utils.utils",
        "documentation": {}
    },
    {
        "label": "RichPath",
        "importPath": "dpu_utils.utils",
        "description": "dpu_utils.utils",
        "isExtraImport": true,
        "detail": "dpu_utils.utils",
        "documentation": {}
    },
    {
        "label": "run_and_debug",
        "importPath": "dpu_utils.utils",
        "description": "dpu_utils.utils",
        "isExtraImport": true,
        "detail": "dpu_utils.utils",
        "documentation": {}
    },
    {
        "label": "run_and_debug",
        "importPath": "dpu_utils.utils",
        "description": "dpu_utils.utils",
        "isExtraImport": true,
        "detail": "dpu_utils.utils",
        "documentation": {}
    },
    {
        "label": "RichPath",
        "importPath": "dpu_utils.utils",
        "description": "dpu_utils.utils",
        "isExtraImport": true,
        "detail": "dpu_utils.utils",
        "documentation": {}
    },
    {
        "label": "ChunkWriter",
        "importPath": "dpu_utils.utils",
        "description": "dpu_utils.utils",
        "isExtraImport": true,
        "detail": "dpu_utils.utils",
        "documentation": {}
    },
    {
        "label": "RichPath",
        "importPath": "dpu_utils.utils",
        "description": "dpu_utils.utils",
        "isExtraImport": true,
        "detail": "dpu_utils.utils",
        "documentation": {}
    },
    {
        "label": "run_and_debug",
        "importPath": "dpu_utils.utils",
        "description": "dpu_utils.utils",
        "isExtraImport": true,
        "detail": "dpu_utils.utils",
        "documentation": {}
    },
    {
        "label": "RichPath",
        "importPath": "dpu_utils.utils",
        "description": "dpu_utils.utils",
        "isExtraImport": true,
        "detail": "dpu_utils.utils",
        "documentation": {}
    },
    {
        "label": "run_and_debug",
        "importPath": "dpu_utils.utils",
        "description": "dpu_utils.utils",
        "isExtraImport": true,
        "detail": "dpu_utils.utils",
        "documentation": {}
    },
    {
        "label": "RichPath",
        "importPath": "dpu_utils.utils",
        "description": "dpu_utils.utils",
        "isExtraImport": true,
        "detail": "dpu_utils.utils",
        "documentation": {}
    },
    {
        "label": "RichPath",
        "importPath": "dpu_utils.utils",
        "description": "dpu_utils.utils",
        "isExtraImport": true,
        "detail": "dpu_utils.utils",
        "documentation": {}
    },
    {
        "label": "RichPath",
        "importPath": "dpu_utils.utils",
        "description": "dpu_utils.utils",
        "isExtraImport": true,
        "detail": "dpu_utils.utils",
        "documentation": {}
    },
    {
        "label": "RichPath",
        "importPath": "dpu_utils.utils",
        "description": "dpu_utils.utils",
        "isExtraImport": true,
        "detail": "dpu_utils.utils",
        "documentation": {}
    },
    {
        "label": "run_and_debug",
        "importPath": "dpu_utils.utils",
        "description": "dpu_utils.utils",
        "isExtraImport": true,
        "detail": "dpu_utils.utils",
        "documentation": {}
    },
    {
        "label": "run_and_debug",
        "importPath": "dpu_utils.utils",
        "description": "dpu_utils.utils",
        "isExtraImport": true,
        "detail": "dpu_utils.utils",
        "documentation": {}
    },
    {
        "label": "RichPath",
        "importPath": "dpu_utils.utils",
        "description": "dpu_utils.utils",
        "isExtraImport": true,
        "detail": "dpu_utils.utils",
        "documentation": {}
    },
    {
        "label": "RichPath",
        "importPath": "dpu_utils.utils",
        "description": "dpu_utils.utils",
        "isExtraImport": true,
        "detail": "dpu_utils.utils",
        "documentation": {}
    },
    {
        "label": "git_tag_run",
        "importPath": "dpu_utils.utils",
        "description": "dpu_utils.utils",
        "isExtraImport": true,
        "detail": "dpu_utils.utils",
        "documentation": {}
    },
    {
        "label": "run_and_debug",
        "importPath": "dpu_utils.utils",
        "description": "dpu_utils.utils",
        "isExtraImport": true,
        "detail": "dpu_utils.utils",
        "documentation": {}
    },
    {
        "label": "tokenize_docstring_from_string",
        "importPath": "dataextraction.utils",
        "description": "dataextraction.utils",
        "isExtraImport": true,
        "detail": "dataextraction.utils",
        "documentation": {}
    },
    {
        "label": "tokenize_docstring_from_string",
        "importPath": "dataextraction.utils",
        "description": "dataextraction.utils",
        "isExtraImport": true,
        "detail": "dataextraction.utils",
        "documentation": {}
    },
    {
        "label": "chunked_save_df_to_jsonl",
        "importPath": "utils.pkldf2jsonl",
        "description": "utils.pkldf2jsonl",
        "isExtraImport": true,
        "detail": "utils.pkldf2jsonl",
        "documentation": {}
    },
    {
        "label": "chunked_save_df_to_jsonl",
        "importPath": "utils.pkldf2jsonl",
        "description": "utils.pkldf2jsonl",
        "isExtraImport": true,
        "detail": "utils.pkldf2jsonl",
        "documentation": {}
    },
    {
        "label": "six",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "six",
        "description": "six",
        "detail": "six",
        "documentation": {}
    },
    {
        "label": "tensorflow",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "tensorflow",
        "description": "tensorflow",
        "detail": "tensorflow",
        "documentation": {}
    },
    {
        "label": "get_activation",
        "importPath": "utils.tfutils",
        "description": "utils.tfutils",
        "isExtraImport": true,
        "detail": "utils.tfutils",
        "documentation": {}
    },
    {
        "label": "get_activation",
        "importPath": "utils.tfutils",
        "description": "utils.tfutils",
        "isExtraImport": true,
        "detail": "utils.tfutils",
        "documentation": {}
    },
    {
        "label": "pool_sequence_embedding",
        "importPath": "utils.tfutils",
        "description": "utils.tfutils",
        "isExtraImport": true,
        "detail": "utils.tfutils",
        "documentation": {}
    },
    {
        "label": "get_activation",
        "importPath": "utils.tfutils",
        "description": "utils.tfutils",
        "isExtraImport": true,
        "detail": "utils.tfutils",
        "documentation": {}
    },
    {
        "label": "pool_sequence_embedding",
        "importPath": "utils.tfutils",
        "description": "utils.tfutils",
        "isExtraImport": true,
        "detail": "utils.tfutils",
        "documentation": {}
    },
    {
        "label": "write_to_feed_dict",
        "importPath": "utils.tfutils",
        "description": "utils.tfutils",
        "isExtraImport": true,
        "detail": "utils.tfutils",
        "documentation": {}
    },
    {
        "label": "pool_sequence_embedding",
        "importPath": "utils.tfutils",
        "description": "utils.tfutils",
        "isExtraImport": true,
        "detail": "utils.tfutils",
        "documentation": {}
    },
    {
        "label": "pool_sequence_embedding",
        "importPath": "utils.tfutils",
        "description": "utils.tfutils",
        "isExtraImport": true,
        "detail": "utils.tfutils",
        "documentation": {}
    },
    {
        "label": "write_to_feed_dict",
        "importPath": "utils.tfutils",
        "description": "utils.tfutils",
        "isExtraImport": true,
        "detail": "utils.tfutils",
        "documentation": {}
    },
    {
        "label": "pool_sequence_embedding",
        "importPath": "utils.tfutils",
        "description": "utils.tfutils",
        "isExtraImport": true,
        "detail": "utils.tfutils",
        "documentation": {}
    },
    {
        "label": "pool_sequence_embedding",
        "importPath": "utils.tfutils",
        "description": "utils.tfutils",
        "isExtraImport": true,
        "detail": "utils.tfutils",
        "documentation": {}
    },
    {
        "label": "convert_and_pad_token_sequence",
        "importPath": "utils.tfutils",
        "description": "utils.tfutils",
        "isExtraImport": true,
        "detail": "utils.tfutils",
        "documentation": {}
    },
    {
        "label": "BpeVocabulary",
        "importPath": "utils.bpevocabulary",
        "description": "utils.bpevocabulary",
        "isExtraImport": true,
        "detail": "utils.bpevocabulary",
        "documentation": {}
    },
    {
        "label": "BpeVocabulary",
        "importPath": "utils.bpevocabulary",
        "description": "utils.bpevocabulary",
        "isExtraImport": true,
        "detail": "utils.bpevocabulary",
        "documentation": {}
    },
    {
        "label": "split_identifier_into_parts",
        "importPath": "dpu_utils.codeutils",
        "description": "dpu_utils.codeutils",
        "isExtraImport": true,
        "detail": "dpu_utils.codeutils",
        "documentation": {}
    },
    {
        "label": "split_identifier_into_parts",
        "importPath": "dpu_utils.codeutils",
        "description": "dpu_utils.codeutils",
        "isExtraImport": true,
        "detail": "dpu_utils.codeutils",
        "documentation": {}
    },
    {
        "label": "Vocabulary",
        "importPath": "dpu_utils.mlutils",
        "description": "dpu_utils.mlutils",
        "isExtraImport": true,
        "detail": "dpu_utils.mlutils",
        "documentation": {}
    },
    {
        "label": "Vocabulary",
        "importPath": "dpu_utils.mlutils",
        "description": "dpu_utils.mlutils",
        "isExtraImport": true,
        "detail": "dpu_utils.mlutils",
        "documentation": {}
    },
    {
        "label": "Vocabulary",
        "importPath": "dpu_utils.mlutils",
        "description": "dpu_utils.mlutils",
        "isExtraImport": true,
        "detail": "dpu_utils.mlutils",
        "documentation": {}
    },
    {
        "label": "ConvolutionSeqEncoder",
        "importPath": "encoders",
        "description": "encoders",
        "isExtraImport": true,
        "detail": "encoders",
        "documentation": {}
    },
    {
        "label": "ConvSelfAttentionEncoder",
        "importPath": "encoders",
        "description": "encoders",
        "isExtraImport": true,
        "detail": "encoders",
        "documentation": {}
    },
    {
        "label": "Encoder",
        "importPath": "encoders",
        "description": "encoders",
        "isExtraImport": true,
        "detail": "encoders",
        "documentation": {}
    },
    {
        "label": "QueryType",
        "importPath": "encoders",
        "description": "encoders",
        "isExtraImport": true,
        "detail": "encoders",
        "documentation": {}
    },
    {
        "label": "NBoWEncoder",
        "importPath": "encoders",
        "description": "encoders",
        "isExtraImport": true,
        "detail": "encoders",
        "documentation": {}
    },
    {
        "label": "RNNEncoder",
        "importPath": "encoders",
        "description": "encoders",
        "isExtraImport": true,
        "detail": "encoders",
        "documentation": {}
    },
    {
        "label": "SelfAttentionEncoder",
        "importPath": "encoders",
        "description": "encoders",
        "isExtraImport": true,
        "detail": "encoders",
        "documentation": {}
    },
    {
        "label": "wandb",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "wandb",
        "description": "wandb",
        "detail": "wandb",
        "documentation": {}
    },
    {
        "label": "run_jobs_in_parallel",
        "importPath": "utils.py_utils",
        "description": "utils.py_utils",
        "isExtraImport": true,
        "detail": "utils.py_utils",
        "documentation": {}
    },
    {
        "label": "Model",
        "importPath": "models",
        "description": "models",
        "isExtraImport": true,
        "detail": "models",
        "documentation": {}
    },
    {
        "label": "Model",
        "importPath": "models",
        "description": "models",
        "isExtraImport": true,
        "detail": "models",
        "documentation": {}
    },
    {
        "label": "Model",
        "importPath": "models",
        "description": "models",
        "isExtraImport": true,
        "detail": "models",
        "documentation": {}
    },
    {
        "label": "NeuralBoWModel",
        "importPath": "models",
        "description": "models",
        "isExtraImport": true,
        "detail": "models",
        "documentation": {}
    },
    {
        "label": "RNNModel",
        "importPath": "models",
        "description": "models",
        "isExtraImport": true,
        "detail": "models",
        "documentation": {}
    },
    {
        "label": "SelfAttentionModel",
        "importPath": "models",
        "description": "models",
        "isExtraImport": true,
        "detail": "models",
        "documentation": {}
    },
    {
        "label": "ConvolutionalModel",
        "importPath": "models",
        "description": "models",
        "isExtraImport": true,
        "detail": "models",
        "documentation": {}
    },
    {
        "label": "ConvSelfAttentionModel",
        "importPath": "models",
        "description": "models",
        "isExtraImport": true,
        "detail": "models",
        "documentation": {}
    },
    {
        "label": "toolz",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "toolz",
        "description": "toolz",
        "detail": "toolz",
        "documentation": {}
    },
    {
        "label": "TSNE",
        "importPath": "sklearn.manifold",
        "description": "sklearn.manifold",
        "isExtraImport": true,
        "detail": "sklearn.manifold",
        "documentation": {}
    },
    {
        "label": "pdist",
        "importPath": "scipy.spatial.distance",
        "description": "scipy.spatial.distance",
        "isExtraImport": true,
        "detail": "scipy.spatial.distance",
        "documentation": {}
    },
    {
        "label": "pdist",
        "importPath": "scipy.spatial.distance",
        "description": "scipy.spatial.distance",
        "isExtraImport": true,
        "detail": "scipy.spatial.distance",
        "documentation": {}
    },
    {
        "label": "cdist",
        "importPath": "scipy.spatial.distance",
        "description": "scipy.spatial.distance",
        "isExtraImport": true,
        "detail": "scipy.spatial.distance",
        "documentation": {}
    },
    {
        "label": "model_restore_helper",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "model_restore_helper",
        "description": "model_restore_helper",
        "detail": "model_restore_helper",
        "documentation": {}
    },
    {
        "label": "square_to_condensed",
        "importPath": "utils.visutils",
        "description": "utils.visutils",
        "isExtraImport": true,
        "detail": "utils.visutils",
        "documentation": {}
    },
    {
        "label": "square_to_condensed",
        "importPath": "utils.visutils",
        "description": "utils.visutils",
        "isExtraImport": true,
        "detail": "utils.visutils",
        "documentation": {}
    },
    {
        "label": "take",
        "importPath": "more_itertools",
        "description": "more_itertools",
        "isExtraImport": true,
        "detail": "more_itertools",
        "documentation": {}
    },
    {
        "label": "chunked",
        "importPath": "more_itertools",
        "description": "more_itertools",
        "isExtraImport": true,
        "detail": "more_itertools",
        "documentation": {}
    },
    {
        "label": "flatten",
        "importPath": "more_itertools",
        "description": "more_itertools",
        "isExtraImport": true,
        "detail": "more_itertools",
        "documentation": {}
    },
    {
        "label": "Initializer",
        "importPath": "tensorflow.python.ops.init_ops",
        "description": "tensorflow.python.ops.init_ops",
        "isExtraImport": true,
        "detail": "tensorflow.python.ops.init_ops",
        "documentation": {}
    },
    {
        "label": "model_test",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "model_test",
        "description": "model_test",
        "detail": "model_test",
        "documentation": {}
    },
    {
        "label": "expand_data_path",
        "importPath": "model_test",
        "description": "model_test",
        "isExtraImport": true,
        "detail": "model_test",
        "documentation": {}
    },
    {
        "label": "MrrSearchTester",
        "importPath": "model_test",
        "description": "model_test",
        "isExtraImport": true,
        "detail": "model_test",
        "documentation": {}
    },
    {
        "label": "compute_evaluation_metrics",
        "importPath": "model_test",
        "description": "model_test",
        "isExtraImport": true,
        "detail": "model_test",
        "documentation": {}
    },
    {
        "label": "get_data_files_from_directory",
        "importPath": "models.model",
        "description": "models.model",
        "isExtraImport": true,
        "detail": "models.model",
        "documentation": {}
    },
    {
        "label": "Model",
        "importPath": "models.model",
        "description": "models.model",
        "isExtraImport": true,
        "detail": "models.model",
        "documentation": {}
    },
    {
        "label": "Model",
        "importPath": "models.model",
        "description": "models.model",
        "isExtraImport": true,
        "detail": "models.model",
        "documentation": {}
    },
    {
        "label": "tokenize_python_from_string",
        "importPath": "dataextraction.python.parse_python_data",
        "description": "dataextraction.python.parse_python_data",
        "isExtraImport": true,
        "detail": "dataextraction.python.parse_python_data",
        "documentation": {}
    },
    {
        "label": "tokenize_docstring_from_string",
        "importPath": "dataextraction.python.parse_python_data",
        "description": "dataextraction.python.parse_python_data",
        "isExtraImport": true,
        "detail": "dataextraction.python.parse_python_data",
        "documentation": {}
    },
    {
        "label": "AnnoyIndex",
        "importPath": "annoy",
        "description": "annoy",
        "isExtraImport": true,
        "detail": "annoy",
        "documentation": {}
    },
    {
        "label": "InternalApi",
        "importPath": "wandb.apis",
        "description": "wandb.apis",
        "isExtraImport": true,
        "detail": "wandb.apis",
        "documentation": {}
    },
    {
        "label": "HTTPServer",
        "importPath": "BaseHTTPServer",
        "description": "BaseHTTPServer",
        "isExtraImport": true,
        "detail": "BaseHTTPServer",
        "documentation": {}
    },
    {
        "label": "BaseHTTPRequestHandler",
        "importPath": "BaseHTTPServer",
        "description": "BaseHTTPServer",
        "isExtraImport": true,
        "detail": "BaseHTTPServer",
        "documentation": {}
    },
    {
        "label": "BaseHTTPRequestHandler",
        "importPath": "BaseHTTPServer",
        "description": "BaseHTTPServer",
        "isExtraImport": true,
        "detail": "BaseHTTPServer",
        "documentation": {}
    },
    {
        "label": "HTTPServer",
        "importPath": "BaseHTTPServer",
        "description": "BaseHTTPServer",
        "isExtraImport": true,
        "detail": "BaseHTTPServer",
        "documentation": {}
    },
    {
        "label": "signal",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "signal",
        "description": "signal",
        "detail": "signal",
        "documentation": {}
    },
    {
        "label": "httplib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "httplib",
        "description": "httplib",
        "detail": "httplib",
        "documentation": {}
    },
    {
        "label": "urllib2",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "urllib2",
        "description": "urllib2",
        "detail": "urllib2",
        "documentation": {}
    },
    {
        "label": "ssl",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "ssl",
        "description": "ssl",
        "detail": "ssl",
        "documentation": {}
    },
    {
        "label": "AngryBird",
        "kind": 6,
        "importPath": "Blog.AAOpen-Unchanged.AAOpen-Cirriculumn.11.2-11.6.angry_bird",
        "description": "Blog.AAOpen-Unchanged.AAOpen-Cirriculumn.11.2-11.6.angry_bird",
        "peekOfCode": "class AngryBird:\n    def __init__(self):\n        self.x = 0\n        self.y = 0\n    def move_up_by(self, delta):\n        self.y += delta\nbird = AngryBird()\nprint(bird)\nprint(bird.y)\nbird.move_up_by(5)",
        "detail": "Blog.AAOpen-Unchanged.AAOpen-Cirriculumn.11.2-11.6.angry_bird",
        "documentation": {}
    },
    {
        "label": "bird",
        "kind": 5,
        "importPath": "Blog.AAOpen-Unchanged.AAOpen-Cirriculumn.11.2-11.6.angry_bird",
        "description": "Blog.AAOpen-Unchanged.AAOpen-Cirriculumn.11.2-11.6.angry_bird",
        "peekOfCode": "bird = AngryBird()\nprint(bird)\nprint(bird.y)\nbird.move_up_by(5)\nprint(bird.y)",
        "detail": "Blog.AAOpen-Unchanged.AAOpen-Cirriculumn.11.2-11.6.angry_bird",
        "documentation": {}
    },
    {
        "label": "base16_tomorrow_dark",
        "kind": 6,
        "importPath": "dotfiles-master.dotfiles-master.bin.git-blame-colored",
        "description": "dotfiles-master.dotfiles-master.bin.git-blame-colored",
        "peekOfCode": "class base16_tomorrow_dark(Style):\n    default_style = ''\n    background_color = BACKGROUND\n    highlight_color = SELECTION\n    background_color = BACKGROUND\n    highlight_color = SELECTION\n    styles = {\n        # No corresponding class for the following:\n        Text:                      FOREGROUND,  # class:  ''\n        Whitespace:                \"\",          # class: 'w'",
        "detail": "dotfiles-master.dotfiles-master.bin.git-blame-colored",
        "documentation": {}
    },
    {
        "label": "lines_starting_with",
        "kind": 2,
        "importPath": "dotfiles-master.dotfiles-master.bin.git-blame-colored",
        "description": "dotfiles-master.dotfiles-master.bin.git-blame-colored",
        "peekOfCode": "def lines_starting_with(all_lines, prefix):\n    grepped = [l for l in all_lines if l.startswith(prefix)]\n    stripped = [l.split(prefix)[1] for l in grepped]\n    return stripped\ndef main():\n    cmd.extend(argv[1:])\n    gbl_raw = (subprocess.run(cmd, stdout=subprocess.PIPE).stdout\n               .decode().split('\\n'))\n    code = '\\n'.join(lines_starting_with(gbl_raw, '\\t'))\n    authors_by_line = lines_starting_with(gbl_raw, 'author ')",
        "detail": "dotfiles-master.dotfiles-master.bin.git-blame-colored",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "dotfiles-master.dotfiles-master.bin.git-blame-colored",
        "description": "dotfiles-master.dotfiles-master.bin.git-blame-colored",
        "peekOfCode": "def main():\n    cmd.extend(argv[1:])\n    gbl_raw = (subprocess.run(cmd, stdout=subprocess.PIPE).stdout\n               .decode().split('\\n'))\n    code = '\\n'.join(lines_starting_with(gbl_raw, '\\t'))\n    authors_by_line = lines_starting_with(gbl_raw, 'author ')\n    authors_unique = sorted(list(set(authors_by_line)))\n    formatter = Terminal256Formatter(style=base16_tomorrow_dark)\n    highlighted_raw = highlight(code, guess_lexer(code), formatter)\n    highlighted = highlighted_raw.split('\\n')",
        "detail": "dotfiles-master.dotfiles-master.bin.git-blame-colored",
        "documentation": {}
    },
    {
        "label": "color_groups",
        "kind": 5,
        "importPath": "dotfiles-master.dotfiles-master.bin.git-blame-colored",
        "description": "dotfiles-master.dotfiles-master.bin.git-blame-colored",
        "peekOfCode": "color_groups = [\n    [('red', None), ('green', None), ('yellow', None), ('magenta', None),\n     ('cyan', None)],\n    [('black', 'light_red'), ('black', 'light_green'),\n     ('black', 'light_yellow'), ('black', 'light_magenta'),\n     ('black', 'light_cyan')]\n]\ncmd = ['git', 'blame', '--line-porcelain']\n###############################################\n# START Base16 Tomorrow Dark style for Pygments",
        "detail": "dotfiles-master.dotfiles-master.bin.git-blame-colored",
        "documentation": {}
    },
    {
        "label": "cmd",
        "kind": 5,
        "importPath": "dotfiles-master.dotfiles-master.bin.git-blame-colored",
        "description": "dotfiles-master.dotfiles-master.bin.git-blame-colored",
        "peekOfCode": "cmd = ['git', 'blame', '--line-porcelain']\n###############################################\n# START Base16 Tomorrow Dark style for Pygments\n###############################################\n# https://github.com/idleberg/base16-pygments/blob/master/base16-tomorrow.dark.py\nfrom pygments.style import Style\nfrom pygments.token import Keyword, Name, Comment, String, Error, Text, \\\n     Number, Operator, Generic, Whitespace, Punctuation, Other, Literal\nBACKGROUND = \"#1d1f21\"\nCURRENT_LINE = \"#282a2e\"",
        "detail": "dotfiles-master.dotfiles-master.bin.git-blame-colored",
        "documentation": {}
    },
    {
        "label": "BACKGROUND",
        "kind": 5,
        "importPath": "dotfiles-master.dotfiles-master.bin.git-blame-colored",
        "description": "dotfiles-master.dotfiles-master.bin.git-blame-colored",
        "peekOfCode": "BACKGROUND = \"#1d1f21\"\nCURRENT_LINE = \"#282a2e\"\nSELECTION = \"#373b41\"\nFOREGROUND = \"#ffffff\"\nCOMMENT = \"#969896\"\nRED = \"#cc6666\"\nORANGE = \"#de935f\"\nYELLOW = \"#f0c674\"\nGREEN = \"#b5bd68\"\nAQUA = \"#8abeb7\"",
        "detail": "dotfiles-master.dotfiles-master.bin.git-blame-colored",
        "documentation": {}
    },
    {
        "label": "CURRENT_LINE",
        "kind": 5,
        "importPath": "dotfiles-master.dotfiles-master.bin.git-blame-colored",
        "description": "dotfiles-master.dotfiles-master.bin.git-blame-colored",
        "peekOfCode": "CURRENT_LINE = \"#282a2e\"\nSELECTION = \"#373b41\"\nFOREGROUND = \"#ffffff\"\nCOMMENT = \"#969896\"\nRED = \"#cc6666\"\nORANGE = \"#de935f\"\nYELLOW = \"#f0c674\"\nGREEN = \"#b5bd68\"\nAQUA = \"#8abeb7\"\nBLUE = \"#81a2be\"",
        "detail": "dotfiles-master.dotfiles-master.bin.git-blame-colored",
        "documentation": {}
    },
    {
        "label": "SELECTION",
        "kind": 5,
        "importPath": "dotfiles-master.dotfiles-master.bin.git-blame-colored",
        "description": "dotfiles-master.dotfiles-master.bin.git-blame-colored",
        "peekOfCode": "SELECTION = \"#373b41\"\nFOREGROUND = \"#ffffff\"\nCOMMENT = \"#969896\"\nRED = \"#cc6666\"\nORANGE = \"#de935f\"\nYELLOW = \"#f0c674\"\nGREEN = \"#b5bd68\"\nAQUA = \"#8abeb7\"\nBLUE = \"#81a2be\"\nPURPLE = \"#b294bb\"",
        "detail": "dotfiles-master.dotfiles-master.bin.git-blame-colored",
        "documentation": {}
    },
    {
        "label": "FOREGROUND",
        "kind": 5,
        "importPath": "dotfiles-master.dotfiles-master.bin.git-blame-colored",
        "description": "dotfiles-master.dotfiles-master.bin.git-blame-colored",
        "peekOfCode": "FOREGROUND = \"#ffffff\"\nCOMMENT = \"#969896\"\nRED = \"#cc6666\"\nORANGE = \"#de935f\"\nYELLOW = \"#f0c674\"\nGREEN = \"#b5bd68\"\nAQUA = \"#8abeb7\"\nBLUE = \"#81a2be\"\nPURPLE = \"#b294bb\"\nclass base16_tomorrow_dark(Style):",
        "detail": "dotfiles-master.dotfiles-master.bin.git-blame-colored",
        "documentation": {}
    },
    {
        "label": "COMMENT",
        "kind": 5,
        "importPath": "dotfiles-master.dotfiles-master.bin.git-blame-colored",
        "description": "dotfiles-master.dotfiles-master.bin.git-blame-colored",
        "peekOfCode": "COMMENT = \"#969896\"\nRED = \"#cc6666\"\nORANGE = \"#de935f\"\nYELLOW = \"#f0c674\"\nGREEN = \"#b5bd68\"\nAQUA = \"#8abeb7\"\nBLUE = \"#81a2be\"\nPURPLE = \"#b294bb\"\nclass base16_tomorrow_dark(Style):\n    default_style = ''",
        "detail": "dotfiles-master.dotfiles-master.bin.git-blame-colored",
        "documentation": {}
    },
    {
        "label": "RED",
        "kind": 5,
        "importPath": "dotfiles-master.dotfiles-master.bin.git-blame-colored",
        "description": "dotfiles-master.dotfiles-master.bin.git-blame-colored",
        "peekOfCode": "RED = \"#cc6666\"\nORANGE = \"#de935f\"\nYELLOW = \"#f0c674\"\nGREEN = \"#b5bd68\"\nAQUA = \"#8abeb7\"\nBLUE = \"#81a2be\"\nPURPLE = \"#b294bb\"\nclass base16_tomorrow_dark(Style):\n    default_style = ''\n    background_color = BACKGROUND",
        "detail": "dotfiles-master.dotfiles-master.bin.git-blame-colored",
        "documentation": {}
    },
    {
        "label": "ORANGE",
        "kind": 5,
        "importPath": "dotfiles-master.dotfiles-master.bin.git-blame-colored",
        "description": "dotfiles-master.dotfiles-master.bin.git-blame-colored",
        "peekOfCode": "ORANGE = \"#de935f\"\nYELLOW = \"#f0c674\"\nGREEN = \"#b5bd68\"\nAQUA = \"#8abeb7\"\nBLUE = \"#81a2be\"\nPURPLE = \"#b294bb\"\nclass base16_tomorrow_dark(Style):\n    default_style = ''\n    background_color = BACKGROUND\n    highlight_color = SELECTION",
        "detail": "dotfiles-master.dotfiles-master.bin.git-blame-colored",
        "documentation": {}
    },
    {
        "label": "YELLOW",
        "kind": 5,
        "importPath": "dotfiles-master.dotfiles-master.bin.git-blame-colored",
        "description": "dotfiles-master.dotfiles-master.bin.git-blame-colored",
        "peekOfCode": "YELLOW = \"#f0c674\"\nGREEN = \"#b5bd68\"\nAQUA = \"#8abeb7\"\nBLUE = \"#81a2be\"\nPURPLE = \"#b294bb\"\nclass base16_tomorrow_dark(Style):\n    default_style = ''\n    background_color = BACKGROUND\n    highlight_color = SELECTION\n    background_color = BACKGROUND",
        "detail": "dotfiles-master.dotfiles-master.bin.git-blame-colored",
        "documentation": {}
    },
    {
        "label": "GREEN",
        "kind": 5,
        "importPath": "dotfiles-master.dotfiles-master.bin.git-blame-colored",
        "description": "dotfiles-master.dotfiles-master.bin.git-blame-colored",
        "peekOfCode": "GREEN = \"#b5bd68\"\nAQUA = \"#8abeb7\"\nBLUE = \"#81a2be\"\nPURPLE = \"#b294bb\"\nclass base16_tomorrow_dark(Style):\n    default_style = ''\n    background_color = BACKGROUND\n    highlight_color = SELECTION\n    background_color = BACKGROUND\n    highlight_color = SELECTION",
        "detail": "dotfiles-master.dotfiles-master.bin.git-blame-colored",
        "documentation": {}
    },
    {
        "label": "AQUA",
        "kind": 5,
        "importPath": "dotfiles-master.dotfiles-master.bin.git-blame-colored",
        "description": "dotfiles-master.dotfiles-master.bin.git-blame-colored",
        "peekOfCode": "AQUA = \"#8abeb7\"\nBLUE = \"#81a2be\"\nPURPLE = \"#b294bb\"\nclass base16_tomorrow_dark(Style):\n    default_style = ''\n    background_color = BACKGROUND\n    highlight_color = SELECTION\n    background_color = BACKGROUND\n    highlight_color = SELECTION\n    styles = {",
        "detail": "dotfiles-master.dotfiles-master.bin.git-blame-colored",
        "documentation": {}
    },
    {
        "label": "BLUE",
        "kind": 5,
        "importPath": "dotfiles-master.dotfiles-master.bin.git-blame-colored",
        "description": "dotfiles-master.dotfiles-master.bin.git-blame-colored",
        "peekOfCode": "BLUE = \"#81a2be\"\nPURPLE = \"#b294bb\"\nclass base16_tomorrow_dark(Style):\n    default_style = ''\n    background_color = BACKGROUND\n    highlight_color = SELECTION\n    background_color = BACKGROUND\n    highlight_color = SELECTION\n    styles = {\n        # No corresponding class for the following:",
        "detail": "dotfiles-master.dotfiles-master.bin.git-blame-colored",
        "documentation": {}
    },
    {
        "label": "PURPLE",
        "kind": 5,
        "importPath": "dotfiles-master.dotfiles-master.bin.git-blame-colored",
        "description": "dotfiles-master.dotfiles-master.bin.git-blame-colored",
        "peekOfCode": "PURPLE = \"#b294bb\"\nclass base16_tomorrow_dark(Style):\n    default_style = ''\n    background_color = BACKGROUND\n    highlight_color = SELECTION\n    background_color = BACKGROUND\n    highlight_color = SELECTION\n    styles = {\n        # No corresponding class for the following:\n        Text:                      FOREGROUND,  # class:  ''",
        "detail": "dotfiles-master.dotfiles-master.bin.git-blame-colored",
        "documentation": {}
    },
    {
        "label": "gen_script",
        "kind": 2,
        "importPath": "dotfiles-master.dotfiles-master.fish.functions.__bass",
        "description": "dotfiles-master.dotfiles-master.fish.functions.__bass",
        "peekOfCode": "def gen_script():\n    divider = '-__-__-__bass___-env-output-__bass_-__-__-__-__'\n    # Use the following instead of /usr/bin/env to read environment so we can\n    # deal with multi-line environment variables (and other odd cases).\n    env_reader = \"python -c 'import os,json; print(json.dumps({k:v for k,v in os.environ.items()}))'\"\n    args = [BASH, '-c', env_reader]\n    output = subprocess.check_output(args, universal_newlines=True)\n    old_env = output.strip()\n    command = '{}; echo \"{}\"; {}'.format(' '.join(sys.argv[1:]), divider, env_reader)\n    args = [BASH, '-c', command]",
        "detail": "dotfiles-master.dotfiles-master.fish.functions.__bass",
        "documentation": {}
    },
    {
        "label": "BASH",
        "kind": 5,
        "importPath": "dotfiles-master.dotfiles-master.fish.functions.__bass",
        "description": "dotfiles-master.dotfiles-master.fish.functions.__bass",
        "peekOfCode": "BASH = 'bash'\ndef gen_script():\n    divider = '-__-__-__bass___-env-output-__bass_-__-__-__-__'\n    # Use the following instead of /usr/bin/env to read environment so we can\n    # deal with multi-line environment variables (and other odd cases).\n    env_reader = \"python -c 'import os,json; print(json.dumps({k:v for k,v in os.environ.items()}))'\"\n    args = [BASH, '-c', env_reader]\n    output = subprocess.check_output(args, universal_newlines=True)\n    old_env = output.strip()\n    command = '{}; echo \"{}\"; {}'.format(' '.join(sys.argv[1:]), divider, env_reader)",
        "detail": "dotfiles-master.dotfiles-master.fish.functions.__bass",
        "documentation": {}
    },
    {
        "label": "zeros",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.all_zeros",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.all_zeros",
        "peekOfCode": "def zeros(arr,n):\n    count=0\n    for i in range(n):\n        if arr[i]!=0:\n            arr[count]=arr[i]\n            count+=1\n    while count<n:\n        arr[count]=0\n        count+=1\ndef print_arr(arr,n):",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.all_zeros",
        "documentation": {}
    },
    {
        "label": "print_arr",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.all_zeros",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.all_zeros",
        "peekOfCode": "def print_arr(arr,n):\n    for i in range(n):\n        print(arr[i],end=\" \")\narr=[1,0,0,2,5,0]\nzeros(arr,len(arr))\nprint_arr(arr,len(arr))",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.all_zeros",
        "documentation": {}
    },
    {
        "label": "hashString",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.anagram-detection",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.anagram-detection",
        "peekOfCode": "def hashString(str):\n  # Map characters to prime numbers to multiply\n  charMap = {\n    'a': 2,\n    'b': 3,\n    'c': 5,\n    'd': 7,\n    'e': 11,\n    'f': 13,\n    'g': 17,",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.anagram-detection",
        "documentation": {}
    },
    {
        "label": "anagramDetection",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.anagram-detection",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.anagram-detection",
        "peekOfCode": "def anagramDetection(parent, child):\n  length = len(child)\n  anagram = hashString(child)\n  total = 0\n  for i in range(0, len(parent) - length):\n    if hashString(parent[i: i + length]) == anagram:\n      total = total + 1\n  return total",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.anagram-detection",
        "documentation": {}
    },
    {
        "label": "SortAnagram",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.Anagram",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.Anagram",
        "peekOfCode": "def SortAnagram(arr):\n    temp = []\n    stage = []\n    dic = []\n    for i in arr:\n        for j in i:\n            stage.append(j)\n        stage.sort()\n        temp.append(''.join(stage))\n        stage = []",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.Anagram",
        "documentation": {}
    },
    {
        "label": "arr",
        "kind": 5,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.Anagram",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.Anagram",
        "peekOfCode": "arr = [\"cat\", \"dog\", \"tac\", \"god\", \"act\"]\nSortAnagram(arr)",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.Anagram",
        "documentation": {}
    },
    {
        "label": "array_pair_sum_tests",
        "kind": 6,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.array-pair-sum",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.array-pair-sum",
        "peekOfCode": "class array_pair_sum_tests(unittest.TestCase):\n    def setUp(self):\n        self.arr1 = [3, 4, 5, 6, 7]\n        self.arr2 = [3, 4, 5, 4, 4]\n        self.result1 = [[3, 7], [4, 6]]\n        self.result2 = [[3, 5], [4, 4], [4, 4], [4, 4]]\n    def test_one(self):\n        self.assertEqual(\n            array_pair_sum_iterative(self.arr1, 10), self.result1)\n        self.assertEqual(",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.array-pair-sum",
        "documentation": {}
    },
    {
        "label": "array_pair_sum_iterative",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.array-pair-sum",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.array-pair-sum",
        "peekOfCode": "def array_pair_sum_iterative(arr, k):\n    \"\"\"\n    returns the array of pairs using an iterative method.\n    complexity: O(n^2)\n    \"\"\"\n    result = []\n    for i in range(len(arr)):\n        for j in range(i + 1, len(arr)):\n            if arr[i] + arr[j] == k:\n                result.append([arr[i], arr[j]])",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.array-pair-sum",
        "documentation": {}
    },
    {
        "label": "array_pair_sum_sort",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.array-pair-sum",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.array-pair-sum",
        "peekOfCode": "def array_pair_sum_sort(arr, k):\n    \"\"\"\n    first sort the array and then use binary search to find pairs.\n    complexity: O(nlogn)\n    \"\"\"\n    result = []\n    arr.sort()\n    for i in range(len(arr)):\n        if k - arr[i] in arr[i+1:]:\n            result.append([arr[i], k - arr[i]])",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.array-pair-sum",
        "documentation": {}
    },
    {
        "label": "array_pair_sum_hash_table",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.array-pair-sum",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.array-pair-sum",
        "peekOfCode": "def array_pair_sum_hash_table(arr, k):\n    \"\"\"\n    Use a hash table to store array elements of pairs.\n    complexity: O(n)\n    \"\"\"\n    result = []\n    hash_table = {}\n    for e in arr:\n        if e in hash_table:\n            result.append([k - e, e])",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.array-pair-sum",
        "documentation": {}
    },
    {
        "label": "balancedBrackets",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.balanced-brackets",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.balanced-brackets",
        "peekOfCode": "def balancedBrackets(string):\n  stack = []\n  # Process every character on input\n  for char in string:\n    # Assign an initial value in case the stack is empty\n    last = 0\n    # Assign the value of the last element if stack is not empty\n    if stack:\n      last = stack[len(stack) - 1]\n    if stack and last in brackets and brackets[last] == char:",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.balanced-brackets",
        "documentation": {}
    },
    {
        "label": "brackets",
        "kind": 5,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.balanced-brackets",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.balanced-brackets",
        "peekOfCode": "brackets = {\n  '(': ')',\n  '{': '}',\n  '[': ']'\n}\n# On each input string, process it using the balance checker\ndef balancedBrackets(string):\n  stack = []\n  # Process every character on input\n  for char in string:",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.balanced-brackets",
        "documentation": {}
    },
    {
        "label": "balance",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.balance_parenthisis",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.balance_parenthisis",
        "peekOfCode": "def balance(arr):\n    open_bracket=['[','{','(']\n    close_bracket=[']','}',')']\n    stack=[]\n    for i in arr:\n        if i in open_bracket:\n            stack.append(i)\n        elif i in close_bracket:\n            pos=close_bracket.index(i)\n            if len(stack)>=0 and (open_bracket[pos]==stack[len(stack)-1]):",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.balance_parenthisis",
        "documentation": {}
    },
    {
        "label": "binary_search_iterative",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.binary_search",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.binary_search",
        "peekOfCode": "def binary_search_iterative(arr,l,r,x):\n    while(l<=r):\n        mid=l+(r-l)//2\n        if(arr[mid]==x):\n            return mid\n        elif(arr[mid]<x):\n            l=mid+1\n        else:\n            l=r-1\n    return -1",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.binary_search",
        "documentation": {}
    },
    {
        "label": "binary_search_recursive",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.binary_search",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.binary_search",
        "peekOfCode": "def binary_search_recursive(arr,l,r,x):\n    if l <=r:\n        mid= l + (r-l)//2\n        if(arr[mid]==x):\n            return mid\n        elif(arr[mid]<x):\n            return binary_search_recursive(arr,mid+1,r,x)\n        else:\n            return binary_search_recursive(arr,l,mid-1,x)\n    else:",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.binary_search",
        "documentation": {}
    },
    {
        "label": "result_recursive",
        "kind": 5,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.binary_search",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.binary_search",
        "peekOfCode": "result_recursive = binary_search_recursive(arr,0,len(arr)-1,x)\nif result_iterative != -1:\n    print(\"element found: \"+ str(result_recursive))\nelse:\n    print(\"not found\")",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.binary_search",
        "documentation": {}
    },
    {
        "label": "bubble_sort",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.buble_sort",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.buble_sort",
        "peekOfCode": "def bubble_sort(arr,n):\n    for i in range(n):\n        for j in range(0,n-i-1):\n            if arr[j]>arr[j+1]:\n                arr[j],arr[j+1]=arr[j+1],arr[j]\n    return arr\narr=[64, 34, 25, 12, 22, 11, 90]\nresult=bubble_sort(arr,len(arr))\nprint(result)",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.buble_sort",
        "documentation": {}
    },
    {
        "label": "orangesRotting",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.celeb",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.celeb",
        "peekOfCode": "def orangesRotting(elemnts):\n    if not elemnts or len(elemnts)==0:\n        return 0\n    n=len(elemnts)\n    m=len(elemnts[0])\n    rotten=[]\n    for i in range(n):\n        for j in range(m):\n            if elemnts[i][j]==2:\n                rotten.append((i,j))",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.celeb",
        "documentation": {}
    },
    {
        "label": "f",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.convert-array",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.convert-array",
        "peekOfCode": "def f(arr):\n    \"\"\"sorts the array by numbers in place using constant extra space\"\"\"\n    position = 0\n    for i in xrange(len(arr) / 3):\n        gap = (len(arr) - position) / 3\n        arr.insert(position + 1, arr.pop(position + gap * 1))\n        arr.insert(position + 2, arr.pop(position + gap * 2))\n        position += 3\n    return arr",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.convert-array",
        "documentation": {}
    },
    {
        "label": "CountChar",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.Count the characters ",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.Count the characters ",
        "peekOfCode": "def CountChar(String,Occurance):\n    STROCR={}\n    RESULT=[]\n    for i in range(len(String)):\n        if String[i] in STROCR.keys():\n            STROCR[String[i]]+=1\n        else:\n            STROCR[String[i]]=1\n    for j in STROCR.keys():\n        if STROCR[j] == Occurance:",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.Count the characters ",
        "documentation": {}
    },
    {
        "label": "String",
        "kind": 5,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.Count the characters ",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.Count the characters ",
        "peekOfCode": "String = \"geeksforgeeks\"\nOccurance = 2\nCountChar(String,Occurance)",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.Count the characters ",
        "documentation": {}
    },
    {
        "label": "Occurance",
        "kind": 5,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.Count the characters ",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.Count the characters ",
        "peekOfCode": "Occurance = 2\nCountChar(String,Occurance)",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.Count the characters ",
        "documentation": {}
    },
    {
        "label": "countingValleys",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.Counting_Valleys",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.Counting_Valleys",
        "peekOfCode": "def countingValleys(steps, path):\n    # Write your code here\n    path=list(path)\n    sealevel=valley=0\n    for paths in path:\n        if paths=='U':\n            sealevel+=1\n        else:\n            sealevel-=1\n        if paths=='U' and sealevel==0:",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.Counting_Valleys",
        "documentation": {}
    },
    {
        "label": "cyclic_rotation",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.cyclic_rotation",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.cyclic_rotation",
        "peekOfCode": "def cyclic_rotation(arr,n):\n    temp=arr[n-1]\n    for i in range(n-1,0,-1):\n        arr[i]=arr[i-1]\n    arr[0]=temp\ndef print_array(arr,n):\n    for i in range(n):\n        print(arr[i])\narr=[1,2,3,4,5]\ncyclic_rotation(arr,5)",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.cyclic_rotation",
        "documentation": {}
    },
    {
        "label": "print_array",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.cyclic_rotation",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.cyclic_rotation",
        "peekOfCode": "def print_array(arr,n):\n    for i in range(n):\n        print(arr[i])\narr=[1,2,3,4,5]\ncyclic_rotation(arr,5)\nprint_array(arr,5)",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.cyclic_rotation",
        "documentation": {}
    },
    {
        "label": "Dis_array",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.Distinct Digit Array",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.Distinct Digit Array",
        "peekOfCode": "def Dis_array(arr):\n    dup=[]\n    for i in arr:\n        length=len(str(i))\n        i=str(i)\n        for j in range(length):\n            if i[j] in dup:\n                pass\n            else:\n                dup.append(i[j])",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.Distinct Digit Array",
        "documentation": {}
    },
    {
        "label": "Stack",
        "kind": 6,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.Doubling_stack",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.Doubling_stack",
        "peekOfCode": "class Stack:\n    def __init__(self,limit=10):\n        self.stack=[]\n        self.limit=limit\n    def push(self,n):\n        if len(self.stack)>self.limit:\n            self.doublelimit()\n        else:\n            self.stack.append(n)\n    def pop(self):",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.Doubling_stack",
        "documentation": {}
    },
    {
        "label": "duplicate_removal",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.duplicate_removal",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.duplicate_removal",
        "peekOfCode": "def duplicate_removal(arr):\n    dictonary={}\n    for i in arr:\n        if i in dictonary:\n            dictonary[i]=dictonary[i]+1\n        else:\n            dictonary[i]=1\n    return dictonary.keys()\narr=[1,2,2,3,4,5,5,6,7]\nprint(int(len(list(duplicate_removal(arr)))))",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.duplicate_removal",
        "documentation": {}
    },
    {
        "label": "even_occuring_element",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.even-occuring-element",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.even-occuring-element",
        "peekOfCode": "def even_occuring_element(arr):\n    \"\"\"Returns the even occuring element within a list of integers\"\"\"\n    dict = {}\n    for num in arr:\n        if num in dict:\n            dict[num] += 1\n        else:\n            dict[num] = 1\n    for num in dict:\n        if not dict[num] & 1: # bitwise check for parity.",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.even-occuring-element",
        "documentation": {}
    },
    {
        "label": "find",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.exists_in",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.exists_in",
        "peekOfCode": "def find(arr,search,n):\n    for i in range(n):\n        if arr[i]== search:\n            return True\n            break\narr=[1,2,3,4,5,6]\nsearch=4\nprint(find(arr,search,6))",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.exists_in",
        "documentation": {}
    },
    {
        "label": "fname",
        "kind": 5,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.extract",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.extract",
        "peekOfCode": "fname = \"spark-3.0.2-bin-hadoop2.7.tgz\"\nif fname.endswith(\"tgz\"):\n    tar = tarfile.open('C:\\\\Users\\\\ag16000\\Downloads\\\\spark-3.0.2-bin-hadoop2.7.tgz', \"r:gz\")\n    tar.extractall()\n    tar.close()\nelif fname.endswith(\"tar\"):\n    tar = tarfile.open('C:\\\\Users\\\\ag16000\\Downloads\\\\spark-3.0.2-bin-hadoop2.7.tgz', \"r:\")\n    tar.extractall()\n    tar.close()",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.extract",
        "documentation": {}
    },
    {
        "label": "factorial_iterative",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.factorial",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.factorial",
        "peekOfCode": "def factorial_iterative(num):\n    \"\"\"returns the factorial of num using an iterative method.\"\"\"\n    factor = 1\n    for i in xrange(1, num + 1):\n        factor *= i\n    return factor\ndef factorial_reduce(num):\n    \"\"\"returns the factorial of num using a reduce (shortest method).\"\"\"\n    return reduce(lambda x, y: x * y, range(1, num + 1))\ndef factorial_recursive(num):",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.factorial",
        "documentation": {}
    },
    {
        "label": "factorial_reduce",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.factorial",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.factorial",
        "peekOfCode": "def factorial_reduce(num):\n    \"\"\"returns the factorial of num using a reduce (shortest method).\"\"\"\n    return reduce(lambda x, y: x * y, range(1, num + 1))\ndef factorial_recursive(num):\n    \"\"\"returns the factorial of num using a recursive method.\"\"\"\n    if num == 1:\n        return 1\n    return num * factorial_recursive(num -1)",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.factorial",
        "documentation": {}
    },
    {
        "label": "factorial_recursive",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.factorial",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.factorial",
        "peekOfCode": "def factorial_recursive(num):\n    \"\"\"returns the factorial of num using a recursive method.\"\"\"\n    if num == 1:\n        return 1\n    return num * factorial_recursive(num -1)",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.factorial",
        "documentation": {}
    },
    {
        "label": "fibonacci_iterative",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.fibonacci",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.fibonacci",
        "peekOfCode": "def fibonacci_iterative(limit):\n    \"\"\"fibonacci sequence using an iterative approach.\"\"\"\n    a, b = 0, 1\n    for i in xrange(limit):\n        a, b = b, a + b\n    return a\ndef fibonacci_recursive(limit):\n    \"\"\"fibonacci sequence using a recusive approach.\"\"\"\n    if limit <= 1:\n        return limit",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.fibonacci",
        "documentation": {}
    },
    {
        "label": "fibonacci_recursive",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.fibonacci",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.fibonacci",
        "peekOfCode": "def fibonacci_recursive(limit):\n    \"\"\"fibonacci sequence using a recusive approach.\"\"\"\n    if limit <= 1:\n        return limit\n    return fibonacci_recursive(limit - 1) + fibonacci_recursive(limit - 2)\ndef fibonacci_reduce(limit):\n    \"\"\"fibonacci sequence using reduce (shortest option).\"\"\"\n    return reduce(lambda x, y: x + [x[y] + x[y - 1]], range(1, limit), [0, 1])[-1]\ndef fibonacci_comprehension(limit):\n    \"\"\"fibonacci sequence using a list comprehension.\"\"\"",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.fibonacci",
        "documentation": {}
    },
    {
        "label": "fibonacci_reduce",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.fibonacci",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.fibonacci",
        "peekOfCode": "def fibonacci_reduce(limit):\n    \"\"\"fibonacci sequence using reduce (shortest option).\"\"\"\n    return reduce(lambda x, y: x + [x[y] + x[y - 1]], range(1, limit), [0, 1])[-1]\ndef fibonacci_comprehension(limit):\n    \"\"\"fibonacci sequence using a list comprehension.\"\"\"\n    sequence = [0, 1]\n    [sequence.append(sequence[i] + sequence[i-1]) for i in range(1, limit)]\n    return sequence[-1]",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.fibonacci",
        "documentation": {}
    },
    {
        "label": "fibonacci_comprehension",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.fibonacci",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.fibonacci",
        "peekOfCode": "def fibonacci_comprehension(limit):\n    \"\"\"fibonacci sequence using a list comprehension.\"\"\"\n    sequence = [0, 1]\n    [sequence.append(sequence[i] + sequence[i-1]) for i in range(1, limit)]\n    return sequence[-1]",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.fibonacci",
        "documentation": {}
    },
    {
        "label": "fib_series",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.fib_series",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.fib_series",
        "peekOfCode": "def fib_series(count):\n    a=0\n    b=1\n    c=1\n    for i in range(count):\n        a=b\n        b=c\n        c=a+b\n        print(a)\nfib_series(10)",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.fib_series",
        "documentation": {}
    },
    {
        "label": "findDuplicate",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.Find the Duplicate Number",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.Find the Duplicate Number",
        "peekOfCode": "def findDuplicate(arr):\n    for i in range(len(arr)):\n        if arr[i]==arr[i+1]:\n            return arr[i]\n        else:\n            pass\narr=[1,3,4,2,2]\nprint(findDuplicate(arr))",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.Find the Duplicate Number",
        "documentation": {}
    },
    {
        "label": "difference_set",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.find-missing-element",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.find-missing-element",
        "peekOfCode": "def difference_set(orig, shuffled):\n    \"\"\"finds the missing element using a set.\"\"\"\n    return set(orig).difference(set(shuffled)).pop()\ndef difference_iterative(orig, shuffled):\n    \"\"\"finds the missing element by iterating over the list\"\"\"\n    for x in orig:\n        if not x in shuffled:\n            return x",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.find-missing-element",
        "documentation": {}
    },
    {
        "label": "difference_iterative",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.find-missing-element",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.find-missing-element",
        "peekOfCode": "def difference_iterative(orig, shuffled):\n    \"\"\"finds the missing element by iterating over the list\"\"\"\n    for x in orig:\n        if not x in shuffled:\n            return x",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.find-missing-element",
        "documentation": {}
    },
    {
        "label": "first_non_repeated_character",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.first-non-repeated-character",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.first-non-repeated-character",
        "peekOfCode": "def first_non_repeated_character(str):\n    \"\"\"finds the first character in a string that's not repreated\"\"\"\n    for i, char in enumerate(str):\n        if i - 1 >= 0 and char == str[i - 1]:\n            continue\n        if i + 1 < len(str) and char == str[i + 1]:\n            continue\n        return char",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.first-non-repeated-character",
        "documentation": {}
    },
    {
        "label": "left_search",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.first_occurance",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.first_occurance",
        "peekOfCode": "def left_search(arr,low,high,x):\n    temp=-1\n    while low <= high:\n        mid=low+(high-low)//2\n        if arr[mid]>x:\n            high=mid-1\n        elif arr[mid]<x:\n            low=mid+1\n        else:\n            temp=mid",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.first_occurance",
        "documentation": {}
    },
    {
        "label": "right_search",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.first_occurance",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.first_occurance",
        "peekOfCode": "def right_search(arr,low,high,x):\n    temp=-1\n    while low <= high:\n        mid=low+(high-low)//2\n        if arr[mid]>x:\n            high=mid-1\n        elif arr[mid]<x:\n            low=mid+1\n        else:\n            temp=mid",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.first_occurance",
        "documentation": {}
    },
    {
        "label": "flatten_array",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.flatten-array",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.flatten-array",
        "peekOfCode": "def flatten_array(orig):\n    \"\"\"returns a new, flattened, list\"\"\"\n    flattened_list = []\n    for item in orig:\n        if isinstance(item, list):\n            flattened_list += flatten_array(item)\n        else:\n            flattened_list.append(item)\n    return flattened_list\ndef flatten_in_place(orig):",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.flatten-array",
        "documentation": {}
    },
    {
        "label": "flatten_in_place",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.flatten-array",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.flatten-array",
        "peekOfCode": "def flatten_in_place(orig):\n    \"\"\"flattens a given list in place\"\"\"\n    is_flattened = False\n    while not is_flattened: # iterating until no more lists are found\n        is_flattened = True\n        for i, item in enumerate(orig):\n            if isinstance(item, list):\n                is_flattened = False\n                orig = orig[:i] + item + orig[i + 1:]\n    return orig",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.flatten-array",
        "documentation": {}
    },
    {
        "label": "jumpingOnClouds",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.Jumping_on_the_Clouds",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.Jumping_on_the_Clouds",
        "peekOfCode": "def jumpingOnClouds(c):\n    i = counter = 0\n    length = len(c)\n    while i<length-1:\n        if c[i+2]==0:\n            i+=2\n        else:\n            i+=1\n        counter+=1\n    return counter",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.Jumping_on_the_Clouds",
        "documentation": {}
    },
    {
        "label": "kidsWithCandies",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.Kids With the Greatest Number of Candies",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.Kids With the Greatest Number of Candies",
        "peekOfCode": "def kidsWithCandies(candies, extraCandies):\n    temp_array=[]\n    max_element=max(candies)\n    for i in candies:\n        temp=i+extraCandies\n        if max_element<=temp:\n            temp_array.append(True)\n        else:\n            temp_array.append(False)\n    return temp_array",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.Kids With the Greatest Number of Candies",
        "documentation": {}
    },
    {
        "label": "candies",
        "kind": 5,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.Kids With the Greatest Number of Candies",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.Kids With the Greatest Number of Candies",
        "peekOfCode": "candies = [2,3,5,1,3]\nextraCandies = 3\nprint(kidsWithCandies(candies,extraCandies))",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.Kids With the Greatest Number of Candies",
        "documentation": {}
    },
    {
        "label": "extraCandies",
        "kind": 5,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.Kids With the Greatest Number of Candies",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.Kids With the Greatest Number of Candies",
        "peekOfCode": "extraCandies = 3\nprint(kidsWithCandies(candies,extraCandies))",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.Kids With the Greatest Number of Candies",
        "documentation": {}
    },
    {
        "label": "kthSmallest",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.Kth smallest element",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.Kth smallest element",
        "peekOfCode": "def kthSmallest(arr, l, r, k): \n    if (k > 0 and k <= r - l + 1): \n        pos = randomPartition(arr, l, r)  \n        if (pos - l == k - 1):  \n            return arr[pos]  \n        if (pos - l > k - 1):  \n            return kthSmallest(arr, l, pos - 1, k)  \n        return kthSmallest(arr, pos + 1, r,  \n                           k - pos + l - 1) \n    return 999999999999",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.Kth smallest element",
        "documentation": {}
    },
    {
        "label": "swap",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.Kth smallest element",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.Kth smallest element",
        "peekOfCode": "def swap(arr, a, b): \n    temp = arr[a] \n    arr[a] = arr[b] \n    arr[b] = temp \ndef partition(arr, l, r): \n    x = arr[r] \n    i = l \n    for j in range(l, r): \n        if (arr[j] <= x): \n            swap(arr, i, j)  ",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.Kth smallest element",
        "documentation": {}
    },
    {
        "label": "partition",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.Kth smallest element",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.Kth smallest element",
        "peekOfCode": "def partition(arr, l, r): \n    x = arr[r] \n    i = l \n    for j in range(l, r): \n        if (arr[j] <= x): \n            swap(arr, i, j)  \n            i += 1\n    swap(arr, i, r)  \n    return i \ndef randomPartition(arr, l, r): ",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.Kth smallest element",
        "documentation": {}
    },
    {
        "label": "randomPartition",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.Kth smallest element",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.Kth smallest element",
        "peekOfCode": "def randomPartition(arr, l, r): \n    n = r - l + 1\n    pivot = int(random.random() % n)  \n    swap(arr, l + pivot, r)  \n    return partition(arr, l, r)",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.Kth smallest element",
        "documentation": {}
    },
    {
        "label": "kth_array",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.kth_largest",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.kth_largest",
        "peekOfCode": "def kth_array(arr,n):\n    arr.sort(reverse=True)\n    for i in range(n):\n        print(arr[i])\narr=[1, 23, 12, 9, 30, 2, 50]\nkth_array(arr,3)",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.kth_largest",
        "documentation": {}
    },
    {
        "label": "largest_continuous_sum",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.largest-continuous-sum",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.largest-continuous-sum",
        "peekOfCode": "def largest_continuous_sum(arr):\n    \"\"\"returns the highest sum of a continuous sequence in a given list\"\"\"\n    largest = 0\n    queue = []\n    for num in arr:\n        if len(queue) > 0 and queue[-1] + 1 != num:\n            sum = reduce(lambda x, y: x + y, queue)\n            if largest < sum:\n                largest = sum\n            queue = []",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.largest-continuous-sum",
        "documentation": {}
    },
    {
        "label": "addTwoNumbers",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.leet_1",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.leet_1",
        "peekOfCode": "def addTwoNumbers( l1, l2):\n    l1.reverse()\n    l2.reverse()\n    con_1=\"\"\n    con_2=\"\"\n    for i in l1:\n        con_1+=str(i)\n    for i in l2:\n        con_2+=str(i)\n    result=int(con_1)+int(con_2)",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.leet_1",
        "documentation": {}
    },
    {
        "label": "Node",
        "kind": 6,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.linked_list",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.linked_list",
        "peekOfCode": "class Node:\n    def __init__(self,data):\n        self.data=data\n        self.next=None\nclass LinkedList:\n    def __init__(self):\n        self.head=None\n    def PrintList(self):\n        if self.head is not None:\n            itr=self.head",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.linked_list",
        "documentation": {}
    },
    {
        "label": "LinkedList",
        "kind": 6,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.linked_list",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.linked_list",
        "peekOfCode": "class LinkedList:\n    def __init__(self):\n        self.head=None\n    def PrintList(self):\n        if self.head is not None:\n            itr=self.head\n            while itr:\n                print(itr.data,end=\"-->\")\n                itr=itr.next\nif __name__=='__main__':",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.linked_list",
        "documentation": {}
    },
    {
        "label": "getSumOfMultiple",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.multiples-of-3-and-5",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.multiples-of-3-and-5",
        "peekOfCode": "def getSumOfMultiple(num, limit):\n  return int((ceil(limit / num) - 1) * ceil(limit / num) * num / 2)\ndef getSumOfMultiples(multiples, limit):\n  result = 0\n  sign = 1\n  for i in range(1, len(multiples) + 1):\n    for x in combinations(multiples, i):\n      result += sign * getSumOfMultiple(reduce(mul, x, 1), limit)\n    sign *= -1\n  return result",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.multiples-of-3-and-5",
        "documentation": {}
    },
    {
        "label": "getSumOfMultiples",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.multiples-of-3-and-5",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.multiples-of-3-and-5",
        "peekOfCode": "def getSumOfMultiples(multiples, limit):\n  result = 0\n  sign = 1\n  for i in range(1, len(multiples) + 1):\n    for x in combinations(multiples, i):\n      result += sign * getSumOfMultiple(reduce(mul, x, 1), limit)\n    sign *= -1\n  return result",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.multiples-of-3-and-5",
        "documentation": {}
    },
    {
        "label": "once",
        "kind": 6,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.once",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.once",
        "peekOfCode": "class once:\n    def __init__(self, func, times=1):\n        self.times = int(times)\n        self.func  = func\n    def __call__(self, *args, **kwargs):\n        if self.times > 0:\n            self.times -= 1\n            return self.func(*args, **kwargs)",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.once",
        "documentation": {}
    },
    {
        "label": "is_prime",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.prime-number",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.prime-number",
        "peekOfCode": "def is_prime(n):\n    if n <= 1:\n        return False\n    elif n == 2:\n        return True\n    elif n % 2 == 0:\n        return False\n    for i in xrange(3, int(sqrt(n))+1, 2):\n        if n % i == 0:\n            return False",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.prime-number",
        "documentation": {}
    },
    {
        "label": "quickSort",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.quick-sort",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.quick-sort",
        "peekOfCode": "def quickSort(lst):\n    # List of 0 or 1 items is already sorted\n    if len(lst) <= 1:\n        return lst\n    else:\n        # Pivot can be chosen randomly\n        pivotIndex = randint(0, len(lst)-1)\n        pivot = lst[pivotIndex]\n        # Elements lower than and greater than pivot\n        lesser, greater = [], []",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.quick-sort",
        "documentation": {}
    },
    {
        "label": "sorted_rotation",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.sorted_array_rotation",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.sorted_array_rotation",
        "peekOfCode": "def sorted_rotation(arr,low,high,n):\n    while(low<high):\n        if arr[low]<=arr[high]:\n            return low\n        mid=low+(high-low)//2\n        next=(mid+1)%n\n        prev=(mid+n-1)%n\n        if(arr[mid]<arr[next] and arr[mid]<arr[prev]):\n            return mid\n        elif arr[mid]<=arr[high]:",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.sorted_array_rotation",
        "documentation": {}
    },
    {
        "label": "sort_num",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.sort_0_1_2",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.sort_0_1_2",
        "peekOfCode": "def sort_num(arr,n):\n    cnt0=0\n    cnt1=0\n    cnt2=0\n    for i in range(n):\n        if arr[i] == 0:\n            cnt0+=1\n        elif arr[i]==1:\n            cnt1+=1\n        elif arr[i]==2:",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.sort_0_1_2",
        "documentation": {}
    },
    {
        "label": "print_arr",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.sort_0_1_2",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.sort_0_1_2",
        "peekOfCode": "def print_arr(arr,n):\n    for i in range(n):\n        print(arr[i],end=\" \")\narr=[0, 1, 2, 0, 1, 2]\nn=len(arr)\nsort_num(arr,n)\nprint_arr(arr,n)",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.sort_0_1_2",
        "documentation": {}
    },
    {
        "label": "sprialMatrix",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.sprial_rotation",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.sprial_rotation",
        "peekOfCode": "def sprialMatrix(arr,m,n):\n    k=0\n    l=0\n    while k<m and l<n:\n        for i in range(l,n):\n            print(arr[k][i],end=\" \")\n        k+=1\n        for i in range(k,m):\n            print(arr[i][n-1],end=\" \")\n        n-=1",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.sprial_rotation",
        "documentation": {}
    },
    {
        "label": "Stack",
        "kind": 6,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.stack_imply",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.stack_imply",
        "peekOfCode": "class Stack:\n    # initialize the constructor of empty array\n    def __init__(self,arr,limit):\n        self.arr=arr\n        self.arr = []\n        self.limit = limit\n    # defining an method to get all the elements in the que\n    def print_elements(self):\n        for i in range(len(self.arr)):\n            print(self.arr[i])",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.stack_imply",
        "documentation": {}
    },
    {
        "label": "sta",
        "kind": 5,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.stack_imply",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.stack_imply",
        "peekOfCode": "sta = Stack([],4)\n# pushing an element to the array\nsta.push(1)\nsta.push(2)\nsta.push(1)\nsta.push(2)\nsta.push(2)\nsta.push(2)\n# printing all the elements in the stack\nsta.print_elements()",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.stack_imply",
        "documentation": {}
    },
    {
        "label": "Stack",
        "kind": 6,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.stack_max_o(1)",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.stack_max_o(1)",
        "peekOfCode": "class Stack:\n    # initialize the constructor of empty array\n    def __init__(self, arr, limit):\n        self.arr = arr\n        self.arr = []\n        self.limit = limit\n        self.max_array = []\n    # defining an method to get all the elements in the que\n    def print_elements(self):\n        for i in range(len(self.arr)):",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.stack_max_o(1)",
        "documentation": {}
    },
    {
        "label": "sta",
        "kind": 5,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.stack_max_o(1)",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.stack_max_o(1)",
        "peekOfCode": "sta = Stack([], 6)\n# pushing an element to the array\nsta.push(10)\nsta.maxPush()\nprint(\"-------------------\")\nsta.push(2)\nsta.maxPush()\nprint(\"-------------------\")\nsta.push(3)\nsta.maxPush()",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.stack_max_o(1)",
        "documentation": {}
    },
    {
        "label": "Solution",
        "kind": 6,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.Strong Password Checker",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.Strong Password Checker",
        "peekOfCode": "class Solution:\n    def strongPasswordChecker(self, s: str) -> int:\n        len_passwd = len(s)\n        lowercase, uppercase, digit = False, False, False\n        repeating = []  # list of interval of consecutive char.\n        for idx, char in enumerate(s):\n            if not lowercase and 97 <= ord(char) <= 122:\n                lowercase = True\n            if not uppercase and 65 <= ord(char) <= 90:\n                uppercase = True",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.Strong Password Checker",
        "documentation": {}
    },
    {
        "label": "Sol",
        "kind": 5,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.Strong Password Checker",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.Strong Password Checker",
        "peekOfCode": "Sol =  Solution()\nprint(Sol.strongPasswordChecker(\"a\"))",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.Strong Password Checker",
        "documentation": {}
    },
    {
        "label": "exactMatch",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.substring_search",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.substring_search",
        "peekOfCode": "def exactMatch(text, pat, text_index, pat_index):\n    if text_index == len(text) and pat_index != len(pat):\n        return 0\n    # Else If last character of pattern reaches\n    if pat_index == len(pat):\n        return 1\n    if text[text_index] == pat[pat_index]:\n        return exactMatch(text, pat, text_index+1, pat_index+1)\n    return 0\n# This function returns true if 'text' contain 'pat'",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.substring_search",
        "documentation": {}
    },
    {
        "label": "contains",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.substring_search",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.substring_search",
        "peekOfCode": "def contains(text, pat, text_index, pat_index):\n    # If last character of text reaches\n    if text_index == len(text):\n        return 0\n    # If current characters of pat and text match\n    if text[text_index] == pat[pat_index]:\n        if exactMatch(text, pat, text_index, pat_index):\n            return 1\n        else:\n            return contains(text, pat, text_index+1, pat_index)",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.substring_search",
        "documentation": {}
    },
    {
        "label": "Solution",
        "kind": 6,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.sun_finder",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.sun_finder",
        "peekOfCode": "class Solution:\n    # def __init__(self,arr,n,target):\n    #     self.arr=arr\n    #     self.n=n\n    #     self.target=target\n    def twoSum(self,arr,n,target):\n        for i in range(self.n):\n            for j in range(1,self.n):\n                result=self.arr[i]+self.arr[j]\n                if result==self.target:",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.sun_finder",
        "documentation": {}
    },
    {
        "label": "getListOfProcessSortedByMemory",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.system_process_scanner",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.system_process_scanner",
        "peekOfCode": "def getListOfProcessSortedByMemory():\n    listOfProcObjects = []\n    for proc in psutil.process_iter():\n        pinfo = proc.as_dict(attrs=['pid', 'name'])\n        pinfo['CPU_USAGE'] = proc.memory_info().vms / (1024 * 1024)\n        # Append dict to list\n        listOfProcObjects.append(pinfo);\n    listOfProcObjects = sorted(listOfProcObjects, key=lambda procObj: procObj['CPU_USAGE'], reverse=True)\n    result = json.dumps(listOfProcObjects)\n    lis=result.split(\"}\")",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.system_process_scanner",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.system_process_scanner",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.system_process_scanner",
        "peekOfCode": "def main():\n    print('##### Create a list of all running processes #######')\n    getListOfProcessSortedByMemory()\nif __name__ == '__main__':\n    main()",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.system_process_scanner",
        "documentation": {}
    },
    {
        "label": "theBoard",
        "kind": 5,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.temp",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.temp",
        "peekOfCode": "theBoard = [' '] * 10\nprint(theBoard)\n((bo[7] == le and bo[8] == le and bo[9] == le) or # across the top\n    (bo[4] == le and bo[5] == le and bo[6] == le) or # across the middle\n    (bo[1] == le and bo[2] == le and bo[3] == le) or # across the bottom\n    (bo[7] == le and bo[4] == le and bo[1] == le) or # down the left side\n    (bo[8] == le and bo[5] == le and bo[2] == le) or # down the middle\n    (bo[9] == le and bo[6] == le and bo[3] == le) or # down the right side\n    (bo[7] == le and bo[5] == le and bo[3] == le) or # diagonal\n    (bo[9] == le and bo[5] == le and bo[1] == le)) ",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.temp",
        "documentation": {}
    },
    {
        "label": "drawBoard",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.TicTacToe",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.TicTacToe",
        "peekOfCode": "def drawBoard(board):\n    # This function prints out the board that it was passed.\n    # \"board\" is a list of 10 strings representing the board (ignore index 0)\n    print('   |   |')\n    print(' ' + board[7] + ' | ' + board[8] + ' | ' + board[9])\n    print('   |   |')\n    print('-----------')\n    print('   |   |')\n    print(' ' + board[4] + ' | ' + board[5] + ' | ' + board[6])\n    print('   |   |')",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.TicTacToe",
        "documentation": {}
    },
    {
        "label": "inputPlayerLetter",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.TicTacToe",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.TicTacToe",
        "peekOfCode": "def inputPlayerLetter():\n    # Lets the player type which letter they want to be.\n    # Returns a list with the player’s letter as the first item, and the computer's letter as the second.\n    letter = ''\n    while not (letter == 'X' or letter == 'O'):\n        print('Do you want to be X or O?')\n        letter = input().upper()\n    # the first element in the list is the player’s letter, the second is the computer's letter.\n    if letter == 'X':\n        return ['X', 'O']",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.TicTacToe",
        "documentation": {}
    },
    {
        "label": "whoGoesFirst",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.TicTacToe",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.TicTacToe",
        "peekOfCode": "def whoGoesFirst():\n    # Randomly choose the player who goes first.\n    if random.randint(0, 1) == 0:\n        return 'computer'\n    else:\n        return 'player'\ndef playAgain():\n    # This function returns True if the player wants to play again, otherwise it returns False.\n    print('Do you want to play again? (yes or no)')\n    return input().lower().startswith('y')",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.TicTacToe",
        "documentation": {}
    },
    {
        "label": "playAgain",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.TicTacToe",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.TicTacToe",
        "peekOfCode": "def playAgain():\n    # This function returns True if the player wants to play again, otherwise it returns False.\n    print('Do you want to play again? (yes or no)')\n    return input().lower().startswith('y')\ndef makeMove(board, letter, move):\n    board[move] = letter\ndef isWinner(bo, le):\n    # Given a board and a player’s letter, this function returns True if that player has won.\n    # We use bo instead of board and le instead of letter so we don’t have to type as much.\n    return ((bo[7] == le and bo[8] == le and bo[9] == le) or # across the top",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.TicTacToe",
        "documentation": {}
    },
    {
        "label": "makeMove",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.TicTacToe",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.TicTacToe",
        "peekOfCode": "def makeMove(board, letter, move):\n    board[move] = letter\ndef isWinner(bo, le):\n    # Given a board and a player’s letter, this function returns True if that player has won.\n    # We use bo instead of board and le instead of letter so we don’t have to type as much.\n    return ((bo[7] == le and bo[8] == le and bo[9] == le) or # across the top\n    (bo[4] == le and bo[5] == le and bo[6] == le) or # across the middle\n    (bo[1] == le and bo[2] == le and bo[3] == le) or # across the bottom\n    (bo[7] == le and bo[4] == le and bo[1] == le) or # down the left side\n    (bo[8] == le and bo[5] == le and bo[2] == le) or # down the middle",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.TicTacToe",
        "documentation": {}
    },
    {
        "label": "isWinner",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.TicTacToe",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.TicTacToe",
        "peekOfCode": "def isWinner(bo, le):\n    # Given a board and a player’s letter, this function returns True if that player has won.\n    # We use bo instead of board and le instead of letter so we don’t have to type as much.\n    return ((bo[7] == le and bo[8] == le and bo[9] == le) or # across the top\n    (bo[4] == le and bo[5] == le and bo[6] == le) or # across the middle\n    (bo[1] == le and bo[2] == le and bo[3] == le) or # across the bottom\n    (bo[7] == le and bo[4] == le and bo[1] == le) or # down the left side\n    (bo[8] == le and bo[5] == le and bo[2] == le) or # down the middle\n    (bo[9] == le and bo[6] == le and bo[3] == le) or # down the right side\n    (bo[7] == le and bo[5] == le and bo[3] == le) or # diagonal",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.TicTacToe",
        "documentation": {}
    },
    {
        "label": "getBoardCopy",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.TicTacToe",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.TicTacToe",
        "peekOfCode": "def getBoardCopy(board):\n    # Make a duplicate of the board list and return it the duplicate.\n    dupeBoard = []\n    for i in board:\n        dupeBoard.append(i)\n    return dupeBoard\ndef isSpaceFree(board, move):\n    # Return true if the passed move is free on the passed board.\n    return board[move] == ' '\ndef getPlayerMove(board):",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.TicTacToe",
        "documentation": {}
    },
    {
        "label": "isSpaceFree",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.TicTacToe",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.TicTacToe",
        "peekOfCode": "def isSpaceFree(board, move):\n    # Return true if the passed move is free on the passed board.\n    return board[move] == ' '\ndef getPlayerMove(board):\n    # Let the player type in their move.\n    move = ' '\n    while move not in '1 2 3 4 5 6 7 8 9'.split() or not isSpaceFree(board, int(move)):\n        print('What is your next move? (1-9)')\n        move = input()\n    return int(move)",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.TicTacToe",
        "documentation": {}
    },
    {
        "label": "getPlayerMove",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.TicTacToe",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.TicTacToe",
        "peekOfCode": "def getPlayerMove(board):\n    # Let the player type in their move.\n    move = ' '\n    while move not in '1 2 3 4 5 6 7 8 9'.split() or not isSpaceFree(board, int(move)):\n        print('What is your next move? (1-9)')\n        move = input()\n    return int(move)\ndef chooseRandomMoveFromList(board, movesList):\n    # Returns a valid move from the passed list on the passed board.\n    # Returns None if there is no valid move.",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.TicTacToe",
        "documentation": {}
    },
    {
        "label": "chooseRandomMoveFromList",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.TicTacToe",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.TicTacToe",
        "peekOfCode": "def chooseRandomMoveFromList(board, movesList):\n    # Returns a valid move from the passed list on the passed board.\n    # Returns None if there is no valid move.\n    possibleMoves = []\n    for i in movesList:\n        if isSpaceFree(board, i):\n            possibleMoves.append(i)\n    if len(possibleMoves) != 0:\n        return random.choice(possibleMoves)\n    else:",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.TicTacToe",
        "documentation": {}
    },
    {
        "label": "getComputerMove",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.TicTacToe",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.TicTacToe",
        "peekOfCode": "def getComputerMove(board, computerLetter):\n    # Given a board and the computer's letter, determine where to move and return that move.\n    if computerLetter == 'X':\n        playerLetter = 'O'\n    else:\n        playerLetter = 'X'\n    # Here is our algorithm for our Tic Tac Toe AI:\n    # First, check if we can win in the next move\n    for i in range(1, 10):\n        copy = getBoardCopy(board)",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.TicTacToe",
        "documentation": {}
    },
    {
        "label": "isBoardFull",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.TicTacToe",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.TicTacToe",
        "peekOfCode": "def isBoardFull(board):\n    # Return True if every space on the board has been taken. Otherwise return False.\n    for i in range(1, 10):\n        if isSpaceFree(board, i):\n            return False\n    return True\nprint('Welcome to Tic Tac Toe!')\nwhile True:\n    # Reset the board\n    theBoard = [' '] * 10",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.TicTacToe",
        "documentation": {}
    },
    {
        "label": "TowerOfHanoi",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.Tower_of_hanoi",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.Tower_of_hanoi",
        "peekOfCode": "def TowerOfHanoi(n , source, destination, auxiliary):\n    if n==1:\n        print(\"Move disk 1 from source\",source,\"to destination\",destination)\n        return\n    TowerOfHanoi(n-1, source, auxiliary, destination)\n    print(\"Move disk\",n,\"from source\",source,\"to destination\",destination)\n    TowerOfHanoi(n-1, auxiliary, destination, source)\n# Driver code\nn = 4\nTowerOfHanoi(n,'A','B','C')",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.Tower_of_hanoi",
        "documentation": {}
    },
    {
        "label": "n",
        "kind": 5,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.Tower_of_hanoi",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.Tower_of_hanoi",
        "peekOfCode": "n = 4\nTowerOfHanoi(n,'A','B','C')",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.Tower_of_hanoi",
        "documentation": {}
    },
    {
        "label": "LeftMax",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.trapping_water",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.trapping_water",
        "peekOfCode": "def LeftMax(array,i):\n    left=array[i]\n    for j in range(i):\n        # left=max(left,array[j])\n        if left < array[j]:\n            left = array[j]\n        else:\n            left=left\n    return left\ndef RightMax(array,i):",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.trapping_water",
        "documentation": {}
    },
    {
        "label": "RightMax",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.trapping_water",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.trapping_water",
        "peekOfCode": "def RightMax(array,i):\n    right=array[i]\n    for j in range(i+1,len(array)):\n        # right=max(right,array[j])\n        if right < array[j]:\n            right = array[j]\n        else:\n            right=right\n    return right\ndef TrappingWater(array):",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.trapping_water",
        "documentation": {}
    },
    {
        "label": "TrappingWater",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.trapping_water",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.trapping_water",
        "peekOfCode": "def TrappingWater(array):\n    totalwater=0\n    for i in range(1,len(array)-1):\n        leftMax=LeftMax(array,i)\n        rightMax=RightMax(array,i)\n        totalwater=totalwater+(min(leftMax,rightMax)-array[i])\n    return totalwater\narray=[2,0,2]\nprint(TrappingWater(array))",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.trapping_water",
        "documentation": {}
    },
    {
        "label": "node",
        "kind": 6,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.traversals",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.traversals",
        "peekOfCode": "class node:\n    def __init__(self,val):\n        self.right=None\n        self.left=None\n        self.val = val\nroot = node(1)\nroot.left=node(2)\nroot.right=node(3)\nroot.left.right=node(5)\nroot.left.left=node(4)",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.traversals",
        "documentation": {}
    },
    {
        "label": "inorder_traversal",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.traversals",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.traversals",
        "peekOfCode": "def inorder_traversal(root):\n    if root:\n        inorder_traversal(root.left)\n        print(root.val)\n        inorder_traversal(root.right)\ndef preorder_traversal(root):\n    if root:\n        print(root.val)\n        preorder_traversal(root.left)\n        preorder_traversal(root.right)",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.traversals",
        "documentation": {}
    },
    {
        "label": "preorder_traversal",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.traversals",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.traversals",
        "peekOfCode": "def preorder_traversal(root):\n    if root:\n        print(root.val)\n        preorder_traversal(root.left)\n        preorder_traversal(root.right)\ndef postorder_traversal(root):\n    if root:\n        postorder_traversal(root.left)\n        postorder_traversal(root.right)\n        print(root.val)",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.traversals",
        "documentation": {}
    },
    {
        "label": "postorder_traversal",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.traversals",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.traversals",
        "peekOfCode": "def postorder_traversal(root):\n    if root:\n        postorder_traversal(root.left)\n        postorder_traversal(root.right)\n        print(root.val)\nprint(\"########################\")\nprint(\"inorder traversal: L N R \")\ninorder_traversal(root)\nprint(\"########################\")\nprint(\"preorder traversal: N L R \")",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.traversals",
        "documentation": {}
    },
    {
        "label": "root",
        "kind": 5,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.traversals",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.traversals",
        "peekOfCode": "root = node(1)\nroot.left=node(2)\nroot.right=node(3)\nroot.left.right=node(5)\nroot.left.left=node(4)\ndef inorder_traversal(root):\n    if root:\n        inorder_traversal(root.left)\n        print(root.val)\n        inorder_traversal(root.right)",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.traversals",
        "documentation": {}
    },
    {
        "label": "Node",
        "kind": 6,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.tree-level-order-print",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.tree-level-order-print",
        "peekOfCode": "class Node(object):\n    def __init__(self, value):\n        self.value = value\n        self.left = None\n        self.right = None\ndef traverse_levelorder(root):\n    if not root:\n        return\n    q = [root, True]  # Use True as sentinel for end of row\n    while len(q) > 0:",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.tree-level-order-print",
        "documentation": {}
    },
    {
        "label": "traverse_levelorder",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.tree-level-order-print",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.tree-level-order-print",
        "peekOfCode": "def traverse_levelorder(root):\n    if not root:\n        return\n    q = [root, True]  # Use True as sentinel for end of row\n    while len(q) > 0:\n        node = q.pop(0)\n        print node.value,\n        if node.left:\n            q.append(node.left)\n        if node.right:",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.tree-level-order-print",
        "documentation": {}
    },
    {
        "label": "Tree",
        "kind": 6,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.tree_creation",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.tree_creation",
        "peekOfCode": "class Tree:\n    def __init__(self,data):\n        self.data=data\n        self.children=[]\n        self.parent=None\n    def add_child(self,child):\n        child.parent=self\n        self.children.append(child)\n    def print_elements(self):\n        print(self.data)",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.tree_creation",
        "documentation": {}
    },
    {
        "label": "Triplet",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.TripletSearch",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.TripletSearch",
        "peekOfCode": "def Triplet(arr):\n    n=len(arr)\n    found=True\n    for i in range(n-1):\n        l=i+1\n        r=n-1\n        x=arr[i]\n        while l<r:\n            if arr[l]+arr[r]+x==0:\n                print(arr[l],arr[r],x)",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.TripletSearch",
        "documentation": {}
    },
    {
        "label": "Solution",
        "kind": 6,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.Union of two arrays",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.Union of two arrays",
        "peekOfCode": "class Solution:    \n    #Function to return the count of number of elements in union of two arrays.\n    def doUnion(self,a,n,b,m):\n        c=a+b\n        c.sort()\n        d=[]\n        for i in c:\n            if i not in d:\n                d.append(i)\n            else:",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.Union of two arrays",
        "documentation": {}
    },
    {
        "label": "Solution",
        "kind": 6,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.Union of two arrays",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.Union of two arrays",
        "peekOfCode": "class Solution:    \n    #Function to return the count of number of elements in union of two arrays.\n    def doUnion(self,a,n,b,m):\n        c=a+b\n        c.sort() #O(Mlog(M))+O(Nlog(N))\n        sample_dict={}\n        for i in c: #O(M)+O(N)\n            if i in sample_dict.keys():\n                sample_dict[i]+=1\n            else:",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.Union of two arrays",
        "documentation": {}
    },
    {
        "label": "wave",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.wave",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.wave",
        "peekOfCode": "def wave(arr,n):\n    arr.sort()\n    for i in range(0,n-1,2):\n        arr[i],arr[i+1]=arr[i+1],arr[i]\narr=[10, 90, 49, 2, 1, 5, 23]\nwave(arr,len(arr))\nfor i in range(len(arr)):\n    print(arr[i],end=\" \")",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.wave",
        "documentation": {}
    },
    {
        "label": "xor",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.xor",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.xor",
        "peekOfCode": "def xor(arr,n):\n    xor_val=0\n    for i in range(n):\n        xor_val=xor_val^arr[i]\n    return xor_val\narr=[3, 9, 12, 13, 15]\nn=len(arr)\nprint(xor(arr,n))",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.xor",
        "documentation": {}
    },
    {
        "label": "url",
        "kind": 5,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.YT_DOWN",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.YT_DOWN",
        "peekOfCode": "url = \"https://www.youtube.com/watch?v=OE7wUUpJw6I&list=PL2_aWCzGMAwLPEZrZIcNEq9ukGWPfLT4A\"\nvideo = pafy.new(url)\nprint(video.title)\nstream=pafy.new(url).streams\nbest=video.getbest()\nfor i in stream:\n    print(i)\nprint(best.resolution,best.extension)\nprint(best.url)\nbest.download(quiet=False)",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.YT_DOWN",
        "documentation": {}
    },
    {
        "label": "video",
        "kind": 5,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.YT_DOWN",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.YT_DOWN",
        "peekOfCode": "video = pafy.new(url)\nprint(video.title)\nstream=pafy.new(url).streams\nbest=video.getbest()\nfor i in stream:\n    print(i)\nprint(best.resolution,best.extension)\nprint(best.url)\nbest.download(quiet=False)",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.ALGO.__PYTHON.YT_DOWN",
        "documentation": {}
    },
    {
        "label": "sum_arr",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.Arrays.python.sum-arr-dir.sum-arr",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.Arrays.python.sum-arr-dir.sum-arr",
        "peekOfCode": "def sum_arr(n):\n    res = 0\n    for x in n:\n        res += x\n    return res\nnums = [52345,746587,98589,54398,9348,45887,49856]\ntest = sum_arr(nums) \n#sum() is Pythons built in method of adding all the elements in a list\nif test == sum(nums):\n    print(\"Sum of arr: {}\".format(test))",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.Arrays.python.sum-arr-dir.sum-arr",
        "documentation": {}
    },
    {
        "label": "nums",
        "kind": 5,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.Arrays.python.sum-arr-dir.sum-arr",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.Arrays.python.sum-arr-dir.sum-arr",
        "peekOfCode": "nums = [52345,746587,98589,54398,9348,45887,49856]\ntest = sum_arr(nums) \n#sum() is Pythons built in method of adding all the elements in a list\nif test == sum(nums):\n    print(\"Sum of arr: {}\".format(test))\nelse:\n    print(\"Func dosen't work!\")\n# [Running] python -u \"c:\\0-a-A-October\\00-weeks\\08-my-website\\Stable\\Public\\2-content\\Data-Structures\\DS-and-Algorithms-Prac\\In-Progress\\python\\sum-arr-dir\\sum-arr.py\"\n# Sum of arr: 1057010",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.Arrays.python.sum-arr-dir.sum-arr",
        "documentation": {}
    },
    {
        "label": "test",
        "kind": 5,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.Arrays.python.sum-arr-dir.sum-arr",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.Arrays.python.sum-arr-dir.sum-arr",
        "peekOfCode": "test = sum_arr(nums) \n#sum() is Pythons built in method of adding all the elements in a list\nif test == sum(nums):\n    print(\"Sum of arr: {}\".format(test))\nelse:\n    print(\"Func dosen't work!\")\n# [Running] python -u \"c:\\0-a-A-October\\00-weeks\\08-my-website\\Stable\\Public\\2-content\\Data-Structures\\DS-and-Algorithms-Prac\\In-Progress\\python\\sum-arr-dir\\sum-arr.py\"\n# Sum of arr: 1057010",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.Arrays.python.sum-arr-dir.sum-arr",
        "documentation": {}
    },
    {
        "label": "avgSums",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.Arrays.python.sum-avg.avg",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.Arrays.python.sum-avg.avg",
        "peekOfCode": "def avgSums(a,b,c):\n\tsummingUp = sum(a) + sum(b) + sum(c)\n\tsummed = summingUp / 3\n\treturn(summed)\nprint(avgSums(m,n,q))\n# [Running] python -u \"c:\\0-a-A-October\\00-weeks\\08-my-website\\Stable\\Public\\2-content\\Data-Structures\\DS-and-Algorithms-Prac\\DS-n-Algos\\Arrays\\python\\sum-avg\\avg.py\"\n# 2892.6666666666665\n# \n# [Done] exited with code=0 in 0.186 seconds",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.Arrays.python.sum-avg.avg",
        "documentation": {}
    },
    {
        "label": "m",
        "kind": 5,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.Arrays.python.sum-avg.avg",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.Arrays.python.sum-avg.avg",
        "peekOfCode": "m = [1,43,656,8,54,908,4,5,23,78,435,89,45,476,89]\nn = [234,56,90,675,56,786,90,564,8,657,87,64,354,2,75]\nq = [34,76,76,564,34,32,16,67,25,98,90,345,235,64,134,76]\ndef avgSums(a,b,c):\n\tsummingUp = sum(a) + sum(b) + sum(c)\n\tsummed = summingUp / 3\n\treturn(summed)\nprint(avgSums(m,n,q))\n# [Running] python -u \"c:\\0-a-A-October\\00-weeks\\08-my-website\\Stable\\Public\\2-content\\Data-Structures\\DS-and-Algorithms-Prac\\DS-n-Algos\\Arrays\\python\\sum-avg\\avg.py\"\n# 2892.6666666666665",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.Arrays.python.sum-avg.avg",
        "documentation": {}
    },
    {
        "label": "n",
        "kind": 5,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.Arrays.python.sum-avg.avg",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.Arrays.python.sum-avg.avg",
        "peekOfCode": "n = [234,56,90,675,56,786,90,564,8,657,87,64,354,2,75]\nq = [34,76,76,564,34,32,16,67,25,98,90,345,235,64,134,76]\ndef avgSums(a,b,c):\n\tsummingUp = sum(a) + sum(b) + sum(c)\n\tsummed = summingUp / 3\n\treturn(summed)\nprint(avgSums(m,n,q))\n# [Running] python -u \"c:\\0-a-A-October\\00-weeks\\08-my-website\\Stable\\Public\\2-content\\Data-Structures\\DS-and-Algorithms-Prac\\DS-n-Algos\\Arrays\\python\\sum-avg\\avg.py\"\n# 2892.6666666666665\n# ",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.Arrays.python.sum-avg.avg",
        "documentation": {}
    },
    {
        "label": "q",
        "kind": 5,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.Arrays.python.sum-avg.avg",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.Arrays.python.sum-avg.avg",
        "peekOfCode": "q = [34,76,76,564,34,32,16,67,25,98,90,345,235,64,134,76]\ndef avgSums(a,b,c):\n\tsummingUp = sum(a) + sum(b) + sum(c)\n\tsummed = summingUp / 3\n\treturn(summed)\nprint(avgSums(m,n,q))\n# [Running] python -u \"c:\\0-a-A-October\\00-weeks\\08-my-website\\Stable\\Public\\2-content\\Data-Structures\\DS-and-Algorithms-Prac\\DS-n-Algos\\Arrays\\python\\sum-avg\\avg.py\"\n# 2892.6666666666665\n# \n# [Done] exited with code=0 in 0.186 seconds",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.Arrays.python.sum-avg.avg",
        "documentation": {}
    },
    {
        "label": "\tsummingUp",
        "kind": 5,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.Arrays.python.sum-avg.avg",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.Arrays.python.sum-avg.avg",
        "peekOfCode": "\tsummingUp = sum(a) + sum(b) + sum(c)\n\tsummed = summingUp / 3\n\treturn(summed)\nprint(avgSums(m,n,q))\n# [Running] python -u \"c:\\0-a-A-October\\00-weeks\\08-my-website\\Stable\\Public\\2-content\\Data-Structures\\DS-and-Algorithms-Prac\\DS-n-Algos\\Arrays\\python\\sum-avg\\avg.py\"\n# 2892.6666666666665\n# \n# [Done] exited with code=0 in 0.186 seconds",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.Arrays.python.sum-avg.avg",
        "documentation": {}
    },
    {
        "label": "\tsummed",
        "kind": 5,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.Arrays.python.sum-avg.avg",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.Arrays.python.sum-avg.avg",
        "peekOfCode": "\tsummed = summingUp / 3\n\treturn(summed)\nprint(avgSums(m,n,q))\n# [Running] python -u \"c:\\0-a-A-October\\00-weeks\\08-my-website\\Stable\\Public\\2-content\\Data-Structures\\DS-and-Algorithms-Prac\\DS-n-Algos\\Arrays\\python\\sum-avg\\avg.py\"\n# 2892.6666666666665\n# \n# [Done] exited with code=0 in 0.186 seconds",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.Arrays.python.sum-avg.avg",
        "documentation": {}
    },
    {
        "label": "rev_word",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.Strings.python.reverse-word.rev-word",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.Strings.python.reverse-word.rev-word",
        "peekOfCode": "def rev_word(inStr:str)->str:\n    return ' '.join(inStr.split()[::-1])\nprint(rev_word(\"Python is kinda cool\"))\n# Print Output:\n# cool kinda is Python\n# Variables:\n# {}",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.Strings.python.reverse-word.rev-word",
        "documentation": {}
    },
    {
        "label": "split_string",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.Strings.python.split-string.split-string",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.Strings.python.split-string.split-string",
        "peekOfCode": "def split_string(string:str, break_on:str = \" \")->list:\n    # A list is similar to an array but apparently not the same\n    split_words = []\n    last_index = 0\n    for index, char in enumerate(string):\n        if char == break_on:\n            split_words.append(string[last_index:index])\n            last_index = index + 1\n        elif index + 1 == len(string):\n            split_words.append(string[last_index: index + 1])",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos.Strings.python.split-string.split-string",
        "documentation": {}
    },
    {
        "label": "binarystr",
        "kind": 5,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos._Extra-Practice.30-days-of-code-master.day10_binary",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos._Extra-Practice.30-days-of-code-master.day10_binary",
        "peekOfCode": "binarystr = max([len(x) for x in bin(int(input()))[2:].split('0')])\nprint(binarystr)",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos._Extra-Practice.30-days-of-code-master.day10_binary",
        "documentation": {}
    },
    {
        "label": "matrix",
        "kind": 5,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos._Extra-Practice.30-days-of-code-master.day11_2darrays",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos._Extra-Practice.30-days-of-code-master.day11_2darrays",
        "peekOfCode": "matrix = []\nfor x in range(6):\n    matrix.append([int(x) for x in input().split()])\nhourglass = []\nfor i,row in enumerate(matrix):\n    if i >= (len(matrix) -2):\n        break\n    for j,e in enumerate(row):\n        if j >= (len(row) - 2):\n            break",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos._Extra-Practice.30-days-of-code-master.day11_2darrays",
        "documentation": {}
    },
    {
        "label": "hourglass",
        "kind": 5,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos._Extra-Practice.30-days-of-code-master.day11_2darrays",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos._Extra-Practice.30-days-of-code-master.day11_2darrays",
        "peekOfCode": "hourglass = []\nfor i,row in enumerate(matrix):\n    if i >= (len(matrix) -2):\n        break\n    for j,e in enumerate(row):\n        if j >= (len(row) - 2):\n            break\n        templist = []\n        templist = templist + [matrix[i][j], matrix[i][j+1], matrix[i][j+2]]\n        templist = templist + [matrix[i+1][j+1]]",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos._Extra-Practice.30-days-of-code-master.day11_2darrays",
        "documentation": {}
    },
    {
        "label": "hourglasssums",
        "kind": 5,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos._Extra-Practice.30-days-of-code-master.day11_2darrays",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos._Extra-Practice.30-days-of-code-master.day11_2darrays",
        "peekOfCode": "hourglasssums = [sum(eachglass) for eachglass in hourglass]\nprint(max(hourglasssums))",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos._Extra-Practice.30-days-of-code-master.day11_2darrays",
        "documentation": {}
    },
    {
        "label": "Student",
        "kind": 6,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos._Extra-Practice.30-days-of-code-master.day12_inheritance",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos._Extra-Practice.30-days-of-code-master.day12_inheritance",
        "peekOfCode": "class Student(Person):\n    def __init__(self, firstName, lastName, idNumber, scores):\n        Person.__init__(self, firstName, lastName, idNumber)\n        self.scores = scores\n    def calculate(self):\n        average = sum(scores) / len(scores)\n        if 90 <= average <= 100:\n            return \"O\"\n        if 80 <= average <= 90:\n            return \"E\"",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos._Extra-Practice.30-days-of-code-master.day12_inheritance",
        "documentation": {}
    },
    {
        "label": "Book",
        "kind": 6,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos._Extra-Practice.30-days-of-code-master.day13_abstractclasses",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos._Extra-Practice.30-days-of-code-master.day13_abstractclasses",
        "peekOfCode": "class Book(object, metaclass=ABCMeta):\n    def __init__(self,title,author):\n        self.title=title\n        self.author=author   \n    @abstractmethod\n    def display(): pass\nclass MyBook(Book):\ntitle=input()\nauthor=input()\nprice=int(input())",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos._Extra-Practice.30-days-of-code-master.day13_abstractclasses",
        "documentation": {}
    },
    {
        "label": "MyBook",
        "kind": 6,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos._Extra-Practice.30-days-of-code-master.day13_abstractclasses",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos._Extra-Practice.30-days-of-code-master.day13_abstractclasses",
        "peekOfCode": "class MyBook(Book):\ntitle=input()\nauthor=input()\nprice=int(input())\nnew_novel=MyBook(title,author,price)\nnew_novel.display()",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos._Extra-Practice.30-days-of-code-master.day13_abstractclasses",
        "documentation": {}
    },
    {
        "label": "i",
        "kind": 5,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos._Extra-Practice.30-days-of-code-master.day1_datatypes",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos._Extra-Practice.30-days-of-code-master.day1_datatypes",
        "peekOfCode": "i = 4\nd = 4.0\ns = 'HackerRank'\n# Declare second integer, double, and String variables.\n# Read and save an integer, double, and String to your variables.\ni2 = int(input())\nd2 = float(input())\ns2 = str(input())\n# Print the sum of both integer variables on a new line.\nprint(i + i2)",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos._Extra-Practice.30-days-of-code-master.day1_datatypes",
        "documentation": {}
    },
    {
        "label": "d",
        "kind": 5,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos._Extra-Practice.30-days-of-code-master.day1_datatypes",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos._Extra-Practice.30-days-of-code-master.day1_datatypes",
        "peekOfCode": "d = 4.0\ns = 'HackerRank'\n# Declare second integer, double, and String variables.\n# Read and save an integer, double, and String to your variables.\ni2 = int(input())\nd2 = float(input())\ns2 = str(input())\n# Print the sum of both integer variables on a new line.\nprint(i + i2)\n# Print the sum of the double variables on a new line.",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos._Extra-Practice.30-days-of-code-master.day1_datatypes",
        "documentation": {}
    },
    {
        "label": "s",
        "kind": 5,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos._Extra-Practice.30-days-of-code-master.day1_datatypes",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos._Extra-Practice.30-days-of-code-master.day1_datatypes",
        "peekOfCode": "s = 'HackerRank'\n# Declare second integer, double, and String variables.\n# Read and save an integer, double, and String to your variables.\ni2 = int(input())\nd2 = float(input())\ns2 = str(input())\n# Print the sum of both integer variables on a new line.\nprint(i + i2)\n# Print the sum of the double variables on a new line.\nprint(d + d2)",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos._Extra-Practice.30-days-of-code-master.day1_datatypes",
        "documentation": {}
    },
    {
        "label": "i2",
        "kind": 5,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos._Extra-Practice.30-days-of-code-master.day1_datatypes",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos._Extra-Practice.30-days-of-code-master.day1_datatypes",
        "peekOfCode": "i2 = int(input())\nd2 = float(input())\ns2 = str(input())\n# Print the sum of both integer variables on a new line.\nprint(i + i2)\n# Print the sum of the double variables on a new line.\nprint(d + d2)\n# Concatenate and print the String variables on a new line\n# The 's' variable above should be printed first.\nprint(s + s2)",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos._Extra-Practice.30-days-of-code-master.day1_datatypes",
        "documentation": {}
    },
    {
        "label": "d2",
        "kind": 5,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos._Extra-Practice.30-days-of-code-master.day1_datatypes",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos._Extra-Practice.30-days-of-code-master.day1_datatypes",
        "peekOfCode": "d2 = float(input())\ns2 = str(input())\n# Print the sum of both integer variables on a new line.\nprint(i + i2)\n# Print the sum of the double variables on a new line.\nprint(d + d2)\n# Concatenate and print the String variables on a new line\n# The 's' variable above should be printed first.\nprint(s + s2)",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos._Extra-Practice.30-days-of-code-master.day1_datatypes",
        "documentation": {}
    },
    {
        "label": "s2",
        "kind": 5,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos._Extra-Practice.30-days-of-code-master.day1_datatypes",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos._Extra-Practice.30-days-of-code-master.day1_datatypes",
        "peekOfCode": "s2 = str(input())\n# Print the sum of both integer variables on a new line.\nprint(i + i2)\n# Print the sum of the double variables on a new line.\nprint(d + d2)\n# Concatenate and print the String variables on a new line\n# The 's' variable above should be printed first.\nprint(s + s2)",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos._Extra-Practice.30-days-of-code-master.day1_datatypes",
        "documentation": {}
    },
    {
        "label": "mealCost",
        "kind": 5,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos._Extra-Practice.30-days-of-code-master.day2_operators",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos._Extra-Practice.30-days-of-code-master.day2_operators",
        "peekOfCode": "mealCost = float(input())\ntipPercent = int(input())\ntaxPercent = int(input())\ntotalCost = mealCost + (mealCost * (tipPercent/100)) + (mealCost * (taxPercent/100))\nprint('The total meal cost is', round(totalCost), 'dollars.')",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos._Extra-Practice.30-days-of-code-master.day2_operators",
        "documentation": {}
    },
    {
        "label": "tipPercent",
        "kind": 5,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos._Extra-Practice.30-days-of-code-master.day2_operators",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos._Extra-Practice.30-days-of-code-master.day2_operators",
        "peekOfCode": "tipPercent = int(input())\ntaxPercent = int(input())\ntotalCost = mealCost + (mealCost * (tipPercent/100)) + (mealCost * (taxPercent/100))\nprint('The total meal cost is', round(totalCost), 'dollars.')",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos._Extra-Practice.30-days-of-code-master.day2_operators",
        "documentation": {}
    },
    {
        "label": "taxPercent",
        "kind": 5,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos._Extra-Practice.30-days-of-code-master.day2_operators",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos._Extra-Practice.30-days-of-code-master.day2_operators",
        "peekOfCode": "taxPercent = int(input())\ntotalCost = mealCost + (mealCost * (tipPercent/100)) + (mealCost * (taxPercent/100))\nprint('The total meal cost is', round(totalCost), 'dollars.')",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos._Extra-Practice.30-days-of-code-master.day2_operators",
        "documentation": {}
    },
    {
        "label": "totalCost",
        "kind": 5,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos._Extra-Practice.30-days-of-code-master.day2_operators",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos._Extra-Practice.30-days-of-code-master.day2_operators",
        "peekOfCode": "totalCost = mealCost + (mealCost * (tipPercent/100)) + (mealCost * (taxPercent/100))\nprint('The total meal cost is', round(totalCost), 'dollars.')",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos._Extra-Practice.30-days-of-code-master.day2_operators",
        "documentation": {}
    },
    {
        "label": "Person",
        "kind": 6,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos._Extra-Practice.30-days-of-code-master.day4_classvsinstance",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos._Extra-Practice.30-days-of-code-master.day4_classvsinstance",
        "peekOfCode": "class Person:\n    def __init__(self,initialAge):\n        # Add some more code to run some checks on initialAge\n        if initialAge < 0:\n            self.age = 0\n            print('Age is not valid, setting age to 0.')\n        else:\n            self.age = initialAge\n    def amIOld(self):\n        # Do some computations in here and print out the correct statement to the console",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos._Extra-Practice.30-days-of-code-master.day4_classvsinstance",
        "documentation": {}
    },
    {
        "label": "t",
        "kind": 5,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos._Extra-Practice.30-days-of-code-master.day4_classvsinstance",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos._Extra-Practice.30-days-of-code-master.day4_classvsinstance",
        "peekOfCode": "t = int(input())\nfor i in range(0, t):\n    age = int(input())         \n    p = Person(age)  \n    p.amIOld()\n    for j in range(0, 3):\n        p.yearPasses()       \n    p.amIOld()\n    print(\"\")\nclass Person:",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos._Extra-Practice.30-days-of-code-master.day4_classvsinstance",
        "documentation": {}
    },
    {
        "label": "n",
        "kind": 5,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos._Extra-Practice.30-days-of-code-master.day5_loops",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos._Extra-Practice.30-days-of-code-master.day5_loops",
        "peekOfCode": "n = int(input().strip())\nfor i in range(10):\n    print(n,'x',i+1,'=',(n*(i+1)))",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos._Extra-Practice.30-days-of-code-master.day5_loops",
        "documentation": {}
    },
    {
        "label": "t",
        "kind": 5,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos._Extra-Practice.30-days-of-code-master.day6_review",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos._Extra-Practice.30-days-of-code-master.day6_review",
        "peekOfCode": "t = int(input())\nfor i in range(t):\n    s = input()\n    s1 = ''.join([s[i] for i in range(len(s)) if i%2 == 0])\n    s2 = ''.join([s[i] for i in range(len(s)) if i%2 != 0])\n    print(s1, s2)",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos._Extra-Practice.30-days-of-code-master.day6_review",
        "documentation": {}
    },
    {
        "label": "n",
        "kind": 5,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos._Extra-Practice.30-days-of-code-master.day7_arrays",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos._Extra-Practice.30-days-of-code-master.day7_arrays",
        "peekOfCode": "n = int(input().strip())\narr = [int(arr_temp) for arr_temp in input().strip().split(' ')]\narr.reverse()\narrstring = ' '.join(str(e) for e in arr)\nprint(arrstring)",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos._Extra-Practice.30-days-of-code-master.day7_arrays",
        "documentation": {}
    },
    {
        "label": "arr",
        "kind": 5,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos._Extra-Practice.30-days-of-code-master.day7_arrays",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos._Extra-Practice.30-days-of-code-master.day7_arrays",
        "peekOfCode": "arr = [int(arr_temp) for arr_temp in input().strip().split(' ')]\narr.reverse()\narrstring = ' '.join(str(e) for e in arr)\nprint(arrstring)",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos._Extra-Practice.30-days-of-code-master.day7_arrays",
        "documentation": {}
    },
    {
        "label": "arrstring",
        "kind": 5,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos._Extra-Practice.30-days-of-code-master.day7_arrays",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos._Extra-Practice.30-days-of-code-master.day7_arrays",
        "peekOfCode": "arrstring = ' '.join(str(e) for e in arr)\nprint(arrstring)",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos._Extra-Practice.30-days-of-code-master.day7_arrays",
        "documentation": {}
    },
    {
        "label": "getphonebook",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos._Extra-Practice.30-days-of-code-master.day8_dictionariesmaps",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos._Extra-Practice.30-days-of-code-master.day8_dictionariesmaps",
        "peekOfCode": "def getphonebook(n):\n    phonebook = {}\n    for x in range(n):\n        line = input().strip().split(' ')\n        name = line[0]\n        number = line[1]\n        phonebook[name]=number\n    return phonebook\nif __name__ == '__main__':\n    numberofentries = int(input())",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos._Extra-Practice.30-days-of-code-master.day8_dictionariesmaps",
        "documentation": {}
    },
    {
        "label": "factorial",
        "kind": 2,
        "importPath": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos._Extra-Practice.30-days-of-code-master.day9_recursion",
        "description": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos._Extra-Practice.30-days-of-code-master.day9_recursion",
        "peekOfCode": "def factorial(n):\n    if n <= 1:\n        return 1\n    else:\n        return n * factorial(n-1)\nif __name__ == '__main__':\n    n = factorial(int(input()))\n    print(n)",
        "detail": "DS_ALGO.DS-ALGO-OFFICIAL.CONTENT.DS-n-Algos._Extra-Practice.30-days-of-code-master.day9_recursion",
        "documentation": {}
    },
    {
        "label": "get_available_methods",
        "kind": 2,
        "importPath": "gists.aws_services",
        "description": "gists.aws_services",
        "peekOfCode": "def get_available_methods(service):\n    client = boto3.client(service)\n    all_attributes = dir(client)\n    available_methods = [attribute for attribute in all_attributes if callable(getattr(client, attribute))]\n    available_methods = [i for i in available_methods if not i.startswith('_')]\n    return available_methods\nwith open('aws_services.csv', 'w') as file:\n    writer = csv.writer(file)\n    writer.writerow(['ranking', 'method', 'service'])\n    counter = 0",
        "detail": "gists.aws_services",
        "documentation": {}
    },
    {
        "label": "emoji_model",
        "kind": 5,
        "importPath": "gists.deepmoji_usage",
        "description": "gists.deepmoji_usage",
        "peekOfCode": "emoji_model = DeepMoji()\n# Read a file containing user opinions\ndf = pd.read_csv('https://bit.ly/2VbfNiM')\n# Predict the emojis for the open-ended text\nemojis = emoji_model.predict(df['text'])",
        "detail": "gists.deepmoji_usage",
        "documentation": {}
    },
    {
        "label": "df",
        "kind": 5,
        "importPath": "gists.deepmoji_usage",
        "description": "gists.deepmoji_usage",
        "peekOfCode": "df = pd.read_csv('https://bit.ly/2VbfNiM')\n# Predict the emojis for the open-ended text\nemojis = emoji_model.predict(df['text'])",
        "detail": "gists.deepmoji_usage",
        "documentation": {}
    },
    {
        "label": "emojis",
        "kind": 5,
        "importPath": "gists.deepmoji_usage",
        "description": "gists.deepmoji_usage",
        "peekOfCode": "emojis = emoji_model.predict(df['text'])",
        "detail": "gists.deepmoji_usage",
        "documentation": {}
    },
    {
        "label": "EmojiCloud",
        "kind": 6,
        "importPath": "gists.emoji_cloud",
        "description": "gists.emoji_cloud",
        "peekOfCode": "class EmojiCloud:\n    def __init__(self,\n                 font_path='Symbola.ttf',\n                 color='yellow'):\n        self.font_path = font_path\n        self.color = color\n        self.word_cloud = self.initialize_wordcloud()\n        self.emoji_probability = None\n    def initialize_wordcloud(self):\n        word_cloud = WordCloud(font_path=self.font_path,",
        "detail": "gists.emoji_cloud",
        "documentation": {}
    },
    {
        "label": "EmojiCloud",
        "kind": 6,
        "importPath": "gists.emoji_cloud_class",
        "description": "gists.emoji_cloud_class",
        "peekOfCode": "class EmojiCloud:\n    def __init__(self,\n                 font_path='Symbola.ttf',\n                 color='yellow'):\n        self.font_path = font_path\n        self.color = color\n        self.word_cloud = self.initialize_wordcloud()\n        self.emoji_probability = None\n    def initialize_wordcloud(self):\n        word_cloud = WordCloud(font_path=self.font_path,",
        "detail": "gists.emoji_cloud_class",
        "documentation": {}
    },
    {
        "label": "emoji_cloud",
        "kind": 5,
        "importPath": "gists.generate_emoji_cloud",
        "description": "gists.generate_emoji_cloud",
        "peekOfCode": "emoji_cloud = EmojiCloud(font_path='./Symbola.ttf', color='yellow')\nemoji_cloud.generate(emojis)",
        "detail": "gists.generate_emoji_cloud",
        "documentation": {}
    },
    {
        "label": "determine_pip_install_arguments",
        "kind": 2,
        "importPath": "gists.get-pp",
        "description": "gists.get-pp",
        "peekOfCode": "def determine_pip_install_arguments():\n    implicit_pip = True\n    implicit_setuptools = True\n    implicit_wheel = True\n    # Check if the user has requested us not to install setuptools\n    if \"--no-setuptools\" in sys.argv or os.environ.get(\"PIP_NO_SETUPTOOLS\"):\n        args = [x for x in sys.argv[1:] if x != \"--no-setuptools\"]\n        implicit_setuptools = False\n    else:\n        args = sys.argv[1:]",
        "detail": "gists.get-pp",
        "documentation": {}
    },
    {
        "label": "monkeypatch_for_cert",
        "kind": 2,
        "importPath": "gists.get-pp",
        "description": "gists.get-pp",
        "peekOfCode": "def monkeypatch_for_cert(tmpdir):\n    \"\"\"Patches `pip install` to provide default certificate with the lowest priority.\n    This ensures that the bundled certificates are used unless the user specifies a\n    custom cert via any of pip's option passing mechanisms (config, env-var, CLI).\n    A monkeypatch is the easiest way to achieve this, without messing too much with\n    the rest of pip's internals.\n    \"\"\"\n    from pip._internal.commands.install import InstallCommand\n    # We want to be using the internal certificates.\n    cert_path = os.path.join(tmpdir, \"cacert.pem\")",
        "detail": "gists.get-pp",
        "documentation": {}
    },
    {
        "label": "bootstrap",
        "kind": 2,
        "importPath": "gists.get-pp",
        "description": "gists.get-pp",
        "peekOfCode": "def bootstrap(tmpdir):\n    monkeypatch_for_cert(tmpdir)\n    # Execute the included pip and use it to install the latest pip and\n    # setuptools from PyPI\n    from pip._internal.cli.main import main as pip_entry_point\n    args = determine_pip_install_arguments()\n    sys.exit(pip_entry_point(args))\ndef main():\n    tmpdir = None\n    try:",
        "detail": "gists.get-pp",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "gists.get-pp",
        "description": "gists.get-pp",
        "peekOfCode": "def main():\n    tmpdir = None\n    try:\n        # Create a temporary working directory\n        tmpdir = tempfile.mkdtemp()\n        # Unpack the zipfile into the temporary directory\n        pip_zip = os.path.join(tmpdir, \"pip.zip\")\n        with open(pip_zip, \"wb\") as fp:\n            fp.write(b85decode(DATA.replace(b\"\\n\", b\"\")))\n        # Add the zipfile to sys.path so that we can import it",
        "detail": "gists.get-pp",
        "documentation": {}
    },
    {
        "label": "this_python",
        "kind": 5,
        "importPath": "gists.get-pp",
        "description": "gists.get-pp",
        "peekOfCode": "this_python = sys.version_info[:2]\nmin_version = (3, 6)\nif this_python < min_version:\n    message_parts = [\n        \"This script does not work on Python {}.{}\".format(*this_python),\n        \"The minimum supported Python version is {}.{}.\".format(*min_version),\n        \"Please use https://bootstrap.pypa.io/pip/{}.{}/get-pip.py instead.\".format(\n            *this_python),\n    ]\n    print(\"ERROR: \" + \" \".join(message_parts))",
        "detail": "gists.get-pp",
        "documentation": {}
    },
    {
        "label": "min_version",
        "kind": 5,
        "importPath": "gists.get-pp",
        "description": "gists.get-pp",
        "peekOfCode": "min_version = (3, 6)\nif this_python < min_version:\n    message_parts = [\n        \"This script does not work on Python {}.{}\".format(*this_python),\n        \"The minimum supported Python version is {}.{}.\".format(*min_version),\n        \"Please use https://bootstrap.pypa.io/pip/{}.{}/get-pip.py instead.\".format(\n            *this_python),\n    ]\n    print(\"ERROR: \" + \" \".join(message_parts))\n    sys.exit(1)",
        "detail": "gists.get-pp",
        "documentation": {}
    },
    {
        "label": "DATA",
        "kind": 5,
        "importPath": "gists.get-pp",
        "description": "gists.get-pp",
        "peekOfCode": "DATA = b\"\"\"\nP)h>@6aWAK2mt3s+ETYTE!+SB003|S000jF003}la4%n9X>MtBUtcb8c|DLpOT$1Ah41?-hIp`nx}hp\nm3l+Qwf~W^?rG#xVX$F$rWoBZ@zju=ohlODuk8d8Y;n0JQk^C8`kAW3FNOTQfQ7L%W8B><O$dW!~346\n%yH+EwmGGk1Q4fKxu%JEtDpTT3kGmz$HBH|8K3*;~{52AcL=5Y4{<aIV?S@zSCKzhzkDspne>-ReZ-;\nL0t^9oI17zE)oLZo;r5H237;3aejQZYppYi8hEvbwsa>shE#9d)t>L4;N{%C0ERr0sCBRp^U2Mpq<eK\n_UZ6v3-1gvP-ggH&Z{!Vap|*9W)^=dgU>Oq{>oUd0`hL@-+&h4($KMxuo3u0Z>Z=1QY-O00;o*M%q#%\n8{@xi0ssK61ONaJ0001RX>c!JUu|J&ZeL$6aCu!*!ET%|5WVviBXU@FMMw_qp;5O|rCxIBA*z%^Qy~|\nI#aghDZI*1mzHbcdCgFtbH*em&nbG}VT_EcdJ^%Uh<#$rfXmjvMazjtt+Y{4fL(0@tjn1(F!nz|6RBO\njou<lHavpt2DsnN~{0?3^aZW|#k1{K<zbVGw<F9gAoI$2%Q=!IwHz3?Ga8yfULmF;_^_Efc89djgN{>\nLCQKB%tCsnf_O;(TkT9D!5I2G1vZ<eHSH;T&3P=(dl1Ul+n}iN0$4eg8-DWoeqjlH$Ojn(A!3eMku3i",
        "detail": "gists.get-pp",
        "documentation": {}
    },
    {
        "label": "payload",
        "kind": 5,
        "importPath": "gists.neb",
        "description": "gists.neb",
        "peekOfCode": "payload = {\n    'keyword': '20403105',\n    'slug': 'SearchResult'\n}\nresponse = requests.post('http://www.neb.gov.np/result/search', data=payload)\nsoup = BeautifulSoup(response, 'lxml')\n# Gives output like: Congratulation!! FirstName LastName ,\nh1_text = soup.find('h1', {'class': 'text-success text-center'}).text\n# Extract only name from that text\nprint (h1_text.lstrip('Congratulation!! ').rstrip(', '))",
        "detail": "gists.neb",
        "documentation": {}
    },
    {
        "label": "response",
        "kind": 5,
        "importPath": "gists.neb",
        "description": "gists.neb",
        "peekOfCode": "response = requests.post('http://www.neb.gov.np/result/search', data=payload)\nsoup = BeautifulSoup(response, 'lxml')\n# Gives output like: Congratulation!! FirstName LastName ,\nh1_text = soup.find('h1', {'class': 'text-success text-center'}).text\n# Extract only name from that text\nprint (h1_text.lstrip('Congratulation!! ').rstrip(', '))",
        "detail": "gists.neb",
        "documentation": {}
    },
    {
        "label": "soup",
        "kind": 5,
        "importPath": "gists.neb",
        "description": "gists.neb",
        "peekOfCode": "soup = BeautifulSoup(response, 'lxml')\n# Gives output like: Congratulation!! FirstName LastName ,\nh1_text = soup.find('h1', {'class': 'text-success text-center'}).text\n# Extract only name from that text\nprint (h1_text.lstrip('Congratulation!! ').rstrip(', '))",
        "detail": "gists.neb",
        "documentation": {}
    },
    {
        "label": "h1_text",
        "kind": 5,
        "importPath": "gists.neb",
        "description": "gists.neb",
        "peekOfCode": "h1_text = soup.find('h1', {'class': 'text-success text-center'}).text\n# Extract only name from that text\nprint (h1_text.lstrip('Congratulation!! ').rstrip(', '))",
        "detail": "gists.neb",
        "documentation": {}
    },
    {
        "label": "output",
        "kind": 5,
        "importPath": "gists.scan_network",
        "description": "gists.scan_network",
        "peekOfCode": "output = os.popen('arp -a').read().splitlines()\nips = [re.search(r'\\d+\\.\\d+\\d+.\\d+.\\d+', b).group(0) for b in output]\nfor ip in ips:\n\tprint(os.popen('nmblookup -A {}'.format(ip)).read())",
        "detail": "gists.scan_network",
        "documentation": {}
    },
    {
        "label": "ips",
        "kind": 5,
        "importPath": "gists.scan_network",
        "description": "gists.scan_network",
        "peekOfCode": "ips = [re.search(r'\\d+\\.\\d+\\d+.\\d+.\\d+', b).group(0) for b in output]\nfor ip in ips:\n\tprint(os.popen('nmblookup -A {}'.format(ip)).read())",
        "detail": "gists.scan_network",
        "documentation": {}
    },
    {
        "label": "fp",
        "kind": 5,
        "importPath": "gists.tldr",
        "description": "gists.tldr",
        "peekOfCode": "fp = open(sys.argv[1], 'rb')\nparser = PDFParser(fp)\ndoc = PDFDocument(parser)\noutlines = doc.get_outlines()\nfor (level, title, dest, a, se) in outlines:\n    print ' ' * (level - 1) + title",
        "detail": "gists.tldr",
        "documentation": {}
    },
    {
        "label": "parser",
        "kind": 5,
        "importPath": "gists.tldr",
        "description": "gists.tldr",
        "peekOfCode": "parser = PDFParser(fp)\ndoc = PDFDocument(parser)\noutlines = doc.get_outlines()\nfor (level, title, dest, a, se) in outlines:\n    print ' ' * (level - 1) + title",
        "detail": "gists.tldr",
        "documentation": {}
    },
    {
        "label": "doc",
        "kind": 5,
        "importPath": "gists.tldr",
        "description": "gists.tldr",
        "peekOfCode": "doc = PDFDocument(parser)\noutlines = doc.get_outlines()\nfor (level, title, dest, a, se) in outlines:\n    print ' ' * (level - 1) + title",
        "detail": "gists.tldr",
        "documentation": {}
    },
    {
        "label": "outlines",
        "kind": 5,
        "importPath": "gists.tldr",
        "description": "gists.tldr",
        "peekOfCode": "outlines = doc.get_outlines()\nfor (level, title, dest, a, se) in outlines:\n    print ' ' * (level - 1) + title",
        "detail": "gists.tldr",
        "documentation": {}
    },
    {
        "label": "Version",
        "kind": 6,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.release_tools.update_versions",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.release_tools.update_versions",
        "peekOfCode": "class Version(object):\n  def __init__(self, in_string):\n    self.major, self.minor, self.patch = in_string.split(\".\")\n    assert self.major.isdigit()\n    assert self.minor.isdigit()\n    assert self.patch.isdigit()\n  def full(self):\n    return \".\".join([self.major, self.minor, self.patch])\n  def short(self):\n    return \".\".join([self.major, self.minor])",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.release_tools.update_versions",
        "documentation": {}
    },
    {
        "label": "EXTS",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.release_tools.update_versions",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.release_tools.update_versions",
        "peekOfCode": "EXTS = [\".ipynb\",\".md\",\".yaml\",\".html\"]\nEXPAND_TABLES = [\n    \"source_windows.md\",\n    \"source.md\",]\nclass Version(object):\n  def __init__(self, in_string):\n    self.major, self.minor, self.patch = in_string.split(\".\")\n    assert self.major.isdigit()\n    assert self.minor.isdigit()\n    assert self.patch.isdigit()",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.release_tools.update_versions",
        "documentation": {}
    },
    {
        "label": "EXPAND_TABLES",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.release_tools.update_versions",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.release_tools.update_versions",
        "peekOfCode": "EXPAND_TABLES = [\n    \"source_windows.md\",\n    \"source.md\",]\nclass Version(object):\n  def __init__(self, in_string):\n    self.major, self.minor, self.patch = in_string.split(\".\")\n    assert self.major.isdigit()\n    assert self.minor.isdigit()\n    assert self.patch.isdigit()\n  def full(self):",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.release_tools.update_versions",
        "documentation": {}
    },
    {
        "label": "parser",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.release_tools.update_versions",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.release_tools.update_versions",
        "peekOfCode": "parser = argparse.ArgumentParser()\nparser.add_argument(\"--old_version\", type=Version, required=True,\n                    help=\"The old version to replace\")\nparser.add_argument(\"--new_version\", type=Version, required=True,\n                    help=\"The new version to replace it with\")\nif __name__==\"__main__\":\n  args = parser.parse_args()\n  for ext in EXTS:\n    for file_path in pathlib.Path(\".\").rglob(\"*\"+ext):\n      content = file_path.read_text()",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.release_tools.update_versions",
        "documentation": {}
    },
    {
        "label": "gen_api_docs",
        "kind": 2,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.templates.build_docs",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.templates.build_docs",
        "peekOfCode": "def gen_api_docs():\n  \"\"\"Generates api docs for the tensorflow docs package.\"\"\"\n  # The below `del`'s are to avoid the api_gen_test to not document these.\n  # Please remove these lines from your build_docs.py files when you create\n  # them.\n  del tensorflow_docs.google\n  del tensorflow_docs.api_generator.report.schema\n  doc_generator = generate_lib.DocGenerator(\n      root_title=PROJECT_FULL_NAME,\n      # Replace `tensorflow_docs` with your module, here.",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.templates.build_docs",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.templates.build_docs",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.templates.build_docs",
        "peekOfCode": "def main(argv):\n  if argv[1:]:\n    raise ValueError('Unrecognized arguments: {}'.format(argv[1:]))\n  gen_api_docs()\nif __name__ == '__main__':\n  app.run(main)",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.templates.build_docs",
        "documentation": {}
    },
    {
        "label": "PROJECT_SHORT_NAME",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.templates.build_docs",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.templates.build_docs",
        "peekOfCode": "PROJECT_SHORT_NAME = 'tfdocs'\nPROJECT_FULL_NAME = 'TensorFlow Docs'\nFLAGS = flags.FLAGS\nflags.DEFINE_string(\n    'output_dir',\n    default='/tmp/generated_docs',\n    help='Where to write the resulting docs to.')\nflags.DEFINE_string('code_url_prefix',\n                    ('https://github.com/tensorflow/docs/tree/master/tools/tensorflow_docs'),\n                    'The url prefix for links to code.')",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.templates.build_docs",
        "documentation": {}
    },
    {
        "label": "PROJECT_FULL_NAME",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.templates.build_docs",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.templates.build_docs",
        "peekOfCode": "PROJECT_FULL_NAME = 'TensorFlow Docs'\nFLAGS = flags.FLAGS\nflags.DEFINE_string(\n    'output_dir',\n    default='/tmp/generated_docs',\n    help='Where to write the resulting docs to.')\nflags.DEFINE_string('code_url_prefix',\n                    ('https://github.com/tensorflow/docs/tree/master/tools/tensorflow_docs'),\n                    'The url prefix for links to code.')\nflags.DEFINE_bool('search_hints', True,",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.templates.build_docs",
        "documentation": {}
    },
    {
        "label": "FLAGS",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.templates.build_docs",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.templates.build_docs",
        "peekOfCode": "FLAGS = flags.FLAGS\nflags.DEFINE_string(\n    'output_dir',\n    default='/tmp/generated_docs',\n    help='Where to write the resulting docs to.')\nflags.DEFINE_string('code_url_prefix',\n                    ('https://github.com/tensorflow/docs/tree/master/tools/tensorflow_docs'),\n                    'The url prefix for links to code.')\nflags.DEFINE_bool('search_hints', True,\n                  'Include metadata search hints in the generated files')",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.templates.build_docs",
        "documentation": {}
    },
    {
        "label": "_sym_db",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "peekOfCode": "_sym_db = _symbol_database.Default()\nfrom google.protobuf import timestamp_pb2 as google_dot_protobuf_dot_timestamp__pb2\nDESCRIPTOR = _descriptor.FileDescriptor(\n  name='api_report.proto',\n  package='tensorflow_docs.api_report.schema',\n  syntax='proto2',\n  serialized_options=None,\n  create_key=_descriptor._internal_create_key,\n  serialized_pb=b'\\n\\x10\\x61pi_report.proto\\x12!tensorflow_docs.api_report.schema\\x1a\\x1fgoogle/protobuf/timestamp.proto\\\"\\xa2\\x01\\n\\rParameterLint\\x12!\\n\\x19num_empty_param_desc_args\\x18\\x01 \\x01(\\x02\\x12\\x18\\n\\x10num_args_in_code\\x18\\x02 \\x01(\\x02\\x12!\\n\\x19num_empty_param_desc_attr\\x18\\x03 \\x01(\\x02\\x12\\x18\\n\\x10total_attr_param\\x18\\x04 \\x01(\\x02\\x12\\x17\\n\\x0fnum_args_in_doc\\x18\\x05 \\x01(\\x02\\\";\\n\\x0f\\x44\\x65scriptionLint\\x12\\x11\\n\\tlen_brief\\x18\\x01 \\x01(\\x02\\x12\\x15\\n\\rlen_long_desc\\x18\\x03 \\x01(\\x02\\\"F\\n\\x10UsageExampleLint\\x12\\x13\\n\\x0bnum_doctest\\x18\\x01 \\x01(\\x02\\x12\\x1d\\n\\x15num_untested_examples\\x18\\x02 \\x01(\\x02\\\"%\\n\\nReturnLint\\x12\\x17\\n\\x0freturns_defined\\x18\\x01 \\x01(\\x08\\\"F\\n\\nRaisesLint\\x12\\x1a\\n\\x12num_raises_defined\\x18\\x01 \\x01(\\x02\\x12\\x1c\\n\\x14total_raises_in_code\\x18\\x02 \\x01(\\x02\\\"\\xeb\\x03\\n\\x0f\\x41piSymbolMetric\\x12\\x13\\n\\x0bsymbol_name\\x18\\x01 \\x01(\\t\\x12\\x42\\n\\x0bobject_type\\x18\\x02 \\x01(\\x0e\\x32-.tensorflow_docs.api_report.schema.ObjectType\\x12H\\n\\x0eparameter_lint\\x18\\x03 \\x01(\\x0b\\x32\\x30.tensorflow_docs.api_report.schema.ParameterLint\\x12\\x45\\n\\tdesc_lint\\x18\\x04 \\x01(\\x0b\\x32\\x32.tensorflow_docs.api_report.schema.DescriptionLint\\x12O\\n\\x12usage_example_lint\\x18\\x05 \\x01(\\x0b\\x32\\x33.tensorflow_docs.api_report.schema.UsageExampleLint\\x12\\x42\\n\\x0breturn_lint\\x18\\x06 \\x01(\\x0b\\x32-.tensorflow_docs.api_report.schema.ReturnLint\\x12\\x42\\n\\x0braises_lint\\x18\\x07 \\x01(\\x0b\\x32-.tensorflow_docs.api_report.schema.RaisesLint\\x12\\x15\\n\\rpackage_group\\x18\\x08 \\x01(\\t\\\"\\x93\\x01\\n\\tApiReport\\x12-\\n\\ttimestamp\\x18\\x01 \\x01(\\x0b\\x32\\x1a.google.protobuf.Timestamp\\x12\\x0c\\n\\x04\\x64\\x61te\\x18\\x02 \\x01(\\t\\x12I\\n\\rsymbol_metric\\x18\\x03 \\x03(\\x0b\\x32\\x32.tensorflow_docs.api_report.schema.ApiSymbolMetric*M\\n\\nObjectType\\x12\\t\\n\\x05\\x43LASS\\x10\\x00\\x12\\n\\n\\x06METHOD\\x10\\x01\\x12\\x0c\\n\\x08\\x46UNCTION\\x10\\x02\\x12\\n\\n\\x06MODULE\\x10\\x03\\x12\\x0e\\n\\nTYPE_ALIAS\\x10\\x04'\n  ,",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "documentation": {}
    },
    {
        "label": "DESCRIPTOR",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "peekOfCode": "DESCRIPTOR = _descriptor.FileDescriptor(\n  name='api_report.proto',\n  package='tensorflow_docs.api_report.schema',\n  syntax='proto2',\n  serialized_options=None,\n  create_key=_descriptor._internal_create_key,\n  serialized_pb=b'\\n\\x10\\x61pi_report.proto\\x12!tensorflow_docs.api_report.schema\\x1a\\x1fgoogle/protobuf/timestamp.proto\\\"\\xa2\\x01\\n\\rParameterLint\\x12!\\n\\x19num_empty_param_desc_args\\x18\\x01 \\x01(\\x02\\x12\\x18\\n\\x10num_args_in_code\\x18\\x02 \\x01(\\x02\\x12!\\n\\x19num_empty_param_desc_attr\\x18\\x03 \\x01(\\x02\\x12\\x18\\n\\x10total_attr_param\\x18\\x04 \\x01(\\x02\\x12\\x17\\n\\x0fnum_args_in_doc\\x18\\x05 \\x01(\\x02\\\";\\n\\x0f\\x44\\x65scriptionLint\\x12\\x11\\n\\tlen_brief\\x18\\x01 \\x01(\\x02\\x12\\x15\\n\\rlen_long_desc\\x18\\x03 \\x01(\\x02\\\"F\\n\\x10UsageExampleLint\\x12\\x13\\n\\x0bnum_doctest\\x18\\x01 \\x01(\\x02\\x12\\x1d\\n\\x15num_untested_examples\\x18\\x02 \\x01(\\x02\\\"%\\n\\nReturnLint\\x12\\x17\\n\\x0freturns_defined\\x18\\x01 \\x01(\\x08\\\"F\\n\\nRaisesLint\\x12\\x1a\\n\\x12num_raises_defined\\x18\\x01 \\x01(\\x02\\x12\\x1c\\n\\x14total_raises_in_code\\x18\\x02 \\x01(\\x02\\\"\\xeb\\x03\\n\\x0f\\x41piSymbolMetric\\x12\\x13\\n\\x0bsymbol_name\\x18\\x01 \\x01(\\t\\x12\\x42\\n\\x0bobject_type\\x18\\x02 \\x01(\\x0e\\x32-.tensorflow_docs.api_report.schema.ObjectType\\x12H\\n\\x0eparameter_lint\\x18\\x03 \\x01(\\x0b\\x32\\x30.tensorflow_docs.api_report.schema.ParameterLint\\x12\\x45\\n\\tdesc_lint\\x18\\x04 \\x01(\\x0b\\x32\\x32.tensorflow_docs.api_report.schema.DescriptionLint\\x12O\\n\\x12usage_example_lint\\x18\\x05 \\x01(\\x0b\\x32\\x33.tensorflow_docs.api_report.schema.UsageExampleLint\\x12\\x42\\n\\x0breturn_lint\\x18\\x06 \\x01(\\x0b\\x32-.tensorflow_docs.api_report.schema.ReturnLint\\x12\\x42\\n\\x0braises_lint\\x18\\x07 \\x01(\\x0b\\x32-.tensorflow_docs.api_report.schema.RaisesLint\\x12\\x15\\n\\rpackage_group\\x18\\x08 \\x01(\\t\\\"\\x93\\x01\\n\\tApiReport\\x12-\\n\\ttimestamp\\x18\\x01 \\x01(\\x0b\\x32\\x1a.google.protobuf.Timestamp\\x12\\x0c\\n\\x04\\x64\\x61te\\x18\\x02 \\x01(\\t\\x12I\\n\\rsymbol_metric\\x18\\x03 \\x03(\\x0b\\x32\\x32.tensorflow_docs.api_report.schema.ApiSymbolMetric*M\\n\\nObjectType\\x12\\t\\n\\x05\\x43LASS\\x10\\x00\\x12\\n\\n\\x06METHOD\\x10\\x01\\x12\\x0c\\n\\x08\\x46UNCTION\\x10\\x02\\x12\\n\\n\\x06MODULE\\x10\\x03\\x12\\x0e\\n\\nTYPE_ALIAS\\x10\\x04'\n  ,\n  dependencies=[google_dot_protobuf_dot_timestamp__pb2.DESCRIPTOR,])\n_OBJECTTYPE = _descriptor.EnumDescriptor(",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "documentation": {}
    },
    {
        "label": "_OBJECTTYPE",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "peekOfCode": "_OBJECTTYPE = _descriptor.EnumDescriptor(\n  name='ObjectType',\n  full_name='tensorflow_docs.api_report.schema.ObjectType',\n  filename=None,\n  file=DESCRIPTOR,\n  create_key=_descriptor._internal_create_key,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name='CLASS', index=0, number=0,\n      serialized_options=None,",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "documentation": {}
    },
    {
        "label": "ObjectType",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "peekOfCode": "ObjectType = enum_type_wrapper.EnumTypeWrapper(_OBJECTTYPE)\nCLASS = 0\nMETHOD = 1\nFUNCTION = 2\nMODULE = 3\nTYPE_ALIAS = 4\n_PARAMETERLINT = _descriptor.Descriptor(\n  name='ParameterLint',\n  full_name='tensorflow_docs.api_report.schema.ParameterLint',\n  filename=None,",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "documentation": {}
    },
    {
        "label": "CLASS",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "peekOfCode": "CLASS = 0\nMETHOD = 1\nFUNCTION = 2\nMODULE = 3\nTYPE_ALIAS = 4\n_PARAMETERLINT = _descriptor.Descriptor(\n  name='ParameterLint',\n  full_name='tensorflow_docs.api_report.schema.ParameterLint',\n  filename=None,\n  file=DESCRIPTOR,",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "documentation": {}
    },
    {
        "label": "METHOD",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "peekOfCode": "METHOD = 1\nFUNCTION = 2\nMODULE = 3\nTYPE_ALIAS = 4\n_PARAMETERLINT = _descriptor.Descriptor(\n  name='ParameterLint',\n  full_name='tensorflow_docs.api_report.schema.ParameterLint',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "documentation": {}
    },
    {
        "label": "FUNCTION",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "peekOfCode": "FUNCTION = 2\nMODULE = 3\nTYPE_ALIAS = 4\n_PARAMETERLINT = _descriptor.Descriptor(\n  name='ParameterLint',\n  full_name='tensorflow_docs.api_report.schema.ParameterLint',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  create_key=_descriptor._internal_create_key,",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "documentation": {}
    },
    {
        "label": "MODULE",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "peekOfCode": "MODULE = 3\nTYPE_ALIAS = 4\n_PARAMETERLINT = _descriptor.Descriptor(\n  name='ParameterLint',\n  full_name='tensorflow_docs.api_report.schema.ParameterLint',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  create_key=_descriptor._internal_create_key,\n  fields=[",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "documentation": {}
    },
    {
        "label": "TYPE_ALIAS",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "peekOfCode": "TYPE_ALIAS = 4\n_PARAMETERLINT = _descriptor.Descriptor(\n  name='ParameterLint',\n  full_name='tensorflow_docs.api_report.schema.ParameterLint',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  create_key=_descriptor._internal_create_key,\n  fields=[\n    _descriptor.FieldDescriptor(",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "documentation": {}
    },
    {
        "label": "_PARAMETERLINT",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "peekOfCode": "_PARAMETERLINT = _descriptor.Descriptor(\n  name='ParameterLint',\n  full_name='tensorflow_docs.api_report.schema.ParameterLint',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  create_key=_descriptor._internal_create_key,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name='num_empty_param_desc_args', full_name='tensorflow_docs.api_report.schema.ParameterLint.num_empty_param_desc_args', index=0,",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "documentation": {}
    },
    {
        "label": "_DESCRIPTIONLINT",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "peekOfCode": "_DESCRIPTIONLINT = _descriptor.Descriptor(\n  name='DescriptionLint',\n  full_name='tensorflow_docs.api_report.schema.DescriptionLint',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  create_key=_descriptor._internal_create_key,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name='len_brief', full_name='tensorflow_docs.api_report.schema.DescriptionLint.len_brief', index=0,",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "documentation": {}
    },
    {
        "label": "_USAGEEXAMPLELINT",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "peekOfCode": "_USAGEEXAMPLELINT = _descriptor.Descriptor(\n  name='UsageExampleLint',\n  full_name='tensorflow_docs.api_report.schema.UsageExampleLint',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  create_key=_descriptor._internal_create_key,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name='num_doctest', full_name='tensorflow_docs.api_report.schema.UsageExampleLint.num_doctest', index=0,",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "documentation": {}
    },
    {
        "label": "_RETURNLINT",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "peekOfCode": "_RETURNLINT = _descriptor.Descriptor(\n  name='ReturnLint',\n  full_name='tensorflow_docs.api_report.schema.ReturnLint',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  create_key=_descriptor._internal_create_key,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name='returns_defined', full_name='tensorflow_docs.api_report.schema.ReturnLint.returns_defined', index=0,",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "documentation": {}
    },
    {
        "label": "_RAISESLINT",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "peekOfCode": "_RAISESLINT = _descriptor.Descriptor(\n  name='RaisesLint',\n  full_name='tensorflow_docs.api_report.schema.RaisesLint',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  create_key=_descriptor._internal_create_key,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name='num_raises_defined', full_name='tensorflow_docs.api_report.schema.RaisesLint.num_raises_defined', index=0,",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "documentation": {}
    },
    {
        "label": "_APISYMBOLMETRIC",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "peekOfCode": "_APISYMBOLMETRIC = _descriptor.Descriptor(\n  name='ApiSymbolMetric',\n  full_name='tensorflow_docs.api_report.schema.ApiSymbolMetric',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  create_key=_descriptor._internal_create_key,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name='symbol_name', full_name='tensorflow_docs.api_report.schema.ApiSymbolMetric.symbol_name', index=0,",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "documentation": {}
    },
    {
        "label": "_APIREPORT",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "peekOfCode": "_APIREPORT = _descriptor.Descriptor(\n  name='ApiReport',\n  full_name='tensorflow_docs.api_report.schema.ApiReport',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  create_key=_descriptor._internal_create_key,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name='timestamp', full_name='tensorflow_docs.api_report.schema.ApiReport.timestamp', index=0,",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "documentation": {}
    },
    {
        "label": "_APISYMBOLMETRIC.fields_by_name['object_type'].enum_type",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "peekOfCode": "_APISYMBOLMETRIC.fields_by_name['object_type'].enum_type = _OBJECTTYPE\n_APISYMBOLMETRIC.fields_by_name['parameter_lint'].message_type = _PARAMETERLINT\n_APISYMBOLMETRIC.fields_by_name['desc_lint'].message_type = _DESCRIPTIONLINT\n_APISYMBOLMETRIC.fields_by_name['usage_example_lint'].message_type = _USAGEEXAMPLELINT\n_APISYMBOLMETRIC.fields_by_name['return_lint'].message_type = _RETURNLINT\n_APISYMBOLMETRIC.fields_by_name['raises_lint'].message_type = _RAISESLINT\n_APIREPORT.fields_by_name['timestamp'].message_type = google_dot_protobuf_dot_timestamp__pb2._TIMESTAMP\n_APIREPORT.fields_by_name['symbol_metric'].message_type = _APISYMBOLMETRIC\nDESCRIPTOR.message_types_by_name['ParameterLint'] = _PARAMETERLINT\nDESCRIPTOR.message_types_by_name['DescriptionLint'] = _DESCRIPTIONLINT",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "documentation": {}
    },
    {
        "label": "_APISYMBOLMETRIC.fields_by_name['parameter_lint'].message_type",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "peekOfCode": "_APISYMBOLMETRIC.fields_by_name['parameter_lint'].message_type = _PARAMETERLINT\n_APISYMBOLMETRIC.fields_by_name['desc_lint'].message_type = _DESCRIPTIONLINT\n_APISYMBOLMETRIC.fields_by_name['usage_example_lint'].message_type = _USAGEEXAMPLELINT\n_APISYMBOLMETRIC.fields_by_name['return_lint'].message_type = _RETURNLINT\n_APISYMBOLMETRIC.fields_by_name['raises_lint'].message_type = _RAISESLINT\n_APIREPORT.fields_by_name['timestamp'].message_type = google_dot_protobuf_dot_timestamp__pb2._TIMESTAMP\n_APIREPORT.fields_by_name['symbol_metric'].message_type = _APISYMBOLMETRIC\nDESCRIPTOR.message_types_by_name['ParameterLint'] = _PARAMETERLINT\nDESCRIPTOR.message_types_by_name['DescriptionLint'] = _DESCRIPTIONLINT\nDESCRIPTOR.message_types_by_name['UsageExampleLint'] = _USAGEEXAMPLELINT",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "documentation": {}
    },
    {
        "label": "_APISYMBOLMETRIC.fields_by_name['desc_lint'].message_type",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "peekOfCode": "_APISYMBOLMETRIC.fields_by_name['desc_lint'].message_type = _DESCRIPTIONLINT\n_APISYMBOLMETRIC.fields_by_name['usage_example_lint'].message_type = _USAGEEXAMPLELINT\n_APISYMBOLMETRIC.fields_by_name['return_lint'].message_type = _RETURNLINT\n_APISYMBOLMETRIC.fields_by_name['raises_lint'].message_type = _RAISESLINT\n_APIREPORT.fields_by_name['timestamp'].message_type = google_dot_protobuf_dot_timestamp__pb2._TIMESTAMP\n_APIREPORT.fields_by_name['symbol_metric'].message_type = _APISYMBOLMETRIC\nDESCRIPTOR.message_types_by_name['ParameterLint'] = _PARAMETERLINT\nDESCRIPTOR.message_types_by_name['DescriptionLint'] = _DESCRIPTIONLINT\nDESCRIPTOR.message_types_by_name['UsageExampleLint'] = _USAGEEXAMPLELINT\nDESCRIPTOR.message_types_by_name['ReturnLint'] = _RETURNLINT",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "documentation": {}
    },
    {
        "label": "_APISYMBOLMETRIC.fields_by_name['usage_example_lint'].message_type",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "peekOfCode": "_APISYMBOLMETRIC.fields_by_name['usage_example_lint'].message_type = _USAGEEXAMPLELINT\n_APISYMBOLMETRIC.fields_by_name['return_lint'].message_type = _RETURNLINT\n_APISYMBOLMETRIC.fields_by_name['raises_lint'].message_type = _RAISESLINT\n_APIREPORT.fields_by_name['timestamp'].message_type = google_dot_protobuf_dot_timestamp__pb2._TIMESTAMP\n_APIREPORT.fields_by_name['symbol_metric'].message_type = _APISYMBOLMETRIC\nDESCRIPTOR.message_types_by_name['ParameterLint'] = _PARAMETERLINT\nDESCRIPTOR.message_types_by_name['DescriptionLint'] = _DESCRIPTIONLINT\nDESCRIPTOR.message_types_by_name['UsageExampleLint'] = _USAGEEXAMPLELINT\nDESCRIPTOR.message_types_by_name['ReturnLint'] = _RETURNLINT\nDESCRIPTOR.message_types_by_name['RaisesLint'] = _RAISESLINT",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "documentation": {}
    },
    {
        "label": "_APISYMBOLMETRIC.fields_by_name['return_lint'].message_type",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "peekOfCode": "_APISYMBOLMETRIC.fields_by_name['return_lint'].message_type = _RETURNLINT\n_APISYMBOLMETRIC.fields_by_name['raises_lint'].message_type = _RAISESLINT\n_APIREPORT.fields_by_name['timestamp'].message_type = google_dot_protobuf_dot_timestamp__pb2._TIMESTAMP\n_APIREPORT.fields_by_name['symbol_metric'].message_type = _APISYMBOLMETRIC\nDESCRIPTOR.message_types_by_name['ParameterLint'] = _PARAMETERLINT\nDESCRIPTOR.message_types_by_name['DescriptionLint'] = _DESCRIPTIONLINT\nDESCRIPTOR.message_types_by_name['UsageExampleLint'] = _USAGEEXAMPLELINT\nDESCRIPTOR.message_types_by_name['ReturnLint'] = _RETURNLINT\nDESCRIPTOR.message_types_by_name['RaisesLint'] = _RAISESLINT\nDESCRIPTOR.message_types_by_name['ApiSymbolMetric'] = _APISYMBOLMETRIC",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "documentation": {}
    },
    {
        "label": "_APISYMBOLMETRIC.fields_by_name['raises_lint'].message_type",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "peekOfCode": "_APISYMBOLMETRIC.fields_by_name['raises_lint'].message_type = _RAISESLINT\n_APIREPORT.fields_by_name['timestamp'].message_type = google_dot_protobuf_dot_timestamp__pb2._TIMESTAMP\n_APIREPORT.fields_by_name['symbol_metric'].message_type = _APISYMBOLMETRIC\nDESCRIPTOR.message_types_by_name['ParameterLint'] = _PARAMETERLINT\nDESCRIPTOR.message_types_by_name['DescriptionLint'] = _DESCRIPTIONLINT\nDESCRIPTOR.message_types_by_name['UsageExampleLint'] = _USAGEEXAMPLELINT\nDESCRIPTOR.message_types_by_name['ReturnLint'] = _RETURNLINT\nDESCRIPTOR.message_types_by_name['RaisesLint'] = _RAISESLINT\nDESCRIPTOR.message_types_by_name['ApiSymbolMetric'] = _APISYMBOLMETRIC\nDESCRIPTOR.message_types_by_name['ApiReport'] = _APIREPORT",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "documentation": {}
    },
    {
        "label": "_APIREPORT.fields_by_name['timestamp'].message_type",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "peekOfCode": "_APIREPORT.fields_by_name['timestamp'].message_type = google_dot_protobuf_dot_timestamp__pb2._TIMESTAMP\n_APIREPORT.fields_by_name['symbol_metric'].message_type = _APISYMBOLMETRIC\nDESCRIPTOR.message_types_by_name['ParameterLint'] = _PARAMETERLINT\nDESCRIPTOR.message_types_by_name['DescriptionLint'] = _DESCRIPTIONLINT\nDESCRIPTOR.message_types_by_name['UsageExampleLint'] = _USAGEEXAMPLELINT\nDESCRIPTOR.message_types_by_name['ReturnLint'] = _RETURNLINT\nDESCRIPTOR.message_types_by_name['RaisesLint'] = _RAISESLINT\nDESCRIPTOR.message_types_by_name['ApiSymbolMetric'] = _APISYMBOLMETRIC\nDESCRIPTOR.message_types_by_name['ApiReport'] = _APIREPORT\nDESCRIPTOR.enum_types_by_name['ObjectType'] = _OBJECTTYPE",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "documentation": {}
    },
    {
        "label": "_APIREPORT.fields_by_name['symbol_metric'].message_type",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "peekOfCode": "_APIREPORT.fields_by_name['symbol_metric'].message_type = _APISYMBOLMETRIC\nDESCRIPTOR.message_types_by_name['ParameterLint'] = _PARAMETERLINT\nDESCRIPTOR.message_types_by_name['DescriptionLint'] = _DESCRIPTIONLINT\nDESCRIPTOR.message_types_by_name['UsageExampleLint'] = _USAGEEXAMPLELINT\nDESCRIPTOR.message_types_by_name['ReturnLint'] = _RETURNLINT\nDESCRIPTOR.message_types_by_name['RaisesLint'] = _RAISESLINT\nDESCRIPTOR.message_types_by_name['ApiSymbolMetric'] = _APISYMBOLMETRIC\nDESCRIPTOR.message_types_by_name['ApiReport'] = _APIREPORT\nDESCRIPTOR.enum_types_by_name['ObjectType'] = _OBJECTTYPE\n_sym_db.RegisterFileDescriptor(DESCRIPTOR)",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "documentation": {}
    },
    {
        "label": "DESCRIPTOR.message_types_by_name['ParameterLint']",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "peekOfCode": "DESCRIPTOR.message_types_by_name['ParameterLint'] = _PARAMETERLINT\nDESCRIPTOR.message_types_by_name['DescriptionLint'] = _DESCRIPTIONLINT\nDESCRIPTOR.message_types_by_name['UsageExampleLint'] = _USAGEEXAMPLELINT\nDESCRIPTOR.message_types_by_name['ReturnLint'] = _RETURNLINT\nDESCRIPTOR.message_types_by_name['RaisesLint'] = _RAISESLINT\nDESCRIPTOR.message_types_by_name['ApiSymbolMetric'] = _APISYMBOLMETRIC\nDESCRIPTOR.message_types_by_name['ApiReport'] = _APIREPORT\nDESCRIPTOR.enum_types_by_name['ObjectType'] = _OBJECTTYPE\n_sym_db.RegisterFileDescriptor(DESCRIPTOR)\nParameterLint = _reflection.GeneratedProtocolMessageType('ParameterLint', (_message.Message,), {",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "documentation": {}
    },
    {
        "label": "DESCRIPTOR.message_types_by_name['DescriptionLint']",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "peekOfCode": "DESCRIPTOR.message_types_by_name['DescriptionLint'] = _DESCRIPTIONLINT\nDESCRIPTOR.message_types_by_name['UsageExampleLint'] = _USAGEEXAMPLELINT\nDESCRIPTOR.message_types_by_name['ReturnLint'] = _RETURNLINT\nDESCRIPTOR.message_types_by_name['RaisesLint'] = _RAISESLINT\nDESCRIPTOR.message_types_by_name['ApiSymbolMetric'] = _APISYMBOLMETRIC\nDESCRIPTOR.message_types_by_name['ApiReport'] = _APIREPORT\nDESCRIPTOR.enum_types_by_name['ObjectType'] = _OBJECTTYPE\n_sym_db.RegisterFileDescriptor(DESCRIPTOR)\nParameterLint = _reflection.GeneratedProtocolMessageType('ParameterLint', (_message.Message,), {\n  'DESCRIPTOR' : _PARAMETERLINT,",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "documentation": {}
    },
    {
        "label": "DESCRIPTOR.message_types_by_name['UsageExampleLint']",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "peekOfCode": "DESCRIPTOR.message_types_by_name['UsageExampleLint'] = _USAGEEXAMPLELINT\nDESCRIPTOR.message_types_by_name['ReturnLint'] = _RETURNLINT\nDESCRIPTOR.message_types_by_name['RaisesLint'] = _RAISESLINT\nDESCRIPTOR.message_types_by_name['ApiSymbolMetric'] = _APISYMBOLMETRIC\nDESCRIPTOR.message_types_by_name['ApiReport'] = _APIREPORT\nDESCRIPTOR.enum_types_by_name['ObjectType'] = _OBJECTTYPE\n_sym_db.RegisterFileDescriptor(DESCRIPTOR)\nParameterLint = _reflection.GeneratedProtocolMessageType('ParameterLint', (_message.Message,), {\n  'DESCRIPTOR' : _PARAMETERLINT,\n  '__module__' : 'api_report_pb2'",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "documentation": {}
    },
    {
        "label": "DESCRIPTOR.message_types_by_name['ReturnLint']",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "peekOfCode": "DESCRIPTOR.message_types_by_name['ReturnLint'] = _RETURNLINT\nDESCRIPTOR.message_types_by_name['RaisesLint'] = _RAISESLINT\nDESCRIPTOR.message_types_by_name['ApiSymbolMetric'] = _APISYMBOLMETRIC\nDESCRIPTOR.message_types_by_name['ApiReport'] = _APIREPORT\nDESCRIPTOR.enum_types_by_name['ObjectType'] = _OBJECTTYPE\n_sym_db.RegisterFileDescriptor(DESCRIPTOR)\nParameterLint = _reflection.GeneratedProtocolMessageType('ParameterLint', (_message.Message,), {\n  'DESCRIPTOR' : _PARAMETERLINT,\n  '__module__' : 'api_report_pb2'\n  # @@protoc_insertion_point(class_scope:tensorflow_docs.api_report.schema.ParameterLint)",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "documentation": {}
    },
    {
        "label": "DESCRIPTOR.message_types_by_name['RaisesLint']",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "peekOfCode": "DESCRIPTOR.message_types_by_name['RaisesLint'] = _RAISESLINT\nDESCRIPTOR.message_types_by_name['ApiSymbolMetric'] = _APISYMBOLMETRIC\nDESCRIPTOR.message_types_by_name['ApiReport'] = _APIREPORT\nDESCRIPTOR.enum_types_by_name['ObjectType'] = _OBJECTTYPE\n_sym_db.RegisterFileDescriptor(DESCRIPTOR)\nParameterLint = _reflection.GeneratedProtocolMessageType('ParameterLint', (_message.Message,), {\n  'DESCRIPTOR' : _PARAMETERLINT,\n  '__module__' : 'api_report_pb2'\n  # @@protoc_insertion_point(class_scope:tensorflow_docs.api_report.schema.ParameterLint)\n  })",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "documentation": {}
    },
    {
        "label": "DESCRIPTOR.message_types_by_name['ApiSymbolMetric']",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "peekOfCode": "DESCRIPTOR.message_types_by_name['ApiSymbolMetric'] = _APISYMBOLMETRIC\nDESCRIPTOR.message_types_by_name['ApiReport'] = _APIREPORT\nDESCRIPTOR.enum_types_by_name['ObjectType'] = _OBJECTTYPE\n_sym_db.RegisterFileDescriptor(DESCRIPTOR)\nParameterLint = _reflection.GeneratedProtocolMessageType('ParameterLint', (_message.Message,), {\n  'DESCRIPTOR' : _PARAMETERLINT,\n  '__module__' : 'api_report_pb2'\n  # @@protoc_insertion_point(class_scope:tensorflow_docs.api_report.schema.ParameterLint)\n  })\n_sym_db.RegisterMessage(ParameterLint)",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "documentation": {}
    },
    {
        "label": "DESCRIPTOR.message_types_by_name['ApiReport']",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "peekOfCode": "DESCRIPTOR.message_types_by_name['ApiReport'] = _APIREPORT\nDESCRIPTOR.enum_types_by_name['ObjectType'] = _OBJECTTYPE\n_sym_db.RegisterFileDescriptor(DESCRIPTOR)\nParameterLint = _reflection.GeneratedProtocolMessageType('ParameterLint', (_message.Message,), {\n  'DESCRIPTOR' : _PARAMETERLINT,\n  '__module__' : 'api_report_pb2'\n  # @@protoc_insertion_point(class_scope:tensorflow_docs.api_report.schema.ParameterLint)\n  })\n_sym_db.RegisterMessage(ParameterLint)\nDescriptionLint = _reflection.GeneratedProtocolMessageType('DescriptionLint', (_message.Message,), {",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "documentation": {}
    },
    {
        "label": "DESCRIPTOR.enum_types_by_name['ObjectType']",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "peekOfCode": "DESCRIPTOR.enum_types_by_name['ObjectType'] = _OBJECTTYPE\n_sym_db.RegisterFileDescriptor(DESCRIPTOR)\nParameterLint = _reflection.GeneratedProtocolMessageType('ParameterLint', (_message.Message,), {\n  'DESCRIPTOR' : _PARAMETERLINT,\n  '__module__' : 'api_report_pb2'\n  # @@protoc_insertion_point(class_scope:tensorflow_docs.api_report.schema.ParameterLint)\n  })\n_sym_db.RegisterMessage(ParameterLint)\nDescriptionLint = _reflection.GeneratedProtocolMessageType('DescriptionLint', (_message.Message,), {\n  'DESCRIPTOR' : _DESCRIPTIONLINT,",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "documentation": {}
    },
    {
        "label": "ParameterLint",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "peekOfCode": "ParameterLint = _reflection.GeneratedProtocolMessageType('ParameterLint', (_message.Message,), {\n  'DESCRIPTOR' : _PARAMETERLINT,\n  '__module__' : 'api_report_pb2'\n  # @@protoc_insertion_point(class_scope:tensorflow_docs.api_report.schema.ParameterLint)\n  })\n_sym_db.RegisterMessage(ParameterLint)\nDescriptionLint = _reflection.GeneratedProtocolMessageType('DescriptionLint', (_message.Message,), {\n  'DESCRIPTOR' : _DESCRIPTIONLINT,\n  '__module__' : 'api_report_pb2'\n  # @@protoc_insertion_point(class_scope:tensorflow_docs.api_report.schema.DescriptionLint)",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "documentation": {}
    },
    {
        "label": "DescriptionLint",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "peekOfCode": "DescriptionLint = _reflection.GeneratedProtocolMessageType('DescriptionLint', (_message.Message,), {\n  'DESCRIPTOR' : _DESCRIPTIONLINT,\n  '__module__' : 'api_report_pb2'\n  # @@protoc_insertion_point(class_scope:tensorflow_docs.api_report.schema.DescriptionLint)\n  })\n_sym_db.RegisterMessage(DescriptionLint)\nUsageExampleLint = _reflection.GeneratedProtocolMessageType('UsageExampleLint', (_message.Message,), {\n  'DESCRIPTOR' : _USAGEEXAMPLELINT,\n  '__module__' : 'api_report_pb2'\n  # @@protoc_insertion_point(class_scope:tensorflow_docs.api_report.schema.UsageExampleLint)",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "documentation": {}
    },
    {
        "label": "UsageExampleLint",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "peekOfCode": "UsageExampleLint = _reflection.GeneratedProtocolMessageType('UsageExampleLint', (_message.Message,), {\n  'DESCRIPTOR' : _USAGEEXAMPLELINT,\n  '__module__' : 'api_report_pb2'\n  # @@protoc_insertion_point(class_scope:tensorflow_docs.api_report.schema.UsageExampleLint)\n  })\n_sym_db.RegisterMessage(UsageExampleLint)\nReturnLint = _reflection.GeneratedProtocolMessageType('ReturnLint', (_message.Message,), {\n  'DESCRIPTOR' : _RETURNLINT,\n  '__module__' : 'api_report_pb2'\n  # @@protoc_insertion_point(class_scope:tensorflow_docs.api_report.schema.ReturnLint)",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "documentation": {}
    },
    {
        "label": "ReturnLint",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "peekOfCode": "ReturnLint = _reflection.GeneratedProtocolMessageType('ReturnLint', (_message.Message,), {\n  'DESCRIPTOR' : _RETURNLINT,\n  '__module__' : 'api_report_pb2'\n  # @@protoc_insertion_point(class_scope:tensorflow_docs.api_report.schema.ReturnLint)\n  })\n_sym_db.RegisterMessage(ReturnLint)\nRaisesLint = _reflection.GeneratedProtocolMessageType('RaisesLint', (_message.Message,), {\n  'DESCRIPTOR' : _RAISESLINT,\n  '__module__' : 'api_report_pb2'\n  # @@protoc_insertion_point(class_scope:tensorflow_docs.api_report.schema.RaisesLint)",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "documentation": {}
    },
    {
        "label": "RaisesLint",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "peekOfCode": "RaisesLint = _reflection.GeneratedProtocolMessageType('RaisesLint', (_message.Message,), {\n  'DESCRIPTOR' : _RAISESLINT,\n  '__module__' : 'api_report_pb2'\n  # @@protoc_insertion_point(class_scope:tensorflow_docs.api_report.schema.RaisesLint)\n  })\n_sym_db.RegisterMessage(RaisesLint)\nApiSymbolMetric = _reflection.GeneratedProtocolMessageType('ApiSymbolMetric', (_message.Message,), {\n  'DESCRIPTOR' : _APISYMBOLMETRIC,\n  '__module__' : 'api_report_pb2'\n  # @@protoc_insertion_point(class_scope:tensorflow_docs.api_report.schema.ApiSymbolMetric)",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "documentation": {}
    },
    {
        "label": "ApiSymbolMetric",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "peekOfCode": "ApiSymbolMetric = _reflection.GeneratedProtocolMessageType('ApiSymbolMetric', (_message.Message,), {\n  'DESCRIPTOR' : _APISYMBOLMETRIC,\n  '__module__' : 'api_report_pb2'\n  # @@protoc_insertion_point(class_scope:tensorflow_docs.api_report.schema.ApiSymbolMetric)\n  })\n_sym_db.RegisterMessage(ApiSymbolMetric)\nApiReport = _reflection.GeneratedProtocolMessageType('ApiReport', (_message.Message,), {\n  'DESCRIPTOR' : _APIREPORT,\n  '__module__' : 'api_report_pb2'\n  # @@protoc_insertion_point(class_scope:tensorflow_docs.api_report.schema.ApiReport)",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "documentation": {}
    },
    {
        "label": "ApiReport",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "peekOfCode": "ApiReport = _reflection.GeneratedProtocolMessageType('ApiReport', (_message.Message,), {\n  'DESCRIPTOR' : _APIREPORT,\n  '__module__' : 'api_report_pb2'\n  # @@protoc_insertion_point(class_scope:tensorflow_docs.api_report.schema.ApiReport)\n  })\n_sym_db.RegisterMessage(ApiReport)\n# @@protoc_insertion_point(module_scope)",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.schema.api_report_generated_pb2",
        "documentation": {}
    },
    {
        "label": "ReturnVisitor",
        "kind": 6,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.linter",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.linter",
        "peekOfCode": "class ReturnVisitor(ast.NodeVisitor):\n  \"\"\"Visits the Returns node in an AST.\"\"\"\n  def __init__(self) -> None:\n    self.total_returns = []\n  def visit_Return(self, node) -> None:  # pylint: disable=invalid-name\n    if node.value is None:\n      self.total_returns.append('None')\n    else:\n      self.total_returns.append(astor.to_source(node.value))\ndef lint_returns(",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.linter",
        "documentation": {}
    },
    {
        "label": "RaiseVisitor",
        "kind": 6,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.linter",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.linter",
        "peekOfCode": "class RaiseVisitor(ast.NodeVisitor):\n  \"\"\"Visits the Raises node in an AST.\"\"\"\n  def __init__(self) -> None:\n    self.total_raises = []\n  def visit_Raise(self, node) -> None:  # pylint: disable=invalid-name\n    # This `if` block means that there is a bare raise in the code.\n    if node.exc is None:\n      return\n    self.total_raises.append(astor.to_source(node.exc.func).strip())\ndef lint_raises(page_info: parser.PageInfo) -> api_report_pb2.RaisesLint:",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.linter",
        "documentation": {}
    },
    {
        "label": "lint_params",
        "kind": 2,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.linter",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.linter",
        "peekOfCode": "def lint_params(page_info: parser.PageInfo) -> api_report_pb2.ParameterLint:\n  \"\"\"Lints the parameters of a docstring.\n  Args:\n    page_info: A `PageInfo` object containing the information of a page\n      generated via the api generation.\n  Returns:\n    A filled `DescriptionLint` proto object.\n  \"\"\"\n  param_lint = api_report_pb2.ParameterLint()\n  reserved_keywords = frozenset(['self', 'cls', '_cls'])",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.linter",
        "documentation": {}
    },
    {
        "label": "lint_description",
        "kind": 2,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.linter",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.linter",
        "peekOfCode": "def lint_description(\n    page_info: parser.PageInfo) -> api_report_pb2.DescriptionLint:\n  \"\"\"Lints the description of a docstring.\n  If a field in the proto is assigned 0, then it means that that field doesn't\n  exist.\n  Args:\n    page_info: A `PageInfo` object containing the information of a page\n      generated via the api generation.\n  Returns:\n    A filled `DescriptionLint` proto object.",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.linter",
        "documentation": {}
    },
    {
        "label": "lint_usage_example",
        "kind": 2,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.linter",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.linter",
        "peekOfCode": "def lint_usage_example(\n    page_info: parser.PageInfo) -> api_report_pb2.UsageExampleLint:\n  \"\"\"Counts the number of doctests and untested examples in a docstring.\n  Args:\n    page_info: A `PageInfo` object containing the information of a page\n      generated via the api generation.\n  Returns:\n    A filled `UsageExampleLint` proto object.\n  \"\"\"\n  description = []",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.linter",
        "documentation": {}
    },
    {
        "label": "lint_returns",
        "kind": 2,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.linter",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.linter",
        "peekOfCode": "def lint_returns(\n    page_info: parser.PageInfo) -> Optional[api_report_pb2.ReturnLint]:\n  \"\"\"\"Lints the returns/yields block in the docstring.\n  This linter only checks if a `Returns`/`Yields` block exists in the docstring\n  if it finds `return`/`yield` keyword in the source code.\n  Args:\n    page_info: A `PageInfo` object containing the information of a page\n      generated via the api generation.\n  Returns:\n    A filled `ReturnLint` proto object.",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.linter",
        "documentation": {}
    },
    {
        "label": "lint_raises",
        "kind": 2,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.linter",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.linter",
        "peekOfCode": "def lint_raises(page_info: parser.PageInfo) -> api_report_pb2.RaisesLint:\n  \"\"\"Lints the raises block in the docstring.\n  The total raises in code are extracted via an AST and compared against those\n  extracted from the docstring.\n  Args:\n    page_info: A `PageInfo` object containing the information of a page\n      generated via the api generation.\n  Returns:\n    A filled `RaisesLint` proto object.\n  \"\"\"",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.linter",
        "documentation": {}
    },
    {
        "label": "_EXAMPLE_RE",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.linter",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.linter",
        "peekOfCode": "_EXAMPLE_RE = re.compile(\n    r\"\"\"\n    (?P<indent>\\ *)(?P<content>```.*?\\n\\s*?```)\n    \"\"\", re.VERBOSE | re.DOTALL)\ndef lint_usage_example(\n    page_info: parser.PageInfo) -> api_report_pb2.UsageExampleLint:\n  \"\"\"Counts the number of doctests and untested examples in a docstring.\n  Args:\n    page_info: A `PageInfo` object containing the information of a page\n      generated via the api generation.",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.linter",
        "documentation": {}
    },
    {
        "label": "DummyVisitor",
        "kind": 6,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.linter_test",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.linter_test",
        "peekOfCode": "class DummyVisitor(object):\n  def __init__(self, index, duplicate_of):\n    self.index = index\n    self.duplicate_of = duplicate_of\nclass TestClass:\n  \"\"\"Class docstring.\n  Some words here.\n  Another paragraph.\n  >>> x = 1\n  >>> print(x)",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.linter_test",
        "documentation": {}
    },
    {
        "label": "TestClass",
        "kind": 6,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.linter_test",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.linter_test",
        "peekOfCode": "class TestClass:\n  \"\"\"Class docstring.\n  Some words here.\n  Another paragraph.\n  >>> x = 1\n  >>> print(x)\n  1\n  >>> x += 2\n  >>> print(x)\n  3",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.linter_test",
        "documentation": {}
    },
    {
        "label": "LinterTest",
        "kind": 6,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.linter_test",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.linter_test",
        "peekOfCode": "class LinterTest(absltest.TestCase):\n  def setUp(self):\n    super(LinterTest, self).setUp()\n    index = {\n        'TestClass': TestClass,\n        'TestClass.__init__': TestClass.__init__,\n        'TestClass.method_one': TestClass.method_one,\n        'TestClass.temp_c': TestClass.temp_c,\n    }\n    tree = {",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.linter_test",
        "documentation": {}
    },
    {
        "label": "ApiReport",
        "kind": 6,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.utils",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.utils",
        "peekOfCode": "class ApiReport:\n  \"\"\"Generates the API report for a package.\"\"\"\n  def __init__(self):\n    self.api_report = api_report_pb2.ApiReport()\n    invocation_timestamp = timestamp_pb2.Timestamp()\n    invocation_timestamp.GetCurrentTime()\n    self.api_report.timestamp.CopyFrom(invocation_timestamp)\n    self.api_report.date = invocation_timestamp.ToJsonString()\n  def _lint(\n      self,",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.report.utils",
        "documentation": {}
    },
    {
        "label": "set_deprecated",
        "kind": 2,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_controls",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_controls",
        "peekOfCode": "def set_deprecated(obj: T) -> T:\n  \"\"\"Explicitly tag an object as deprecated for the doc generator.\"\"\"\n  setattr(obj, _DEPRECATED, None)\n  return obj\ndef is_deprecated(obj) -> bool:\n  return hasattr(obj, _DEPRECATED)\n_NO_SEARCH_HINTS = \"_tf_docs_no_search_hints\"\ndef hide_from_search(obj: T) -> T:\n  \"\"\"Marks an object so metadata search hints will not be included on it's page.\n  The page is set to \"noindex\" to hide it from search.",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_controls",
        "documentation": {}
    },
    {
        "label": "is_deprecated",
        "kind": 2,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_controls",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_controls",
        "peekOfCode": "def is_deprecated(obj) -> bool:\n  return hasattr(obj, _DEPRECATED)\n_NO_SEARCH_HINTS = \"_tf_docs_no_search_hints\"\ndef hide_from_search(obj: T) -> T:\n  \"\"\"Marks an object so metadata search hints will not be included on it's page.\n  The page is set to \"noindex\" to hide it from search.\n  Note: This only makes sense to apply to functions, classes and modules.\n  Constants, and methods do not get their own pages.\n  Args:\n    obj: the object to hide.",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_controls",
        "documentation": {}
    },
    {
        "label": "hide_from_search",
        "kind": 2,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_controls",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_controls",
        "peekOfCode": "def hide_from_search(obj: T) -> T:\n  \"\"\"Marks an object so metadata search hints will not be included on it's page.\n  The page is set to \"noindex\" to hide it from search.\n  Note: This only makes sense to apply to functions, classes and modules.\n  Constants, and methods do not get their own pages.\n  Args:\n    obj: the object to hide.\n  Returns:\n    The object.\n  \"\"\"",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_controls",
        "documentation": {}
    },
    {
        "label": "should_hide_from_search",
        "kind": 2,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_controls",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_controls",
        "peekOfCode": "def should_hide_from_search(obj) -> bool:\n  \"\"\"Returns true if metadata search hints should not be included.\"\"\"\n  return hasattr(obj, _NO_SEARCH_HINTS)\n_CUSTOM_PAGE_CONTENT = \"_tf_docs_custom_page_content\"\ndef set_custom_page_content(obj, content):\n  \"\"\"Replace most of the generated page with custom content.\"\"\"\n  setattr(obj, _CUSTOM_PAGE_CONTENT, content)\ndef get_custom_page_content(obj):\n  \"\"\"Gets custom page content if available.\"\"\"\n  return getattr(obj, _CUSTOM_PAGE_CONTENT, None)",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_controls",
        "documentation": {}
    },
    {
        "label": "set_custom_page_content",
        "kind": 2,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_controls",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_controls",
        "peekOfCode": "def set_custom_page_content(obj, content):\n  \"\"\"Replace most of the generated page with custom content.\"\"\"\n  setattr(obj, _CUSTOM_PAGE_CONTENT, content)\ndef get_custom_page_content(obj):\n  \"\"\"Gets custom page content if available.\"\"\"\n  return getattr(obj, _CUSTOM_PAGE_CONTENT, None)\n_DO_NOT_DOC = \"_tf_docs_do_not_document\"\ndef do_not_generate_docs(obj: T) -> T:\n  \"\"\"A decorator: Do not generate docs for this object.\n  For example the following classes:",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_controls",
        "documentation": {}
    },
    {
        "label": "get_custom_page_content",
        "kind": 2,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_controls",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_controls",
        "peekOfCode": "def get_custom_page_content(obj):\n  \"\"\"Gets custom page content if available.\"\"\"\n  return getattr(obj, _CUSTOM_PAGE_CONTENT, None)\n_DO_NOT_DOC = \"_tf_docs_do_not_document\"\ndef do_not_generate_docs(obj: T) -> T:\n  \"\"\"A decorator: Do not generate docs for this object.\n  For example the following classes:\n  ```\n  class Parent(object):\n    def method1(self):",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_controls",
        "documentation": {}
    },
    {
        "label": "do_not_generate_docs",
        "kind": 2,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_controls",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_controls",
        "peekOfCode": "def do_not_generate_docs(obj: T) -> T:\n  \"\"\"A decorator: Do not generate docs for this object.\n  For example the following classes:\n  ```\n  class Parent(object):\n    def method1(self):\n      pass\n    def method2(self):\n      pass\n  class Child(Parent):",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_controls",
        "documentation": {}
    },
    {
        "label": "do_not_doc_inheritable",
        "kind": 2,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_controls",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_controls",
        "peekOfCode": "def do_not_doc_inheritable(obj: T) -> T:\n  \"\"\"A decorator: Do not generate docs for this method.\n  This version of the decorator is \"inherited\" by subclasses. No docs will be\n  generated for the decorated method in any subclass. Even if the sub-class\n  overrides the method.\n  For example, to ensure that `method1` is **never documented** use this\n  decorator on the base-class:\n  ```\n  class Parent(object):\n    @do_not_doc_inheritable",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_controls",
        "documentation": {}
    },
    {
        "label": "for_subclass_implementers",
        "kind": 2,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_controls",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_controls",
        "peekOfCode": "def for_subclass_implementers(obj: T) -> T:\n  \"\"\"A decorator: Only generate docs for this method in the defining class.\n  Also group this method's docs with and `@abstractmethod` in the class's docs.\n  No docs will generated for this class attribute in sub-classes.\n  The canonical use case for this is `tf.keras.layers.Layer.call`: It's a\n  public method, essential for anyone implementing a subclass, but it should\n  never be called directly.\n  Works on method, or other class-attributes.\n  When generating docs for a class's arributes, the `__mro__` is searched and\n  the attribute will be skipped if this decorator is detected on the attribute",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_controls",
        "documentation": {}
    },
    {
        "label": "doc_private",
        "kind": 2,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_controls",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_controls",
        "peekOfCode": "def doc_private(obj: T) -> T:\n  \"\"\"A decorator: Generates docs for private methods/functions.\n  For example:\n  ```\n  class Try:\n    @doc_controls.doc_private\n    def _private(self):\n      ...\n  ```\n  As a rule of thumb, private(beginning with `_`) methods/functions are",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_controls",
        "documentation": {}
    },
    {
        "label": "should_doc_private",
        "kind": 2,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_controls",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_controls",
        "peekOfCode": "def should_doc_private(obj) -> bool:\n  return hasattr(obj, _DOC_PRIVATE)\n_DOC_IN_CURRENT_AND_SUBCLASSES = \"_tf_docs_doc_in_current_and_subclasses\"\ndef doc_in_current_and_subclasses(obj: T) -> T:\n  \"\"\"Overrides `do_not_doc_in_subclasses` decorator.\n  If this decorator is set on a child class's method whose parent's method\n  contains `do_not_doc_in_subclasses`, then that will be overriden and the\n  child method will get documented. All classes inherting from the child will\n  also document that method.\n  For example:",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_controls",
        "documentation": {}
    },
    {
        "label": "doc_in_current_and_subclasses",
        "kind": 2,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_controls",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_controls",
        "peekOfCode": "def doc_in_current_and_subclasses(obj: T) -> T:\n  \"\"\"Overrides `do_not_doc_in_subclasses` decorator.\n  If this decorator is set on a child class's method whose parent's method\n  contains `do_not_doc_in_subclasses`, then that will be overriden and the\n  child method will get documented. All classes inherting from the child will\n  also document that method.\n  For example:\n  ```\n  class Parent:\n    @do_not_doc_in_subclasses",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_controls",
        "documentation": {}
    },
    {
        "label": "should_skip",
        "kind": 2,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_controls",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_controls",
        "peekOfCode": "def should_skip(obj) -> bool:\n  \"\"\"Returns true if docs generation should be skipped for this object.\n  Checks for the `do_not_generate_docs` or `do_not_doc_inheritable` decorators.\n  Args:\n    obj: The object to document, or skip.\n  Returns:\n    True if the object should be skipped\n  \"\"\"\n  if isinstance(obj, type):\n    # For classes, only skip if the attribute is set on _this_ class.",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_controls",
        "documentation": {}
    },
    {
        "label": "should_skip_class_attr",
        "kind": 2,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_controls",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_controls",
        "peekOfCode": "def should_skip_class_attr(cls, name):\n  \"\"\"Returns true if docs should be skipped for this class attribute.\n  Args:\n    cls: The class the attribute belongs to.\n    name: The name of the attribute.\n  Returns:\n    True if the attribute should be skipped.\n  \"\"\"\n  # Get the object with standard lookup, from the nearest\n  # defining parent.",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_controls",
        "documentation": {}
    },
    {
        "label": "decorate_all_class_attributes",
        "kind": 2,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_controls",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_controls",
        "peekOfCode": "def decorate_all_class_attributes(decorator, cls, skip: Iterable[str]):\n  \"\"\"Applies `decorator` to every attribute defined in `cls`.\n  Args:\n    decorator: The decorator to apply.\n    cls: The class to apply the decorator to.\n    skip: A collection of attribute names that the decorator should not be\n      aplied to.\n  \"\"\"\n  skip = frozenset(skip)\n  class_contents = list(cls.__dict__.items())",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_controls",
        "documentation": {}
    },
    {
        "label": "T",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_controls",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_controls",
        "peekOfCode": "T = TypeVar(\"T\")\n_DEPRECATED = \"_tf_docs_deprecated\"\ndef set_deprecated(obj: T) -> T:\n  \"\"\"Explicitly tag an object as deprecated for the doc generator.\"\"\"\n  setattr(obj, _DEPRECATED, None)\n  return obj\ndef is_deprecated(obj) -> bool:\n  return hasattr(obj, _DEPRECATED)\n_NO_SEARCH_HINTS = \"_tf_docs_no_search_hints\"\ndef hide_from_search(obj: T) -> T:",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_controls",
        "documentation": {}
    },
    {
        "label": "_DEPRECATED",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_controls",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_controls",
        "peekOfCode": "_DEPRECATED = \"_tf_docs_deprecated\"\ndef set_deprecated(obj: T) -> T:\n  \"\"\"Explicitly tag an object as deprecated for the doc generator.\"\"\"\n  setattr(obj, _DEPRECATED, None)\n  return obj\ndef is_deprecated(obj) -> bool:\n  return hasattr(obj, _DEPRECATED)\n_NO_SEARCH_HINTS = \"_tf_docs_no_search_hints\"\ndef hide_from_search(obj: T) -> T:\n  \"\"\"Marks an object so metadata search hints will not be included on it's page.",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_controls",
        "documentation": {}
    },
    {
        "label": "_NO_SEARCH_HINTS",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_controls",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_controls",
        "peekOfCode": "_NO_SEARCH_HINTS = \"_tf_docs_no_search_hints\"\ndef hide_from_search(obj: T) -> T:\n  \"\"\"Marks an object so metadata search hints will not be included on it's page.\n  The page is set to \"noindex\" to hide it from search.\n  Note: This only makes sense to apply to functions, classes and modules.\n  Constants, and methods do not get their own pages.\n  Args:\n    obj: the object to hide.\n  Returns:\n    The object.",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_controls",
        "documentation": {}
    },
    {
        "label": "_CUSTOM_PAGE_CONTENT",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_controls",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_controls",
        "peekOfCode": "_CUSTOM_PAGE_CONTENT = \"_tf_docs_custom_page_content\"\ndef set_custom_page_content(obj, content):\n  \"\"\"Replace most of the generated page with custom content.\"\"\"\n  setattr(obj, _CUSTOM_PAGE_CONTENT, content)\ndef get_custom_page_content(obj):\n  \"\"\"Gets custom page content if available.\"\"\"\n  return getattr(obj, _CUSTOM_PAGE_CONTENT, None)\n_DO_NOT_DOC = \"_tf_docs_do_not_document\"\ndef do_not_generate_docs(obj: T) -> T:\n  \"\"\"A decorator: Do not generate docs for this object.",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_controls",
        "documentation": {}
    },
    {
        "label": "_DO_NOT_DOC",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_controls",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_controls",
        "peekOfCode": "_DO_NOT_DOC = \"_tf_docs_do_not_document\"\ndef do_not_generate_docs(obj: T) -> T:\n  \"\"\"A decorator: Do not generate docs for this object.\n  For example the following classes:\n  ```\n  class Parent(object):\n    def method1(self):\n      pass\n    def method2(self):\n      pass",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_controls",
        "documentation": {}
    },
    {
        "label": "_DO_NOT_DOC_INHERITABLE",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_controls",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_controls",
        "peekOfCode": "_DO_NOT_DOC_INHERITABLE = \"_tf_docs_do_not_doc_inheritable\"\ndef do_not_doc_inheritable(obj: T) -> T:\n  \"\"\"A decorator: Do not generate docs for this method.\n  This version of the decorator is \"inherited\" by subclasses. No docs will be\n  generated for the decorated method in any subclass. Even if the sub-class\n  overrides the method.\n  For example, to ensure that `method1` is **never documented** use this\n  decorator on the base-class:\n  ```\n  class Parent(object):",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_controls",
        "documentation": {}
    },
    {
        "label": "_FOR_SUBCLASS_IMPLEMENTERS",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_controls",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_controls",
        "peekOfCode": "_FOR_SUBCLASS_IMPLEMENTERS = \"_tf_docs_tools_for_subclass_implementers\"\ndef for_subclass_implementers(obj: T) -> T:\n  \"\"\"A decorator: Only generate docs for this method in the defining class.\n  Also group this method's docs with and `@abstractmethod` in the class's docs.\n  No docs will generated for this class attribute in sub-classes.\n  The canonical use case for this is `tf.keras.layers.Layer.call`: It's a\n  public method, essential for anyone implementing a subclass, but it should\n  never be called directly.\n  Works on method, or other class-attributes.\n  When generating docs for a class's arributes, the `__mro__` is searched and",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_controls",
        "documentation": {}
    },
    {
        "label": "do_not_doc_in_subclasses",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_controls",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_controls",
        "peekOfCode": "do_not_doc_in_subclasses = for_subclass_implementers\n_DOC_PRIVATE = \"_tf_docs_doc_private\"\ndef doc_private(obj: T) -> T:\n  \"\"\"A decorator: Generates docs for private methods/functions.\n  For example:\n  ```\n  class Try:\n    @doc_controls.doc_private\n    def _private(self):\n      ...",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_controls",
        "documentation": {}
    },
    {
        "label": "_DOC_PRIVATE",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_controls",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_controls",
        "peekOfCode": "_DOC_PRIVATE = \"_tf_docs_doc_private\"\ndef doc_private(obj: T) -> T:\n  \"\"\"A decorator: Generates docs for private methods/functions.\n  For example:\n  ```\n  class Try:\n    @doc_controls.doc_private\n    def _private(self):\n      ...\n  ```",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_controls",
        "documentation": {}
    },
    {
        "label": "_DOC_IN_CURRENT_AND_SUBCLASSES",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_controls",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_controls",
        "peekOfCode": "_DOC_IN_CURRENT_AND_SUBCLASSES = \"_tf_docs_doc_in_current_and_subclasses\"\ndef doc_in_current_and_subclasses(obj: T) -> T:\n  \"\"\"Overrides `do_not_doc_in_subclasses` decorator.\n  If this decorator is set on a child class's method whose parent's method\n  contains `do_not_doc_in_subclasses`, then that will be overriden and the\n  child method will get documented. All classes inherting from the child will\n  also document that method.\n  For example:\n  ```\n  class Parent:",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_controls",
        "documentation": {}
    },
    {
        "label": "DocControlsTest",
        "kind": 6,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_controls_test",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_controls_test",
        "peekOfCode": "class DocControlsTest(absltest.TestCase):\n  def test_do_not_generate_docs(self):\n    @doc_controls.do_not_generate_docs\n    def dummy_function():\n      pass\n    self.assertTrue(doc_controls.should_skip(dummy_function))\n  def test_do_not_doc_on_method(self):\n    \"\"\"The simple decorator is not aware of inheritance.\"\"\"\n    class Parent(object):\n      @doc_controls.do_not_generate_docs",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_controls_test",
        "documentation": {}
    },
    {
        "label": "ApiTreeNode",
        "kind": 6,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_generator_visitor",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_generator_visitor",
        "peekOfCode": "class ApiTreeNode(object):\n  \"\"\"Represents a single API end-point.\n  Attributes:\n    path: A tuple of strings containing the path to the object from the root\n      like `('tf', 'losses', 'hinge')`\n    obj: The python object.\n    children: A dictionary from short name to `ApiTreeNode`, including the\n      children nodes.\n    parent: The parent node.\n    short_name: The last path component",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_generator_visitor",
        "documentation": {}
    },
    {
        "label": "ApiTree",
        "kind": 6,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_generator_visitor",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_generator_visitor",
        "peekOfCode": "class ApiTree(object):\n  \"\"\"Represents all api end-points as a tree.\n  Items must be inserted in order, from root to leaf.\n  Attributes:\n    index: A dict, mapping from path tuples to `ApiTreeNode`.\n    aliases: A dict, mapping from object ids to a list of all `ApiTreeNode` that\n      refer to the object.\n    root: The root `ApiTreeNode`\n  \"\"\"\n  def __init__(self):",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_generator_visitor",
        "documentation": {}
    },
    {
        "label": "DocGeneratorVisitor",
        "kind": 6,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_generator_visitor",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_generator_visitor",
        "peekOfCode": "class DocGeneratorVisitor(object):\n  \"\"\"A visitor that generates docs for a python object when __call__ed.\"\"\"\n  def __init__(self):\n    \"\"\"Make a visitor.\n    This visitor expects to be called on each node in the api. It is passed the\n    path to an object, the object, and the filtered list of the object's\n    children. (see the `__call__` method for details.\n    This object accumulates the various data-structures necessary to build the\n    docs, including (see the property definitions for details.):\n    In the decsription below \"main name\" is the object's preferred fully",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_generator_visitor",
        "documentation": {}
    },
    {
        "label": "maybe_singleton",
        "kind": 2,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_generator_visitor",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_generator_visitor",
        "peekOfCode": "def maybe_singleton(py_object: Any) -> bool:\n  \"\"\"Returns `True` if `py_object` might be a singleton value .\n  Many immutable values in python act like singletons: small ints, some strings,\n  Bools, None, the empty tuple.\n  We can't rely on looking these up by their `id()` to find their name or\n  duplicates.\n  This function checks if the object is one of those maybe singleton values.\n  Args:\n    py_object: the object to check.\n  Returns:",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_generator_visitor",
        "documentation": {}
    },
    {
        "label": "ApiPath",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_generator_visitor",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_generator_visitor",
        "peekOfCode": "ApiPath = Tuple[str, ...]\ndef maybe_singleton(py_object: Any) -> bool:\n  \"\"\"Returns `True` if `py_object` might be a singleton value .\n  Many immutable values in python act like singletons: small ints, some strings,\n  Bools, None, the empty tuple.\n  We can't rely on looking these up by their `id()` to find their name or\n  duplicates.\n  This function checks if the object is one of those maybe singleton values.\n  Args:\n    py_object: the object to check.",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_generator_visitor",
        "documentation": {}
    },
    {
        "label": "NoDunderVisitor",
        "kind": 6,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_generator_visitor_test",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_generator_visitor_test",
        "peekOfCode": "class NoDunderVisitor(doc_generator_visitor.DocGeneratorVisitor):\n  def __call__(self, parent_name, parent, children):\n    \"\"\"Drop all the dunder methods to make testing easier.\"\"\"\n    children = [\n        (name, obj) for (name, obj) in children if not name.startswith('_')\n    ]\n    return super(NoDunderVisitor, self).__call__(parent_name, parent, children)\nclass DocGeneratorVisitorTest(absltest.TestCase):\n  def test_call_module(self):\n    visitor = doc_generator_visitor.DocGeneratorVisitor()",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_generator_visitor_test",
        "documentation": {}
    },
    {
        "label": "DocGeneratorVisitorTest",
        "kind": 6,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_generator_visitor_test",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_generator_visitor_test",
        "peekOfCode": "class DocGeneratorVisitorTest(absltest.TestCase):\n  def test_call_module(self):\n    visitor = doc_generator_visitor.DocGeneratorVisitor()\n    visitor(\n        ('doc_generator_visitor',), doc_generator_visitor,\n        [('DocGeneratorVisitor', doc_generator_visitor.DocGeneratorVisitor)])\n    self.assertEqual({'doc_generator_visitor': ['DocGeneratorVisitor']},\n                     visitor.tree)\n    self.assertEqual({\n        'doc_generator_visitor': doc_generator_visitor,",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_generator_visitor_test",
        "documentation": {}
    },
    {
        "label": "ApiTreeTest",
        "kind": 6,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_generator_visitor_test",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_generator_visitor_test",
        "peekOfCode": "class ApiTreeTest(absltest.TestCase):\n  def test_contains(self):\n    tf = argparse.Namespace()\n    tf.sub = argparse.Namespace()\n    tree = doc_generator_visitor.ApiTree()\n    tree[('tf',)] = tf\n    tree[('tf', 'sub')] = tf.sub\n    self.assertIn(('tf',), tree)\n    self.assertIn(('tf', 'sub'), tree)\n  def test_node_insertion(self):",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.doc_generator_visitor_test",
        "documentation": {}
    },
    {
        "label": "TocNode",
        "kind": 6,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.generate_lib",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.generate_lib",
        "peekOfCode": "class TocNode(object):\n  \"\"\"Represents a node in the TOC.\n  Attributes:\n    full_name: Name of the module.\n    short_name: The last path component.\n    py_object: Python object of the module.\n    path: Path to the module's page on tensorflow.org relative to\n      tensorflow.org.\n    experimental: Whether the module is experimental or not.\n    deprecated: Whether the module is deprecated or not.",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.generate_lib",
        "documentation": {}
    },
    {
        "label": "Module",
        "kind": 6,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.generate_lib",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.generate_lib",
        "peekOfCode": "class Module(TocNode):\n  \"\"\"Represents a single module and its children and submodules.\n  Attributes:\n    full_name: Name of the module.\n    short_name: The last path component.\n    py_object: Python object of the module.\n    title: Title of the module in _toc.yaml\n    path: Path to the module's page on tensorflow.org relative to\n      tensorflow.org.\n    children: List of attributes on the module.",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.generate_lib",
        "documentation": {}
    },
    {
        "label": "ModuleChild",
        "kind": 6,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.generate_lib",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.generate_lib",
        "peekOfCode": "class ModuleChild(TocNode):\n  \"\"\"Represents a child of a module.\n  Attributes:\n    full_name: Name of the child.\n    short_name: The last path component.\n    py_object: Python object of the child.\n    title: Title of the module in _toc.yaml\n    path: Path to the module's page on tensorflow.org relative to\n      tensorflow.org.\n    experimental: Whether the module child is experimental or not.",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.generate_lib",
        "documentation": {}
    },
    {
        "label": "GenerateToc",
        "kind": 6,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.generate_lib",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.generate_lib",
        "peekOfCode": "class GenerateToc(object):\n  \"\"\"Generates a data structure that defines the structure of _toc.yaml.\"\"\"\n  def __init__(self, modules):\n    self._modules = modules\n  def _create_graph(self):\n    \"\"\"Creates a graph to allow a dfs traversal on it to generate the toc.\n    Each graph key contains a module and its value is an object of `Module`\n    class. That module object contains a list of submodules.\n    Example low-level structure of the graph is as follows:\n    {",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.generate_lib",
        "documentation": {}
    },
    {
        "label": "DocGenerator",
        "kind": 6,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.generate_lib",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.generate_lib",
        "peekOfCode": "class DocGenerator:\n  \"\"\"Main entry point for generating docs.\"\"\"\n  def __init__(\n      self,\n      root_title: str,\n      py_modules: Sequence[Tuple[str, Any]],\n      base_dir: Optional[Sequence[Union[str, pathlib.Path]]] = None,\n      code_url_prefix: Sequence[str] = (),\n      search_hints: bool = True,\n      site_path: str = 'api_docs/python',",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.generate_lib",
        "documentation": {}
    },
    {
        "label": "dict_representer",
        "kind": 2,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.generate_lib",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.generate_lib",
        "peekOfCode": "def dict_representer(dumper, data):\n  return dumper.represent_dict(data.items())\ndef dict_constructor(loader, node):\n  return collections.OrderedDict(loader.construct_pairs(node))\nyaml.add_representer(collections.OrderedDict, dict_representer)\nyaml.add_constructor(_mapping_tag, dict_constructor)\nclass TocNode(object):\n  \"\"\"Represents a node in the TOC.\n  Attributes:\n    full_name: Name of the module.",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.generate_lib",
        "documentation": {}
    },
    {
        "label": "dict_constructor",
        "kind": 2,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.generate_lib",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.generate_lib",
        "peekOfCode": "def dict_constructor(loader, node):\n  return collections.OrderedDict(loader.construct_pairs(node))\nyaml.add_representer(collections.OrderedDict, dict_representer)\nyaml.add_constructor(_mapping_tag, dict_constructor)\nclass TocNode(object):\n  \"\"\"Represents a node in the TOC.\n  Attributes:\n    full_name: Name of the module.\n    short_name: The last path component.\n    py_object: Python object of the module.",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.generate_lib",
        "documentation": {}
    },
    {
        "label": "write_docs",
        "kind": 2,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.generate_lib",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.generate_lib",
        "peekOfCode": "def write_docs(\n    *,\n    output_dir: Union[str, pathlib.Path],\n    parser_config: parser.ParserConfig,\n    yaml_toc: bool,\n    root_module_name: str,\n    root_title: str = 'TensorFlow',\n    search_hints: bool = True,\n    site_path: str = 'api_docs/python',\n    gen_redirects: bool = True,",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.generate_lib",
        "documentation": {}
    },
    {
        "label": "add_dict_to_dict",
        "kind": 2,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.generate_lib",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.generate_lib",
        "peekOfCode": "def add_dict_to_dict(add_from, add_to):\n  for key in add_from:\n    if key in add_to:\n      add_to[key].extend(add_from[key])\n    else:\n      add_to[key] = add_from[key]\ndef extract(py_modules,\n            base_dir,\n            private_map,\n            visitor_cls=doc_generator_visitor.DocGeneratorVisitor,",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.generate_lib",
        "documentation": {}
    },
    {
        "label": "extract",
        "kind": 2,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.generate_lib",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.generate_lib",
        "peekOfCode": "def extract(py_modules,\n            base_dir,\n            private_map,\n            visitor_cls=doc_generator_visitor.DocGeneratorVisitor,\n            callbacks=None):\n  \"\"\"Walks the module contents, returns an index of all visited objects.\n  The return value is an instance of `self._visitor_cls`, usually:\n  `doc_generator_visitor.DocGeneratorVisitor`\n  Args:\n    py_modules: A list containing a single (short_name, module_object) pair.",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.generate_lib",
        "documentation": {}
    },
    {
        "label": "replace_refs",
        "kind": 2,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.generate_lib",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.generate_lib",
        "peekOfCode": "def replace_refs(\n    src_dir: str,\n    output_dir: str,\n    reference_resolvers: List[parser.ReferenceResolver],\n    api_docs_relpath: List[str],\n    file_pattern: str = '*.md',\n):\n  \"\"\"Link `tf.symbol` references found in files matching `file_pattern`.\n  A matching directory structure, with the modified files is\n  written to `output_dir`.",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.generate_lib",
        "documentation": {}
    },
    {
        "label": "_mapping_tag",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.generate_lib",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.generate_lib",
        "peekOfCode": "_mapping_tag = yaml.resolver.BaseResolver.DEFAULT_MAPPING_TAG\ndef dict_representer(dumper, data):\n  return dumper.represent_dict(data.items())\ndef dict_constructor(loader, node):\n  return collections.OrderedDict(loader.construct_pairs(node))\nyaml.add_representer(collections.OrderedDict, dict_representer)\nyaml.add_constructor(_mapping_tag, dict_constructor)\nclass TocNode(object):\n  \"\"\"Represents a node in the TOC.\n  Attributes:",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.generate_lib",
        "documentation": {}
    },
    {
        "label": "EXCLUDED",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.generate_lib",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.generate_lib",
        "peekOfCode": "EXCLUDED = set(['__init__.py', 'OWNERS', 'README.txt'])\ndef replace_refs(\n    src_dir: str,\n    output_dir: str,\n    reference_resolvers: List[parser.ReferenceResolver],\n    api_docs_relpath: List[str],\n    file_pattern: str = '*.md',\n):\n  \"\"\"Link `tf.symbol` references found in files matching `file_pattern`.\n  A matching directory structure, with the modified files is",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.generate_lib",
        "documentation": {}
    },
    {
        "label": "TestClass",
        "kind": 6,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.generate_lib_test",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.generate_lib_test",
        "peekOfCode": "class TestClass(object):\n  \"\"\"Docstring for TestClass itself.\"\"\"\n  class ChildClass(object):\n    \"\"\"Docstring for a child class.\"\"\"\n    class GrandChildClass(object):\n      \"\"\"Docstring for a child of a child class.\"\"\"\n      pass\nclass DummyVisitor(object):\n  def __init__(self, index, duplicate_of):\n    self.index = index",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.generate_lib_test",
        "documentation": {}
    },
    {
        "label": "DummyVisitor",
        "kind": 6,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.generate_lib_test",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.generate_lib_test",
        "peekOfCode": "class DummyVisitor(object):\n  def __init__(self, index, duplicate_of):\n    self.index = index\n    self.duplicate_of = duplicate_of\nclass GenerateTest(absltest.TestCase):\n  _BASE_DIR = tempfile.mkdtemp()\n  def setUp(self):\n    super(GenerateTest, self).setUp()\n    self.workdir = os.path.join(self._BASE_DIR, self.id())\n    os.makedirs(self.workdir)",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.generate_lib_test",
        "documentation": {}
    },
    {
        "label": "GenerateTest",
        "kind": 6,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.generate_lib_test",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.generate_lib_test",
        "peekOfCode": "class GenerateTest(absltest.TestCase):\n  _BASE_DIR = tempfile.mkdtemp()\n  def setUp(self):\n    super(GenerateTest, self).setUp()\n    self.workdir = os.path.join(self._BASE_DIR, self.id())\n    os.makedirs(self.workdir)\n  def get_test_objects(self):\n    # These are all mutable objects, so rebuild them for each test.\n    # Don't cache the objects.\n    module = sys.modules[__name__]",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.generate_lib_test",
        "documentation": {}
    },
    {
        "label": "deprecated",
        "kind": 2,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.generate_lib_test",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.generate_lib_test",
        "peekOfCode": "def deprecated(func):\n  return func\n@deprecated\ndef test_function():\n  \"\"\"Docstring for test_function.\n  THIS FUNCTION IS DEPRECATED and will be removed after some time.\n  \"\"\"\n  pass\nclass TestClass(object):\n  \"\"\"Docstring for TestClass itself.\"\"\"",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.generate_lib_test",
        "documentation": {}
    },
    {
        "label": "test_function",
        "kind": 2,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.generate_lib_test",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.generate_lib_test",
        "peekOfCode": "def test_function():\n  \"\"\"Docstring for test_function.\n  THIS FUNCTION IS DEPRECATED and will be removed after some time.\n  \"\"\"\n  pass\nclass TestClass(object):\n  \"\"\"Docstring for TestClass itself.\"\"\"\n  class ChildClass(object):\n    \"\"\"Docstring for a child class.\"\"\"\n    class GrandChildClass(object):",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.generate_lib_test",
        "documentation": {}
    },
    {
        "label": "FLAGS",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.generate_lib_test",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.generate_lib_test",
        "peekOfCode": "FLAGS = flags.FLAGS\ndef deprecated(func):\n  return func\n@deprecated\ndef test_function():\n  \"\"\"Docstring for test_function.\n  THIS FUNCTION IS DEPRECATED and will be removed after some time.\n  \"\"\"\n  pass\nclass TestClass(object):",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.generate_lib_test",
        "documentation": {}
    },
    {
        "label": "ObjType",
        "kind": 6,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "peekOfCode": "class ObjType(enum.Enum):\n  \"\"\"Enum to standardize object type checks.\"\"\"\n  TYPE_ALIAS = 'type_alias'\n  MODULE = 'module'\n  CLASS = 'class'\n  CALLABLE = 'callable'\n  PROPERTY = 'property'\n  OTHER = 'other'\ndef get_obj_type(py_obj: Any) -> ObjType:\n  \"\"\"Get the `ObjType` for the `py_object`.\"\"\"",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "documentation": {}
    },
    {
        "label": "ParserConfig",
        "kind": 6,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "peekOfCode": "class ParserConfig(object):\n  \"\"\"Stores all indexes required to parse the docs.\"\"\"\n  def __init__(self, reference_resolver, duplicates, duplicate_of, tree, index,\n               reverse_index, base_dir, code_url_prefix):\n    \"\"\"Object with the common config for docs_for_object() calls.\n    Args:\n      reference_resolver: An instance of ReferenceResolver.\n      duplicates: A `dict` mapping fully qualified names to a set of all aliases\n        of this name. This is used to automatically generate a list of all\n        aliases for each name.",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "documentation": {}
    },
    {
        "label": "_FileLocation",
        "kind": 6,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "peekOfCode": "class _FileLocation(object):\n  \"\"\"This class indicates that the object is defined in a regular file.\n  This can be used for the `defined_in` slot of the `PageInfo` objects.\n  \"\"\"\n  def __init__(\n      self,\n      url: Optional[str] = None,\n      start_line: Optional[int] = None,\n      end_line: Optional[int] = None,\n  ) -> None:",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "documentation": {}
    },
    {
        "label": "TFDocsError",
        "kind": 6,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "peekOfCode": "class TFDocsError(Exception):\n  pass\ndef documentation_path(full_name, is_fragment=False):\n  \"\"\"Returns the file path for the documentation for the given API symbol.\n  Given the fully qualified name of a library symbol, compute the path to which\n  to write the documentation for that symbol (relative to a base directory).\n  Documentation files are organized into directories that mirror the python\n  module/class structure.\n  Args:\n    full_name: Fully qualified name of a library symbol.",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "documentation": {}
    },
    {
        "label": "_AddDoctestFences",
        "kind": 6,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "peekOfCode": "class _AddDoctestFences(object):\n  \"\"\"Adds ``` fences around doctest caret blocks >>> that don't have them.\"\"\"\n  CARET_BLOCK_RE = re.compile(\n      r\"\"\"\n    \\n                                     # After a blank line.\n    (?P<indent>\\ *)(?P<content>\\>\\>\\>.*?)  # Whitespace and a triple caret.\n    \\n\\s*?(?=\\n|$)                         # Followed by a blank line\"\"\",\n      re.VERBOSE | re.DOTALL)\n  def _sub(self, match):\n    groups = match.groupdict()",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "documentation": {}
    },
    {
        "label": "_StripTODOs",
        "kind": 6,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "peekOfCode": "class _StripTODOs(object):\n  TODO_RE = re.compile('#? *TODO.*')\n  def __call__(self, content: str) -> str:\n    return self.TODO_RE.sub('', content)\nclass _StripPylintAndPyformat(object):\n  STRIP_RE = re.compile('# *?(pylint|pyformat):.*', re.I)\n  def __call__(self, content: str) -> str:\n    return self.STRIP_RE.sub('', content)\nclass _DowngradeH1Keywords():\n  \"\"\"Convert keras docstring keyword format to google format.\"\"\"",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "documentation": {}
    },
    {
        "label": "_StripPylintAndPyformat",
        "kind": 6,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "peekOfCode": "class _StripPylintAndPyformat(object):\n  STRIP_RE = re.compile('# *?(pylint|pyformat):.*', re.I)\n  def __call__(self, content: str) -> str:\n    return self.STRIP_RE.sub('', content)\nclass _DowngradeH1Keywords():\n  \"\"\"Convert keras docstring keyword format to google format.\"\"\"\n  KEYWORD_H1_RE = re.compile(\n      r\"\"\"\n    ^                 # Start of line\n    (?P<indent>\\s*)   # Capture leading whitespace as <indent",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "documentation": {}
    },
    {
        "label": "_DowngradeH1Keywords",
        "kind": 6,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "peekOfCode": "class _DowngradeH1Keywords():\n  \"\"\"Convert keras docstring keyword format to google format.\"\"\"\n  KEYWORD_H1_RE = re.compile(\n      r\"\"\"\n    ^                 # Start of line\n    (?P<indent>\\s*)   # Capture leading whitespace as <indent\n    \\#\\s*             # A literal \"#\" and more spaces\n                      # Capture any of these keywords as <keyword>\n    (?P<keyword>Args|Arguments|Returns|Raises|Yields|Examples?|Notes?)\n    \\s*:?             # Optional whitespace and optional \":\"",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "documentation": {}
    },
    {
        "label": "IgnoreLineInBlock",
        "kind": 6,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "peekOfCode": "class IgnoreLineInBlock(object):\n  \"\"\"Ignores the lines in a block.\n  Attributes:\n    block_start: Contains the start string of a block to ignore.\n    block_end: Contains the end string of a block to ignore.\n  \"\"\"\n  def __init__(self, block_start, block_end):\n    self._block_start = block_start\n    self._block_end = block_end\n    self._in_block = False",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "documentation": {}
    },
    {
        "label": "ReferenceResolver",
        "kind": 6,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "peekOfCode": "class ReferenceResolver(object):\n  \"\"\"Class for replacing `tf.symbol` references with Markdown links.\"\"\"\n  def __init__(\n      self,\n      duplicate_of: Dict[str, str],\n      is_fragment: Dict[str, bool],\n      py_module_names: List[str],\n      site_link: Optional[str] = None,\n  ):\n    \"\"\"Initializes a Reference Resolver.",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "documentation": {}
    },
    {
        "label": "TitleBlock",
        "kind": 6,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "peekOfCode": "class TitleBlock(object):\n  \"\"\"A class to parse title blocks (like `Args:`) and convert them to markdown.\n  This handles the \"Args/Returns/Raises\" blocks and anything similar.\n  These are used to extract metadata (argument descriptions, etc), and upgrade\n  This `TitleBlock` to markdown.\n  These blocks are delimited by indentation. There must be a blank line before\n  the first `TitleBlock` in a series.\n  The expected format is:\n  ```\n  Title:",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "documentation": {}
    },
    {
        "label": "_DocstringInfo",
        "kind": 6,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "peekOfCode": "class _DocstringInfo(typing.NamedTuple):\n  brief: str\n  docstring_parts: List[Union[TitleBlock, str]]\n  compatibility: Dict[str, str]\ndef _get_other_member_doc(\n    obj: Any,\n    parser_config: ParserConfig,\n    extra_docs: Optional[Dict[int, str]],\n) -> str:\n  \"\"\"Returns the docs for other members of a module.\"\"\"",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "documentation": {}
    },
    {
        "label": "TypeAnnotationExtractor",
        "kind": 6,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "peekOfCode": "class TypeAnnotationExtractor(ast.NodeVisitor):\n  \"\"\"Extracts the type annotations by parsing the AST of a function.\"\"\"\n  def __init__(self):\n    self.annotation_dict = {}\n    self.arguments_typehint_exists = False\n    self.return_typehint_exists = False\n  def visit_FunctionDef(self, node) -> None:  # pylint: disable=invalid-name\n    \"\"\"Visits the `FunctionDef` node in AST tree and extracts the typehints.\"\"\"\n    # Capture the return type annotation.\n    if node.returns:",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "documentation": {}
    },
    {
        "label": "DataclassTypeAnnotationExtractor",
        "kind": 6,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "peekOfCode": "class DataclassTypeAnnotationExtractor(ast.NodeVisitor):\n  \"\"\"Extracts the type annotations by parsing the AST of a dataclass.\"\"\"\n  def __init__(self):\n    self.annotation_dict = {}\n    self.arguments_typehint_exists = False\n    self.return_typehint_exists = False\n  def visit_ClassDef(self, node) -> None:  # pylint: disable=invalid-name\n    # Don't visit all nodes. Only visit top-level AnnAssign nodes so that\n    # If there's an AnnAssign in a method it doesn't get picked up.\n    for sub in node.body:",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "documentation": {}
    },
    {
        "label": "ASTDefaultValueExtractor",
        "kind": 6,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "peekOfCode": "class ASTDefaultValueExtractor(ast.NodeVisitor):\n  \"\"\"Extracts the default values by parsing the AST of a function.\"\"\"\n  _PAREN_NUMBER_RE = re.compile(r'^\\(([0-9.e-]+)\\)')\n  def __init__(self):\n    self.ast_args_defaults = []\n    self.ast_kw_only_defaults = []\n  def _preprocess(self, val: str) -> str:\n    text_default_val = astor.to_source(val).strip().replace(\n        '\\t', '\\\\t').replace('\\n', '\\\\n').replace('\"\"\"', \"'\")\n    text_default_val = self._PAREN_NUMBER_RE.sub('\\\\1', text_default_val)",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "documentation": {}
    },
    {
        "label": "FormatArguments",
        "kind": 6,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "peekOfCode": "class FormatArguments(object):\n  \"\"\"Formats the arguments and adds type annotations if they exist.\"\"\"\n  _INTERNAL_NAMES = {\n      'ops.GraphKeys': 'tf.GraphKeys',\n      '_ops.GraphKeys': 'tf.GraphKeys',\n      'init_ops.zeros_initializer': 'tf.zeros_initializer',\n      'init_ops.ones_initializer': 'tf.ones_initializer',\n      'saver_pb2.SaverDef': 'tf.train.SaverDef',\n  }\n  _OBJECT_MEMORY_ADDRESS_RE = re.compile(r'<(?P<type>.+) object at 0x[\\da-f]+>')",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "documentation": {}
    },
    {
        "label": "_SignatureComponents",
        "kind": 6,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "peekOfCode": "class _SignatureComponents(NamedTuple):\n  \"\"\"Contains the components that make up the signature of a function/method.\"\"\"\n  arguments: List[str]\n  arguments_typehint_exists: bool\n  return_typehint_exists: bool\n  return_type: Optional[str] = None\n  def __str__(self):\n    arguments_signature = ''\n    if self.arguments:\n      str_signature = ',\\n'.join(self.arguments)",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "documentation": {}
    },
    {
        "label": "MemberInfo",
        "kind": 6,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "peekOfCode": "class MemberInfo(NamedTuple):\n  \"\"\"Describes an attribute of a class or module.\"\"\"\n  short_name: str\n  full_name: str\n  py_object: Any\n  doc: _DocstringInfo\n  url: str\nclass MethodInfo(NamedTuple):\n  \"\"\"Described a method.\"\"\"\n  short_name: str",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "documentation": {}
    },
    {
        "label": "MethodInfo",
        "kind": 6,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "peekOfCode": "class MethodInfo(NamedTuple):\n  \"\"\"Described a method.\"\"\"\n  short_name: str\n  full_name: str\n  py_object: Any\n  doc: _DocstringInfo\n  url: str\n  signature: _SignatureComponents\n  decorators: List[str]\n  defined_in: Optional[_FileLocation]",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "documentation": {}
    },
    {
        "label": "PageInfo",
        "kind": 6,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "peekOfCode": "class PageInfo:\n  \"\"\"Base-class for api_pages objects.\n  Converted to markdown by pretty_docs.py.\n  Attributes:\n    full_name: The full, main name, of the object being documented.\n    short_name: The last part of the full name.\n    py_object: The object being documented.\n    defined_in: A _FileLocation describing where the object was defined.\n    aliases: A list of full-name for all aliases for this object.\n    doc: A list of objects representing the docstring. These can all be",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "documentation": {}
    },
    {
        "label": "FunctionPageInfo",
        "kind": 6,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "peekOfCode": "class FunctionPageInfo(PageInfo):\n  \"\"\"Collects docs For a function Page.\n  Attributes:\n    full_name: The full, main name, of the object being documented.\n    short_name: The last part of the full name.\n    py_object: The object being documented.\n    defined_in: A _FileLocation describing where the object was defined.\n    aliases: A list of full-name for all aliases for this object.\n    doc: A list of objects representing the docstring. These can all be\n      converted to markdown using str().",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "documentation": {}
    },
    {
        "label": "TypeAliasPageInfo",
        "kind": 6,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "peekOfCode": "class TypeAliasPageInfo(PageInfo):\n  \"\"\"Collects docs For a type alias page.\n  Attributes:\n    full_name: The full, main name, of the object being documented.\n    short_name: The last part of the full name.\n    py_object: The object being documented.\n    defined_in: A _FileLocation describing where the object was defined.\n    aliases: A list of full-name for all aliases for this object.\n    doc: A list of objects representing the docstring. These can all be\n      converted to markdown using str().",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "documentation": {}
    },
    {
        "label": "ClassPageInfo",
        "kind": 6,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "peekOfCode": "class ClassPageInfo(PageInfo):\n  \"\"\"Collects docs for a class page.\n  Attributes:\n    full_name: The full, main name, of the object being documented.\n    short_name: The last part of the full name.\n    py_object: The object being documented.\n    defined_in: A _FileLocation describing where the object was defined.\n    aliases: A list of full-name for all aliases for this object.\n    doc: A list of objects representing the docstring. These can all be\n      converted to markdown using str().",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "documentation": {}
    },
    {
        "label": "ModulePageInfo",
        "kind": 6,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "peekOfCode": "class ModulePageInfo(PageInfo):\n  \"\"\"Collects docs for a module page.\n  Attributes:\n    full_name: The full, main name, of the object being documented.\n    short_name: The last part of the full name.\n    py_object: The object being documented.\n    defined_in: A _FileLocation describing where the object was defined.\n    aliases: A list of full-name for all aliases for this object.\n    doc: A list of objects representing the docstring. These can all be\n      converted to markdown using str().",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "documentation": {}
    },
    {
        "label": "Metadata",
        "kind": 6,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "peekOfCode": "class Metadata(object):\n  \"\"\"A class for building a page's Metadata block.\n  Attributes:\n    name: The name of the page being described by the Metadata block.\n    version: The source version.\n  \"\"\"\n  def __init__(self, name, version=None, content=None):\n    \"\"\"Creates a Metadata builder.\n    Args:\n      name: The name of the page being described by the Metadata block.",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "documentation": {}
    },
    {
        "label": "get_obj_type",
        "kind": 2,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "peekOfCode": "def get_obj_type(py_obj: Any) -> ObjType:\n  \"\"\"Get the `ObjType` for the `py_object`.\"\"\"\n  if getattr(py_obj, '__args__', None) and getattr(py_obj, '__origin__', None):\n    return ObjType.TYPE_ALIAS\n  elif inspect.ismodule(py_obj):\n    return ObjType.MODULE\n  elif inspect.isclass(py_obj):\n    return ObjType.CLASS\n  elif callable(py_obj):\n    return ObjType.CALLABLE",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "documentation": {}
    },
    {
        "label": "is_class_attr",
        "kind": 2,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "peekOfCode": "def is_class_attr(full_name, index):\n  \"\"\"Check if the object's parent is a class.\n  Args:\n    full_name: The full name of the object, like `tf.module.symbol`.\n    index: The {full_name:py_object} dictionary for the public API.\n  Returns:\n    True if the object is a class attribute.\n  \"\"\"\n  parent_name = full_name.rsplit('.', 1)[0]\n  if inspect.isclass(index[parent_name]):",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "documentation": {}
    },
    {
        "label": "documentation_path",
        "kind": 2,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "peekOfCode": "def documentation_path(full_name, is_fragment=False):\n  \"\"\"Returns the file path for the documentation for the given API symbol.\n  Given the fully qualified name of a library symbol, compute the path to which\n  to write the documentation for that symbol (relative to a base directory).\n  Documentation files are organized into directories that mirror the python\n  module/class structure.\n  Args:\n    full_name: Fully qualified name of a library symbol.\n    is_fragment: If `False` produce a direct markdown link (`tf.a.b.c` -->\n      `tf/a/b/c.md`). If `True` produce fragment link, `tf.a.b.c` -->",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "documentation": {}
    },
    {
        "label": "generate_signature",
        "kind": 2,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "peekOfCode": "def generate_signature(func: Any, parser_config: ParserConfig,\n                       func_full_name: str) -> _SignatureComponents:\n  \"\"\"Given a function, returns a list of strings representing its args.\n  This function uses `__name__` for callables if it is available. This can lead\n  to poor results for functools.partial and other callable objects.\n  The returned string is Python code, so if it is included in a Markdown\n  document, it should be typeset as code (using backticks), or escaped.\n  Args:\n    func: A function, method, or functools.partial to extract the signature for.\n    parser_config: `ParserConfig` for the method/function whose signature is",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "documentation": {}
    },
    {
        "label": "extract_decorators",
        "kind": 2,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "peekOfCode": "def extract_decorators(func: Any) -> List[str]:\n  \"\"\"Extracts the decorators on top of functions/methods.\n  Args:\n    func: The function to extract the decorators from.\n  Returns:\n    A List of decorators.\n  \"\"\"\n  class ASTDecoratorExtractor(ast.NodeVisitor):\n    def __init__(self):\n      self.decorator_list = []",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "documentation": {}
    },
    {
        "label": "docs_for_object",
        "kind": 2,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "peekOfCode": "def docs_for_object(\n    full_name: str,\n    py_object: Any,\n    parser_config: ParserConfig,\n    extra_docs: Optional[Dict[int, str]] = None,\n) -> PageInfo:\n  \"\"\"Return a PageInfo object describing a given object from the TF API.\n  This function uses _parse_md_docstring to parse the docs pertaining to\n  `object`.\n  This function resolves '`tf.symbol`' references in the docstrings into links",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "documentation": {}
    },
    {
        "label": "generate_global_index",
        "kind": 2,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "peekOfCode": "def generate_global_index(library_name, index, reference_resolver):\n  \"\"\"Given a dict of full names to python objects, generate an index page.\n  The index page generated contains a list of links for all symbols in `index`\n  that have their own documentation page.\n  Args:\n    library_name: The name for the documented library to use in the title.\n    index: A dict mapping full names to python objects.\n    reference_resolver: An instance of ReferenceResolver.\n  Returns:\n    A string containing an index page as Markdown.",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "documentation": {}
    },
    {
        "label": "AUTO_REFERENCE_RE",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "peekOfCode": "AUTO_REFERENCE_RE = re.compile(\n    r\"\"\"\n    (?P<brackets>\\[.*?\\])                    # find characters inside '[]'\n    |\n    `(?P<backticks>[\\w\\(\\[\\)\\]\\{\\}.,=\\s]+?)` # or find characters inside '``'\n    \"\"\",\n    flags=re.VERBOSE)\nclass ReferenceResolver(object):\n  \"\"\"Class for replacing `tf.symbol` references with Markdown links.\"\"\"\n  def __init__(",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "documentation": {}
    },
    {
        "label": "TABLE_TEMPLATE",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "peekOfCode": "TABLE_TEMPLATE = textwrap.dedent(\"\"\"\n  <!-- Tabular view -->\n   <table class=\"responsive fixed orange\">\n  <colgroup><col width=\"214px\"><col></colgroup>\n  <tr><th colspan=\"2\">{title}</th></tr>\n  {text}\n  {items}\n  </table>\n  \"\"\")\nITEMS_TEMPLATE = textwrap.dedent(\"\"\"\\",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "documentation": {}
    },
    {
        "label": "ITEMS_TEMPLATE",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "peekOfCode": "ITEMS_TEMPLATE = textwrap.dedent(\"\"\"\\\n  <tr>\n  <td>\n  {name}{anchor}\n  </td>\n  <td>\n  {description}\n  </td>\n  </tr>\"\"\")\nTEXT_TEMPLATE = textwrap.dedent(\"\"\"\\",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "documentation": {}
    },
    {
        "label": "TEXT_TEMPLATE",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "peekOfCode": "TEXT_TEMPLATE = textwrap.dedent(\"\"\"\\\n  <tr class=\"alt\">\n  <td colspan=\"2\">\n  {text}\n  </td>\n  </tr>\"\"\")\nclass TitleBlock(object):\n  \"\"\"A class to parse title blocks (like `Args:`) and convert them to markdown.\n  This handles the \"Args/Returns/Raises\" blocks and anything similar.\n  These are used to extract metadata (argument descriptions, etc), and upgrade",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser",
        "documentation": {}
    },
    {
        "label": "ParentClass",
        "kind": 6,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser_test",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser_test",
        "peekOfCode": "class ParentClass(object):\n  @doc_controls.do_not_doc_inheritable\n  def hidden_method(self):\n    pass\nclass TestClass(ParentClass):\n  \"\"\"Docstring for TestClass itself.\n  Attributes:\n    hello: hello\n  \"\"\"\n  def a_method(self, arg='default'):",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser_test",
        "documentation": {}
    },
    {
        "label": "TestClass",
        "kind": 6,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser_test",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser_test",
        "peekOfCode": "class TestClass(ParentClass):\n  \"\"\"Docstring for TestClass itself.\n  Attributes:\n    hello: hello\n  \"\"\"\n  def a_method(self, arg='default'):\n    \"\"\"Docstring for a method.\"\"\"\n    pass\n  def hidden_method(self):\n    pass",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser_test",
        "documentation": {}
    },
    {
        "label": "DummyVisitor",
        "kind": 6,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser_test",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser_test",
        "peekOfCode": "class DummyVisitor(object):\n  def __init__(self, index, duplicate_of):\n    self.index = index\n    self.duplicate_of = duplicate_of\nclass ConcreteMutableMapping(collections.MutableMapping):\n  \"\"\"MutableMapping subclass to repro inspect.getsource() IndexError.\"\"\"\n  def __init__(self):\n    self._map = {}\n  def __getitem__(self, key):\n    return self._map[key]",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser_test",
        "documentation": {}
    },
    {
        "label": "ConcreteMutableMapping",
        "kind": 6,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser_test",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser_test",
        "peekOfCode": "class ConcreteMutableMapping(collections.MutableMapping):\n  \"\"\"MutableMapping subclass to repro inspect.getsource() IndexError.\"\"\"\n  def __init__(self):\n    self._map = {}\n  def __getitem__(self, key):\n    return self._map[key]\n  def __setitem__(self, key, value):\n    self._map[key] = value\n  def __delitem__(self, key):\n    del self._map[key]",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser_test",
        "documentation": {}
    },
    {
        "label": "ClassUsingAttrs",
        "kind": 6,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser_test",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser_test",
        "peekOfCode": "class ClassUsingAttrs(object):\n  member = attr.ib(type=int)\n@dataclasses.dataclass\nclass ExampleDataclass:\n  x: List[str]\n  z: int\n  c: List[int] = dataclasses.field(default_factory=list)\n  a: Union[List[str], str, int] = None\n  b: str = 'test'\n  y: bool = False",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser_test",
        "documentation": {}
    },
    {
        "label": "ExampleDataclass",
        "kind": 6,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser_test",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser_test",
        "peekOfCode": "class ExampleDataclass:\n  x: List[str]\n  z: int\n  c: List[int] = dataclasses.field(default_factory=list)\n  a: Union[List[str], str, int] = None\n  b: str = 'test'\n  y: bool = False\n  def add(self, x: int, y: int) -> int:\n    q: int = x + y\n    return q",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser_test",
        "documentation": {}
    },
    {
        "label": "ParserTest",
        "kind": 6,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser_test",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser_test",
        "peekOfCode": "class ParserTest(parameterized.TestCase):\n  def test_documentation_path(self):\n    self.assertEqual('test.md', parser.documentation_path('test'))\n    self.assertEqual('test/module.md', parser.documentation_path('test.module'))\n  def test_replace_references(self):\n    class HasOneMember(object):\n      def foo(self):\n        pass\n    string = (\n        'A `tf.reference`, a member `tf.reference.foo`, and a `tf.third`. '",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser_test",
        "documentation": {}
    },
    {
        "label": "TestReferenceResolver",
        "kind": 6,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser_test",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser_test",
        "peekOfCode": "class TestReferenceResolver(absltest.TestCase):\n  _BASE_DIR = tempfile.mkdtemp()\n  def setUp(self):\n    super(TestReferenceResolver, self).setUp()\n    self.workdir = os.path.join(self._BASE_DIR, self.id())\n    os.makedirs(self.workdir)\n  def testSaveReferenceResolver(self):\n    duplicate_of = {'AClass': ['AClass2']}\n    is_fragment = {\n        'tf': False,",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser_test",
        "documentation": {}
    },
    {
        "label": "TestParseDocstring",
        "kind": 6,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser_test",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser_test",
        "peekOfCode": "class TestParseDocstring(absltest.TestCase):\n  def test_split_title_blocks(self):\n    docstring_parts = parser.TitleBlock.split_string(RELU_DOC)\n    self.assertLen(docstring_parts, 7)\n    args = docstring_parts[1]\n    self.assertEqual(args.title, 'Args')\n    self.assertEqual(args.text, '\\n')\n    self.assertLen(args.items, 2)\n    self.assertEqual(args.items[0][0], \"'features'\")\n    self.assertEqual(",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser_test",
        "documentation": {}
    },
    {
        "label": "TestPartialSymbolAutoRef",
        "kind": 6,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser_test",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser_test",
        "peekOfCode": "class TestPartialSymbolAutoRef(parameterized.TestCase):\n  REF_TEMPLATE = '<a href=\"{link}\"><code>{text}</code></a>'\n  @parameterized.named_parameters(\n      ('basic1', 'keras.Model.fit', '../tf/keras/Model.md#fit'),\n      ('duplicate_object', 'layers.Conv2D', '../tf/keras/layers/Conv2D.md'),\n      ('parens', 'Model.fit(x, y, epochs=5)', '../tf/keras/Model.md#fit'),\n      ('duplicate_name', 'tf.matmul', '../tf/linalg/matmul.md'),\n      ('full_name', 'tf.concat', '../tf/concat.md'),\n      ('normal_and_compat', 'linalg.matmul', '../tf/linalg/matmul.md'),\n      ('compat_only', 'math.deprecated', None),",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser_test",
        "documentation": {}
    },
    {
        "label": "TestIgnoreLineInBlock",
        "kind": 6,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser_test",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser_test",
        "peekOfCode": "class TestIgnoreLineInBlock(parameterized.TestCase):\n  @parameterized.named_parameters(\n      ('ignore_backticks', ['```'], ['```'],\n       '```\\nFiller\\n```\\n```Same line```\\n```python\\nDowner\\n```'),\n      ('ignore_code_cell_output', ['<pre>{% html %}'], ['{% endhtml %}</pre>'],\n       '<pre>{% html %}\\nOutput\\nmultiline{% endhtml %}</pre>'),\n      ('ignore_backticks_and_cell_output', ['<pre>{% html %}', '```'\n                                           ], ['{% endhtml %}</pre>', '```'],\n       ('```\\nFiller\\n```\\n```Same line```\\n<pre>{% html %}\\nOutput\\nmultiline'\n        '{% endhtml %}</pre>\\n```python\\nDowner\\n```')))",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser_test",
        "documentation": {}
    },
    {
        "label": "TestGenerateSignature",
        "kind": 6,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser_test",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser_test",
        "peekOfCode": "class TestGenerateSignature(parameterized.TestCase, absltest.TestCase):\n  def setUp(self):\n    super().setUp()\n    self.known_object = object()\n    reference_resolver = parser.ReferenceResolver(\n        duplicate_of={},\n        is_fragment={'tfdocs.api_generator.parser.extract_decorators': False},\n        py_module_names=[])\n    self.parser_config = parser.ParserConfig(\n        reference_resolver=reference_resolver,",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser_test",
        "documentation": {}
    },
    {
        "label": "test_function",
        "kind": 2,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser_test",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser_test",
        "peekOfCode": "def test_function(unused_arg, unused_kwarg='default'):\n  \"\"\"Docstring for test function.\"\"\"\n  pass\ndef test_function_with_args_kwargs(unused_arg, *unused_args, **unused_kwargs):\n  \"\"\"Docstring for second test function.\"\"\"\n  pass\nclass ParentClass(object):\n  @doc_controls.do_not_doc_inheritable\n  def hidden_method(self):\n    pass",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser_test",
        "documentation": {}
    },
    {
        "label": "test_function_with_args_kwargs",
        "kind": 2,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser_test",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser_test",
        "peekOfCode": "def test_function_with_args_kwargs(unused_arg, *unused_args, **unused_kwargs):\n  \"\"\"Docstring for second test function.\"\"\"\n  pass\nclass ParentClass(object):\n  @doc_controls.do_not_doc_inheritable\n  def hidden_method(self):\n    pass\nclass TestClass(ParentClass):\n  \"\"\"Docstring for TestClass itself.\n  Attributes:",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser_test",
        "documentation": {}
    },
    {
        "label": "test_module",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser_test",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser_test",
        "peekOfCode": "test_module = parser\ndef test_function(unused_arg, unused_kwarg='default'):\n  \"\"\"Docstring for test function.\"\"\"\n  pass\ndef test_function_with_args_kwargs(unused_arg, *unused_args, **unused_kwargs):\n  \"\"\"Docstring for second test function.\"\"\"\n  pass\nclass ParentClass(object):\n  @doc_controls.do_not_doc_inheritable\n  def hidden_method(self):",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser_test",
        "documentation": {}
    },
    {
        "label": "ConcreteNamedTuple",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser_test",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser_test",
        "peekOfCode": "ConcreteNamedTuple = collections.namedtuple('ConcreteNamedTuple', ['a', 'b'])\n@attr.s\nclass ClassUsingAttrs(object):\n  member = attr.ib(type=int)\n@dataclasses.dataclass\nclass ExampleDataclass:\n  x: List[str]\n  z: int\n  c: List[int] = dataclasses.field(default_factory=list)\n  a: Union[List[str], str, int] = None",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser_test",
        "documentation": {}
    },
    {
        "label": "RELU_DOC",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser_test",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser_test",
        "peekOfCode": "RELU_DOC = \"\"\"Computes rectified linear: `max(features, 0)`\nRELU is an activation\nArgs:\n  'features': A `Tensor`. Must be one of the following types: `float32`,\n    `float64`, `int32`, `int64`, `uint8`, `int16`, `int8`, `uint16`,\n    `half`.\n  name: A name for the operation (optional)\n    Note: this is a note, not another parameter.\nExamples:\n  ```",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.parser_test",
        "documentation": {}
    },
    {
        "label": "Methods",
        "kind": 6,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.pretty_docs",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.pretty_docs",
        "peekOfCode": "class Methods(NamedTuple):\n  info_dict: Dict[str, parser.MethodInfo]\n  constructor: parser.MethodInfo\ndef split_methods(methods: List[parser.MethodInfo]) -> Methods:\n  \"\"\"Splits the given methods list into constructors and the remaining methods.\n  If both `__init__` and `__new__` exist on the class, then prefer `__init__`\n  as the constructor over `__new__` to document.\n  Args:\n    methods: List of all the methods on the `ClassPageInfo` object.\n  Returns:",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.pretty_docs",
        "documentation": {}
    },
    {
        "label": "build_md_page",
        "kind": 2,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.pretty_docs",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.pretty_docs",
        "peekOfCode": "def build_md_page(page_info: parser.PageInfo) -> str:\n  \"\"\"Given a PageInfo object, return markdown for the page.\n  Args:\n    page_info: Must be a `parser.FunctionPageInfo`, `parser.ClassPageInfo`, or\n      `parser.ModulePageInfo`.\n  Returns:\n    Markdown for the page\n  Raises:\n    ValueError: if `page_info` is an instance of an unrecognized class\n  \"\"\"",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.pretty_docs",
        "documentation": {}
    },
    {
        "label": "split_methods",
        "kind": 2,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.pretty_docs",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.pretty_docs",
        "peekOfCode": "def split_methods(methods: List[parser.MethodInfo]) -> Methods:\n  \"\"\"Splits the given methods list into constructors and the remaining methods.\n  If both `__init__` and `__new__` exist on the class, then prefer `__init__`\n  as the constructor over `__new__` to document.\n  Args:\n    methods: List of all the methods on the `ClassPageInfo` object.\n  Returns:\n    A `DocumentMethods` object containing a {method_name: method object}\n    dictionary and a constructor object.\n  \"\"\"",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.pretty_docs",
        "documentation": {}
    },
    {
        "label": "merge_blocks",
        "kind": 2,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.pretty_docs",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.pretty_docs",
        "peekOfCode": "def merge_blocks(class_page_info: parser.ClassPageInfo,\n                 ctor_info: parser.MethodInfo):\n  \"\"\"Helper function to merge TitleBlock in constructor and class docstring.\"\"\"\n  # Get the class docstring. `.doc.docstring_parts` contain the entire\n  # docstring except for the one-line docstring that's compulsory.\n  class_doc = class_page_info.doc.docstring_parts\n  # If constructor doesn't exist, return the class docstring as it is.\n  if ctor_info is None:\n    return class_doc\n  # Get the constructor's docstring parts.",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.pretty_docs",
        "documentation": {}
    },
    {
        "label": "merge_class_and_constructor_docstring",
        "kind": 2,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.pretty_docs",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.pretty_docs",
        "peekOfCode": "def merge_class_and_constructor_docstring(\n    class_page_info: parser.ClassPageInfo,\n    ctor_info: parser.MethodInfo,\n) -> List[str]:\n  \"\"\"Merges the class and the constructor docstrings.\n  While merging, the following rules are followed:\n  * Only `Arguments` and `Raises` blocks from constructor are uplifted to the\n    class docstring. Rest of the stuff is ignored since it doesn't add much\n    value and in some cases the information is repeated.\n  * The `Raises` block is added to the end of the classes docstring.",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.pretty_docs",
        "documentation": {}
    },
    {
        "label": "_TABLE_ITEMS",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.pretty_docs",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.pretty_docs",
        "peekOfCode": "_TABLE_ITEMS = ('arg', 'return', 'raise', 'attr', 'yield')\ndef build_md_page(page_info: parser.PageInfo) -> str:\n  \"\"\"Given a PageInfo object, return markdown for the page.\n  Args:\n    page_info: Must be a `parser.FunctionPageInfo`, `parser.ClassPageInfo`, or\n      `parser.ModulePageInfo`.\n  Returns:\n    Markdown for the page\n  Raises:\n    ValueError: if `page_info` is an instance of an unrecognized class",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.pretty_docs",
        "documentation": {}
    },
    {
        "label": "DECORATOR_ALLOWLIST",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.pretty_docs",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.pretty_docs",
        "peekOfCode": "DECORATOR_ALLOWLIST = {\n    'classmethod',\n    'staticmethod',\n    'tf_contextlib.contextmanager',\n    'contextlib.contextmanager',\n    'tf.function',\n    'types.method',\n    'abc.abstractmethod',\n}\ndef _build_signature(obj_info: parser.PageInfo,",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.pretty_docs",
        "documentation": {}
    },
    {
        "label": "TABLE_HEADER",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.pretty_docs",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.pretty_docs",
        "peekOfCode": "TABLE_HEADER = (\n    '<table class=\"tfo-notebook-buttons tfo-api nocontent\" align=\"left\">')\n_TABLE_TEMPLATE = textwrap.dedent(\"\"\"\n    {table_header}\n    {table_content}\n    </table>\n    {table_footer}\"\"\")\n_TABLE_LINK_TEMPLATE = textwrap.dedent(\"\"\"\\\n    <td>\n      <a target=\"_blank\" href=\"{url}\">",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.pretty_docs",
        "documentation": {}
    },
    {
        "label": "_TABLE_TEMPLATE",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.pretty_docs",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.pretty_docs",
        "peekOfCode": "_TABLE_TEMPLATE = textwrap.dedent(\"\"\"\n    {table_header}\n    {table_content}\n    </table>\n    {table_footer}\"\"\")\n_TABLE_LINK_TEMPLATE = textwrap.dedent(\"\"\"\\\n    <td>\n      <a target=\"_blank\" href=\"{url}\">\n        <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />\n        View source on GitHub",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.pretty_docs",
        "documentation": {}
    },
    {
        "label": "_TABLE_LINK_TEMPLATE",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.pretty_docs",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.pretty_docs",
        "peekOfCode": "_TABLE_LINK_TEMPLATE = textwrap.dedent(\"\"\"\\\n    <td>\n      <a target=\"_blank\" href=\"{url}\">\n        <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />\n        View source on GitHub\n      </a>\n    </td>\"\"\")\ndef _top_source_link(location):\n  \"\"\"Retrns a source link with Github image, like the notebook butons.\"\"\"\n  table_content = ''",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.pretty_docs",
        "documentation": {}
    },
    {
        "label": "ParserTest",
        "kind": 6,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.pretty_docs_test",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.pretty_docs_test",
        "peekOfCode": "class ParserTest(absltest.TestCase):\n  def test_github_source_link_in_table(self):\n    url = \"https://github.com/tensorflow/docs/blob/master/path/to/file\"\n    location = parser._FileLocation(url=url)\n    table = pretty_docs._top_source_link(location)\n    expected = textwrap.dedent(f\"\"\"\n        <table class=\"tfo-notebook-buttons tfo-api nocontent\" align=\"left\">\n        <td>\n          <a target=\"_blank\" href=\"{url}\">\n            <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.pretty_docs_test",
        "documentation": {}
    },
    {
        "label": "PublicAPIFilter",
        "kind": 6,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.public_api",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.public_api",
        "peekOfCode": "class PublicAPIFilter(object):\n  \"\"\"Visitor to use with `traverse` to filter just the public API.\"\"\"\n  def __init__(self, base_dir, private_map=None):\n    \"\"\"Constructor.\n    Args:\n      base_dir: The directory to take source file paths relative to.\n      private_map: A mapping from dotted path like \"tf.symbol\" to a list of\n        names. Included names will not be listed at that location.\n    \"\"\"\n    self._base_dir = base_dir",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.public_api",
        "documentation": {}
    },
    {
        "label": "get_module_base_dirs",
        "kind": 2,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.public_api",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.public_api",
        "peekOfCode": "def get_module_base_dirs(module) -> Tuple[pathlib.Path, ...]:\n  \"\"\"Returns the list of base_dirs.\n  Args:\n    module: A python module object.\n  Returns:\n    A tuple of paths. Usually 1 unless the module is a namespace package.\n  \"\"\"\n  if not hasattr(module, '__file__'):\n    return ()\n  mod_file = module.__file__",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.public_api",
        "documentation": {}
    },
    {
        "label": "ignore_typing",
        "kind": 2,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.public_api",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.public_api",
        "peekOfCode": "def ignore_typing(path: Sequence[str], parent: Any,\n                  children: Children) -> Children:\n  \"\"\"Removes all children that are members of the typing module.\n  Arguments:\n    path: A tuple of name parts forming the attribute-lookup path to this\n      object. For `tf.keras.layers.Dense` path is:\n        (\"tf\",\"keras\",\"layers\",\"Dense\")\n    parent: The parent object.\n    children: A list of (name, value) pairs. The attributes of the patent.\n  Returns:",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.public_api",
        "documentation": {}
    },
    {
        "label": "local_definitions_filter",
        "kind": 2,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.public_api",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.public_api",
        "peekOfCode": "def local_definitions_filter(path: Sequence[str], parent: Any,\n                             children: Children) -> Children:\n  \"\"\"Filters children recursively.\n  Only returns those defined in this package.\n  This follows the API for visitors defined by `traverse.traverse`.\n  This is a much tighter constraint than the default \"base_dir\" filter which\n  ensures that only objects defined within the package root are documented.\n  This applies a similar constraint, to each submodule.\n  in the api-tree below, `Dense` is defined in `tf.keras.layers`, but imported\n  into `tf.layers` and `tf.keras`.",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.public_api",
        "documentation": {}
    },
    {
        "label": "explicit_package_contents_filter",
        "kind": 2,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.public_api",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.public_api",
        "peekOfCode": "def explicit_package_contents_filter(path: Sequence[str], parent: Any,\n                                     children: Children) -> Children:\n  \"\"\"Filter modules to only include explicit contents.\n  This function returns the children explicitly included by this module, meaning\n  that it will exclude:\n  *   Modules in a package not explicitly imported by the package (submodules\n      are implicitly injected into their parent's namespace).\n  *   Modules imported by a module that is not a package.\n  This filter is useful if you explicitly define your API in the packages of\n  your library, but do not expliticly define that API in the `__all__` variable",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.public_api",
        "documentation": {}
    },
    {
        "label": "TYPING_IDS",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.public_api",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.public_api",
        "peekOfCode": "TYPING_IDS = frozenset(\n    id(obj)\n    for obj in typing.__dict__.values()\n    if not doc_generator_visitor.maybe_singleton(obj))\nChildren = List[Tuple[str, Any]]\nApiFilter = Callable[[Tuple[str, ...], Any, Children], Children]\ndef get_module_base_dirs(module) -> Tuple[pathlib.Path, ...]:\n  \"\"\"Returns the list of base_dirs.\n  Args:\n    module: A python module object.",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.public_api",
        "documentation": {}
    },
    {
        "label": "Children",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.public_api",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.public_api",
        "peekOfCode": "Children = List[Tuple[str, Any]]\nApiFilter = Callable[[Tuple[str, ...], Any, Children], Children]\ndef get_module_base_dirs(module) -> Tuple[pathlib.Path, ...]:\n  \"\"\"Returns the list of base_dirs.\n  Args:\n    module: A python module object.\n  Returns:\n    A tuple of paths. Usually 1 unless the module is a namespace package.\n  \"\"\"\n  if not hasattr(module, '__file__'):",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.public_api",
        "documentation": {}
    },
    {
        "label": "ApiFilter",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.public_api",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.public_api",
        "peekOfCode": "ApiFilter = Callable[[Tuple[str, ...], Any, Children], Children]\ndef get_module_base_dirs(module) -> Tuple[pathlib.Path, ...]:\n  \"\"\"Returns the list of base_dirs.\n  Args:\n    module: A python module object.\n  Returns:\n    A tuple of paths. Usually 1 unless the module is a namespace package.\n  \"\"\"\n  if not hasattr(module, '__file__'):\n    return ()",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.public_api",
        "documentation": {}
    },
    {
        "label": "ALLOWED_DUNDER_METHODS",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.public_api",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.public_api",
        "peekOfCode": "ALLOWED_DUNDER_METHODS = frozenset([\n    '__abs__', '__add__', '__and__', '__bool__', '__call__', '__concat__',\n    '__contains__', '__div__', '__enter__', '__eq__', '__exit__',\n    '__floordiv__', '__ge__', '__getitem__', '__gt__', '__init__', '__invert__',\n    '__iter__', '__le__', '__len__', '__lt__', '__matmul__', '__mod__',\n    '__mul__', '__new__', '__ne__', '__neg__', '__pos__', '__nonzero__',\n    '__or__', '__pow__', '__radd__', '__rand__', '__rdiv__', '__rfloordiv__',\n    '__rmatmul__', '__rmod__', '__rmul__', '__ror__', '__rpow__', '__rsub__',\n    '__rtruediv__', '__rxor__', '__sub__', '__truediv__', '__xor__',\n    '__version__'",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.public_api",
        "documentation": {}
    },
    {
        "label": "PublicApiTest",
        "kind": 6,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.public_api_test",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.public_api_test",
        "peekOfCode": "class PublicApiTest(absltest.TestCase):\n  class TestVisitor(object):\n    def __init__(self):\n      self.symbols = set()\n      self.last_parent = None\n      self.last_children = None\n    def __call__(self, path, parent, children):\n      self.symbols.add(path)\n      self.last_parent = parent\n      self.last_children = list(children)  # Make a copy to preserve state.",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.public_api_test",
        "documentation": {}
    },
    {
        "label": "ModuleClass1",
        "kind": 6,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.test_module1",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.test_module1",
        "peekOfCode": "class ModuleClass1(object):\n  def __init__(self):\n    self._m2 = test_module2.ModuleClass2()\n  def __model_class1_method__(self):\n    pass",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.test_module1",
        "documentation": {}
    },
    {
        "label": "ModuleClass2",
        "kind": 6,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.test_module2",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.test_module2",
        "peekOfCode": "class ModuleClass2(object):\n  def __init__(self):\n    pass\n  def __model_class1_method__(self):\n    pass\nclass Hidden(object):\n  pass\n__all__ = ['ModuleClass2']",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.test_module2",
        "documentation": {}
    },
    {
        "label": "Hidden",
        "kind": 6,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.test_module2",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.test_module2",
        "peekOfCode": "class Hidden(object):\n  pass\n__all__ = ['ModuleClass2']",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.test_module2",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.test_module2",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.test_module2",
        "peekOfCode": "__all__ = ['ModuleClass2']",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.test_module2",
        "documentation": {}
    },
    {
        "label": "traverse",
        "kind": 2,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.traverse",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.traverse",
        "peekOfCode": "def traverse(root, visitors, root_name):\n  \"\"\"Recursively enumerate all members of `root`.\n  Similar to the Python library function `os.path.walk`.\n  Traverses the tree of Python objects starting with `root`, depth first.\n  Parent-child relationships in the tree are defined by membership in modules or\n  classes. The function `visit` is called with arguments\n  `(path, parent, children)` for each module or class `parent` found in the tree\n  of python objects starting with `root`. `path` is a string containing the name\n  with which `parent` is reachable from the current context. For example, if\n  `root` is a local class called `X` which contains a class `Y`, `visit` will be",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.traverse",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.traverse",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.traverse",
        "peekOfCode": "__all__ = ['traverse']\ndef _filter_module_all(path, root, children):\n  \"\"\"Filters module children based on the \"__all__\" arrtibute.\n  Args:\n    path: API to this symbol\n    root: The object\n    children: A list of (name, object) pairs.\n  Returns:\n    `children` filtered to respect __all__\n  \"\"\"",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.traverse",
        "documentation": {}
    },
    {
        "label": "TestVisitor",
        "kind": 6,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.traverse_test",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.traverse_test",
        "peekOfCode": "class TestVisitor(object):\n  def __init__(self):\n    self.call_log = []\n  def __call__(self, path, parent, children):\n    self.call_log += [(path, parent, children)]\n    return children\nclass TraverseTest(absltest.TestCase):\n  def test_cycle(self):\n    class Cyclist(object):\n      pass",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.traverse_test",
        "documentation": {}
    },
    {
        "label": "TraverseTest",
        "kind": 6,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.traverse_test",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.traverse_test",
        "peekOfCode": "class TraverseTest(absltest.TestCase):\n  def test_cycle(self):\n    class Cyclist(object):\n      pass\n    Cyclist.cycle = Cyclist\n    visitor = TestVisitor()\n    traverse.traverse(Cyclist, [visitor], root_name='root_name')\n    # We simply want to make sure we terminate.\n  def test_module(self):\n    visitor = TestVisitor()",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.traverse_test",
        "documentation": {}
    },
    {
        "label": "recursive_import",
        "kind": 2,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.utils",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.utils",
        "peekOfCode": "def recursive_import(root, strict=False):\n  \"\"\"Recursively imports all the modules under a root package.\n  Args:\n    root: A python package.\n    strict: Bool, if `True` raise exceptions, else just log them.\n  Returns:\n    A list of all imported modules.\n  \"\"\"\n  modules = []\n  kwargs = {}",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.api_generator.utils",
        "documentation": {}
    },
    {
        "label": "collect_notebook_paths",
        "kind": 2,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nbfmt.notebook_utils",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nbfmt.notebook_utils",
        "peekOfCode": "def collect_notebook_paths(\n    filepaths: List[Union[str, pathlib.Path]]\n) -> Tuple[List[pathlib.Path], List[pathlib.Path]]:\n  \"\"\"Return list of `pathlib.Path`s for (recursive) notebook filepaths.\n  Skips any file that's not an .ipynb notebook or invalid file.\n  Args:\n    filepaths: List file path strings passed at command-line.\n  Returns:\n    A list of Path objects for all notebook files.\n    A list of Path objects that returned an error.",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nbfmt.notebook_utils",
        "documentation": {}
    },
    {
        "label": "load_notebook",
        "kind": 2,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nbfmt.notebook_utils",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nbfmt.notebook_utils",
        "peekOfCode": "def load_notebook(path: pathlib.Path) -> Tuple[Optional[Dict[str, Any]], str]:\n  \"\"\"Load and parse JSON data from a notebook file.\n  Args:\n    path: A `pathlib.Path` of a Jupyter notebook.\n  Returns:\n    Dict: Contains data of the parsed JSON notebook, or null if can't read.\n    String: The entire JSON source code of the notebook.\n  \"\"\"\n  source = path.read_text(encoding=\"utf-8\")\n  try:",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nbfmt.notebook_utils",
        "documentation": {}
    },
    {
        "label": "warn",
        "kind": 2,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nbfmt.notebook_utils",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nbfmt.notebook_utils",
        "peekOfCode": "def warn(msg: str) -> None:\n  \"\"\"Print highlighted warning message to stderr.\n  Args:\n    msg: String to print to console.\n  \"\"\"\n  # Use terminal codes to print color output to console.\n  print(f\" \\033[33m {msg}\\033[00m\", file=sys.stderr)\ndef generate_cell_id(source: str, cell_count: int) -> str:\n  \"\"\"Generate a new cell ID unique to the notebook.\"\"\"\n  str_to_hash = f\"{cell_count} {source}\"",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nbfmt.notebook_utils",
        "documentation": {}
    },
    {
        "label": "generate_cell_id",
        "kind": 2,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nbfmt.notebook_utils",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nbfmt.notebook_utils",
        "peekOfCode": "def generate_cell_id(source: str, cell_count: int) -> str:\n  \"\"\"Generate a new cell ID unique to the notebook.\"\"\"\n  str_to_hash = f\"{cell_count} {source}\"\n  cell_id = hashlib.sha256(str_to_hash.encode(\"utf-8\")).hexdigest()\n  return cell_id[:12]\ndef del_entries_except(data: Dict[str, Any], keep: List[str]) -> None:\n  \"\"\"Modifies `data` to remove any entry not specified in the `keep` list.\n  Args:\n    data: Dict representing a parsed JSON object.\n    keep: List of key entries to not deleted from `data`.",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nbfmt.notebook_utils",
        "documentation": {}
    },
    {
        "label": "del_entries_except",
        "kind": 2,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nbfmt.notebook_utils",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nbfmt.notebook_utils",
        "peekOfCode": "def del_entries_except(data: Dict[str, Any], keep: List[str]) -> None:\n  \"\"\"Modifies `data` to remove any entry not specified in the `keep` list.\n  Args:\n    data: Dict representing a parsed JSON object.\n    keep: List of key entries to not deleted from `data`.\n  \"\"\"\n  to_delete = set(data.keys()) - frozenset(keep)\n  for key in to_delete:\n    del data[key]",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nbfmt.notebook_utils",
        "documentation": {}
    },
    {
        "label": "search_wordlist",
        "kind": 2,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.style.google",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.style.google",
        "peekOfCode": "def search_wordlist(wordlist, src_str):\n  \"\"\"Search for wordlist entries in text and return set of found items.\n  Args:\n    wordlist: Dict of word entries and recommendations to search in string.\n    src_str: String to search for word entries.\n  Returns:\n    A dict that is a subset of entries from `wordlist` found in `src_str`.\n  \"\"\"\n  found_words = {}\n  for word in wordlist:",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.style.google",
        "documentation": {}
    },
    {
        "label": "inclusive_language",
        "kind": 2,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.style.google",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.style.google",
        "peekOfCode": "def inclusive_language(args):\n  \"\"\"Test for words found in inclusive wordlist and recommend alternatives.\"\"\"\n  found_words = search_wordlist(_INCLUSIVE_WORDLIST, args[\"cell_source\"])\n  if found_words:\n    words = \", \".join([f\"{word} => {alt}\" for word, alt in found_words.items()])\n    fail(f\"Use inclusive language where possible and accurate. Found: {words}\")\n  else:\n    return True\n# Non-exhaustive list: {word: alt-word} (Use False if alt not provided.)\n_SECOND_PERSON_WORDLIST = {\"we\": \"you\", \"we're\": \"you are\"}",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.style.google",
        "documentation": {}
    },
    {
        "label": "second_person",
        "kind": 2,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.style.google",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.style.google",
        "peekOfCode": "def second_person(args):\n  \"\"\"Test for first person usage in doc and recommend second person.\"\"\"\n  found_words = search_wordlist(_SECOND_PERSON_WORDLIST, args[\"cell_source\"])\n  if found_words:\n    words = \", \".join([f\"{word} => {alt}\" for word, alt in found_words.items()])\n    fail(f\"Prefer second person instead of first person. Found: {words}\")\n  else:\n    return True",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.style.google",
        "documentation": {}
    },
    {
        "label": "_INCLUSIVE_WORDLIST",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.style.google",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.style.google",
        "peekOfCode": "_INCLUSIVE_WORDLIST = {\n    \"blacklist\": \"blocked\",\n    \"whitelist\": \"allowed\",\n    \"master\": \"primary\",\n    \"slave\": \"replica\",\n    \"native\": \"built-in\"\n}\n@lint(\n    message=\"Use inclusive language: https://developers.google.com/style/inclusive-documentation\",\n    cond=Options.Cond.ALL)",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.style.google",
        "documentation": {}
    },
    {
        "label": "_SECOND_PERSON_WORDLIST",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.style.google",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.style.google",
        "peekOfCode": "_SECOND_PERSON_WORDLIST = {\"we\": \"you\", \"we're\": \"you are\"}\n@lint(\n    message=\"Prefer second person instead of first person: https://developers.google.com/style/person\",\n    cond=Options.Cond.ALL)\ndef second_person(args):\n  \"\"\"Test for first person usage in doc and recommend second person.\"\"\"\n  found_words = search_wordlist(_SECOND_PERSON_WORDLIST, args[\"cell_source\"])\n  if found_words:\n    words = \", \".join([f\"{word} => {alt}\" for word, alt in found_words.items()])\n    fail(f\"Prefer second person instead of first person. Found: {words}\")",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.style.google",
        "documentation": {}
    },
    {
        "label": "copyright_check",
        "kind": 2,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.style.tensorflow",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.style.tensorflow",
        "peekOfCode": "def copyright_check(args):\n  cell_source = args[\"cell_source\"]\n  return any(re.search(pattern, cell_source) for pattern in copyrights_re)\nlicense_re = re.compile(\"#@title Licensed under the Apache License\")\n@lint(\n    message=\"Apache license cell is required\",\n    scope=Options.Scope.CODE,\n    cond=Options.Cond.ANY)\ndef license_check(args):\n  if license_re.search(args[\"cell_source\"]):",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.style.tensorflow",
        "documentation": {}
    },
    {
        "label": "license_check",
        "kind": 2,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.style.tensorflow",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.style.tensorflow",
        "peekOfCode": "def license_check(args):\n  if license_re.search(args[\"cell_source\"]):\n    return True\n  else:\n    template_url = \"https://github.com/tensorflow/docs/blob/master/tools/templates/notebook.ipynb\"\n    fail(f\"License cell missing or doesn't follow template: {template_url}\")\n@lint(scope=Options.Scope.FILE)\ndef not_translation(args):\n  if \"site\" not in args[\"path\"].parents:\n    return True",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.style.tensorflow",
        "documentation": {}
    },
    {
        "label": "not_translation",
        "kind": 2,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.style.tensorflow",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.style.tensorflow",
        "peekOfCode": "def not_translation(args):\n  if \"site\" not in args[\"path\"].parents:\n    return True\n  else:\n    return \"site/en\" in args[\"path\"].parents\n# Button checks\nis_button_cell_re = re.compile(r\"class.*tfo-notebook-buttons\")\ndef get_arg_or_fail(user_args, arg_name, arg_fmt):\n  \"\"\"Get value of the user-defined arg passed at the command-line.\n  Args:",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.style.tensorflow",
        "documentation": {}
    },
    {
        "label": "get_arg_or_fail",
        "kind": 2,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.style.tensorflow",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.style.tensorflow",
        "peekOfCode": "def get_arg_or_fail(user_args, arg_name, arg_fmt):\n  \"\"\"Get value of the user-defined arg passed at the command-line.\n  Args:\n    user_args: Dict containing user-defined args passed at command-line.\n    arg_name: String name of user-defined arg.\n    arg_fmt: String format of expected user-defined arg.\n  Returns:\n    Value of arg passed to command-line. If the arg does not exist, raise a\n    failure, log a message, and skip the lint function.\n  \"\"\"",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.style.tensorflow",
        "documentation": {}
    },
    {
        "label": "split_doc_path",
        "kind": 2,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.style.tensorflow",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.style.tensorflow",
        "peekOfCode": "def split_doc_path(filepath):\n  \"\"\"Return paths for docs root prefix directory and the relative path to file.\n  Given a full path to notebook file, standalone or within an established\n  documentation directory layout, split the provided path into two:\n  1. a path reprsenting the prefix directory to the docs root (if it exists),\n  2. the relative path to the file from the docs root directory.\n  If in an unknown docs directory layout, return an empty prefix path and the\n  full path of the original argument.\n  For example:\n  \"site/en/notebook.ipynb\" => (\"site/en\", \"notebook.ipynb\")",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.style.tensorflow",
        "documentation": {}
    },
    {
        "label": "button_colab",
        "kind": 2,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.style.tensorflow",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.style.tensorflow",
        "peekOfCode": "def button_colab(args):\n  \"\"\"Test that the URL in the Colab button matches the file path.\"\"\"\n  cell_source = args[\"cell_source\"]\n  repo = get_arg_or_fail(args[\"user\"], \"repo\", \"<org/name>\")\n  docs_dir, rel_path = split_doc_path(args[\"path\"])\n  # Buttons use OSS URLs.\n  if str(docs_dir) == \"g3doc/en\":\n    docs_dir = pathlib.Path(\"site/en\")\n  base_url = f\"colab.research.google.com/github/{repo}/blob/master\"\n  this_url = \"https://\" + str(base_url / docs_dir / rel_path)",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.style.tensorflow",
        "documentation": {}
    },
    {
        "label": "button_download",
        "kind": 2,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.style.tensorflow",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.style.tensorflow",
        "peekOfCode": "def button_download(args):\n  \"\"\"Test that the URL in the Download button matches the file path.\"\"\"\n  cell_source = args[\"cell_source\"]\n  repo = get_arg_or_fail(args[\"user\"], \"repo\", \"<org/name>\")\n  repo_name = pathlib.Path(repo.split(\"/\")[1])\n  docs_dir, rel_path = split_doc_path(args[\"path\"])\n  if \"r1\" in rel_path.parts:\n    return True  # No download button for TF 1.x docs.\n  # Buttons use OSS URLs.\n  if str(docs_dir) == \"g3doc/en\":",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.style.tensorflow",
        "documentation": {}
    },
    {
        "label": "button_github",
        "kind": 2,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.style.tensorflow",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.style.tensorflow",
        "peekOfCode": "def button_github(args):\n  \"\"\"Test that the URL in the GitHub button matches the file path.\"\"\"\n  cell_source = args[\"cell_source\"]\n  repo = get_arg_or_fail(args[\"user\"], \"repo\", \"<org/name>\")\n  docs_dir, rel_path = split_doc_path(args[\"path\"])\n  # Buttons use OSS URLs.\n  if str(docs_dir) == \"g3doc/en\":\n    docs_dir = pathlib.Path(\"site/en\")\n  base_url = f\"github.com/{repo}/blob/master\"\n  this_url = \"https://\" + str(base_url / docs_dir / rel_path)",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.style.tensorflow",
        "documentation": {}
    },
    {
        "label": "button_website",
        "kind": 2,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.style.tensorflow",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.style.tensorflow",
        "peekOfCode": "def button_website(args):\n  \"\"\"Test that the website URL in the 'View on' button matches the file path.\n  Because of subsites and different output directories, the exact website path\n  can't be known from the file alone. But can check that the URL matches a\n  correct pattern.\n  Args:\n    args: Nested dict of runtime arguments.\n  Returns:\n    Boolean: True if lint test passes, False if not.\n  \"\"\"",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.style.tensorflow",
        "documentation": {}
    },
    {
        "label": "button_hub",
        "kind": 2,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.style.tensorflow",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.style.tensorflow",
        "peekOfCode": "def button_hub(args):\n  \"\"\"Notebooks that mention tfhub.dev should have a TFHub button.\"\"\"\n  cell_source = args[\"cell_source\"]\n  file_source = args[\"file_source\"]\n  hub_url = \"https://tfhub.dev/\"\n  # Only check files that mention TFHub.\n  if file_source.find(hub_url) == -1:\n    return True\n  if is_button_cell_re.search(cell_source) and cell_source.find(hub_url) != -1:\n    return True",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.style.tensorflow",
        "documentation": {}
    },
    {
        "label": "button_r1_extra",
        "kind": 2,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.style.tensorflow",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.style.tensorflow",
        "peekOfCode": "def button_r1_extra(args):\n  \"\"\"The r1/ docs should not have website or download buttons.\"\"\"\n  cell_source = args[\"cell_source\"]\n  docs_dir, rel_path = split_doc_path(args[\"path\"])\n  # Only test r1/ notebooks.\n  if \"r1\" not in rel_path.parts:\n    return True\n  # Only check text cells that contain the button nav bar.\n  if not is_button_cell_re.search(cell_source):\n    return True",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.style.tensorflow",
        "documentation": {}
    },
    {
        "label": "copyrights_re",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.style.tensorflow",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.style.tensorflow",
        "peekOfCode": "copyrights_re = [\n    r\"Copyright 20[1-9][0-9] The TensorFlow\\s.*?\\s?Authors\",\n    r\"Copyright 20[1-9][0-9] Google\"\n]\n@lint(message=\"Copyright required\", scope=Options.Scope.TEXT)\ndef copyright_check(args):\n  cell_source = args[\"cell_source\"]\n  return any(re.search(pattern, cell_source) for pattern in copyrights_re)\nlicense_re = re.compile(\"#@title Licensed under the Apache License\")\n@lint(",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.style.tensorflow",
        "documentation": {}
    },
    {
        "label": "license_re",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.style.tensorflow",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.style.tensorflow",
        "peekOfCode": "license_re = re.compile(\"#@title Licensed under the Apache License\")\n@lint(\n    message=\"Apache license cell is required\",\n    scope=Options.Scope.CODE,\n    cond=Options.Cond.ANY)\ndef license_check(args):\n  if license_re.search(args[\"cell_source\"]):\n    return True\n  else:\n    template_url = \"https://github.com/tensorflow/docs/blob/master/tools/templates/notebook.ipynb\"",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.style.tensorflow",
        "documentation": {}
    },
    {
        "label": "is_button_cell_re",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.style.tensorflow",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.style.tensorflow",
        "peekOfCode": "is_button_cell_re = re.compile(r\"class.*tfo-notebook-buttons\")\ndef get_arg_or_fail(user_args, arg_name, arg_fmt):\n  \"\"\"Get value of the user-defined arg passed at the command-line.\n  Args:\n    user_args: Dict containing user-defined args passed at command-line.\n    arg_name: String name of user-defined arg.\n    arg_fmt: String format of expected user-defined arg.\n  Returns:\n    Value of arg passed to command-line. If the arg does not exist, raise a\n    failure, log a message, and skip the lint function.",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.style.tensorflow",
        "documentation": {}
    },
    {
        "label": "is_translation",
        "kind": 2,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.style.tensorflow_docs_l10n",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.style.tensorflow_docs_l10n",
        "peekOfCode": "def is_translation(args):\n  \"\"\"Translations live in the site/<lang>/ directory of the docs-l10n repo.\"\"\"\n  path_str = str(args[\"path\"].resolve())\n  if \"site/\" not in path_str:\n    return False\n  elif \"site/en/\" in path_str:\n    return False\n  elif \"site/en-snapshot/\" in path_str:\n    return False\n  else:",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.style.tensorflow_docs_l10n",
        "documentation": {}
    },
    {
        "label": "china_hostname_url",
        "kind": 2,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.style.tensorflow_docs_l10n",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.style.tensorflow_docs_l10n",
        "peekOfCode": "def china_hostname_url(args):\n  \"\"\"Chinese docs should use tensorflow.google.cn as the URL hostname.\n  Replace hostname 'www.tensorflow.org' with 'tensorflow.google.cn'.\n  Args:\n    args: Nested dict of runtime arguments.\n  Returns:\n    Boolean: True if lint test passes, False if not.\n  \"\"\"\n  docs_dir, _ = split_doc_path(args[\"path\"])\n  # Only applicable for China docs.",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.style.tensorflow_docs_l10n",
        "documentation": {}
    },
    {
        "label": "rtl_language_wrap",
        "kind": 2,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.style.tensorflow_docs_l10n",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.style.tensorflow_docs_l10n",
        "peekOfCode": "def rtl_language_wrap(args):\n  \"\"\"Check that RTL languages wrap text elemenst in a directional div.\n  Required for languages like Arabic to render correctly in Colab. Some care\n  must be taken or any Markdown syntax within the div will break.\n  Args:\n    args: Nested dict of runtime arguments.\n  Returns:\n    Boolean: True if lint test passes, False if not.\n  \"\"\"\n  docs_dir, _ = split_doc_path(args[\"path\"])",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.style.tensorflow_docs_l10n",
        "documentation": {}
    },
    {
        "label": "has_tf_hostname_re",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.style.tensorflow_docs_l10n",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.style.tensorflow_docs_l10n",
        "peekOfCode": "has_tf_hostname_re = re.compile(\n    r\"(?<!/a/)(?<!@)(?<!download\\.)(?<!js\\.)(www\\.)(blog\\.)?tensorflow\\.org\",\n    re.IGNORECASE)\n@lint(\n    message=\"Replace 'www.tensorflow.org' URL with 'tensorflow.google.cn' in Chinese docs.\",\n    scope=Options.Scope.TEXT,\n    cond=Options.Cond.ALL)\ndef china_hostname_url(args):\n  \"\"\"Chinese docs should use tensorflow.google.cn as the URL hostname.\n  Replace hostname 'www.tensorflow.org' with 'tensorflow.google.cn'.",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.style.tensorflow_docs_l10n",
        "documentation": {}
    },
    {
        "label": "has_rtl_div_re",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.style.tensorflow_docs_l10n",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.style.tensorflow_docs_l10n",
        "peekOfCode": "has_rtl_div_re = re.compile(r\"<div\\s*dir\\s*=\\s*[\\\"']rtl[\\\"'].*>\", re.IGNORECASE)\nhas_copyright_re = re.compile(r\"Copyright 20[1-9][0-9]\")\n@lint(\n    message=\"RTL languages must wrap all text cell elements with: <div dir=\\\"rtl\\\">...</div>\",\n    scope=Options.Scope.TEXT,\n    cond=Options.Cond.ALL)\ndef rtl_language_wrap(args):\n  \"\"\"Check that RTL languages wrap text elemenst in a directional div.\n  Required for languages like Arabic to render correctly in Colab. Some care\n  must be taken or any Markdown syntax within the div will break.",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.style.tensorflow_docs_l10n",
        "documentation": {}
    },
    {
        "label": "has_copyright_re",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.style.tensorflow_docs_l10n",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.style.tensorflow_docs_l10n",
        "peekOfCode": "has_copyright_re = re.compile(r\"Copyright 20[1-9][0-9]\")\n@lint(\n    message=\"RTL languages must wrap all text cell elements with: <div dir=\\\"rtl\\\">...</div>\",\n    scope=Options.Scope.TEXT,\n    cond=Options.Cond.ALL)\ndef rtl_language_wrap(args):\n  \"\"\"Check that RTL languages wrap text elemenst in a directional div.\n  Required for languages like Arabic to render correctly in Colab. Some care\n  must be taken or any Markdown syntax within the div will break.\n  Args:",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.style.tensorflow_docs_l10n",
        "documentation": {}
    },
    {
        "label": "Options",
        "kind": 6,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.decorator",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.decorator",
        "peekOfCode": "class Options:\n  \"\"\"Options to define the condition and scope of a @lint defined assertion.\"\"\"\n  class Cond(enum.Enum):\n    \"\"\"Determines if a test is considered a success by which cells it passes.\n    Attributes:\n      ALL: Success if all cells pass.\n      ANY: Success if any cells pass (just one). [Default]\n    \"\"\"\n    ALL = enum.auto()\n    ANY = enum.auto()",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.decorator",
        "documentation": {}
    },
    {
        "label": "Lint",
        "kind": 6,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.decorator",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.decorator",
        "peekOfCode": "class Lint:\n  \"\"\"Contains the function and properties defined by the @lint decorator.\n  Attributes:\n    run: User-defined assertion callback that returns a Boolean.\n    scope: `Options.Scope` to determine where an assertion is executed.\n    cond: `Options.Cond` to determine if an assertion is considered a success.\n    name: Optional string name for assertion function in reports.\n    message: String message to include in status report.\n    style: String name of style module that defines the Lint. (Added on load.)\n  \"\"\"",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.decorator",
        "documentation": {}
    },
    {
        "label": "LintFailError",
        "kind": 6,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.decorator",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.decorator",
        "peekOfCode": "class LintFailError(Exception):\n  \"\"\"Exception raised for lint failure with optional message.\n    Attributes:\n      message: String message to add to status log.\n      always_show: Boolean if failure message should display in status,\n        regardless if larger conditional met.\n      fix_fn: Optional Callable to run that fixes the lint failure.\n      fix_args: List of arguments passed to the `fix_fn` Callable.\n  \"\"\"\n  def __init__(self,",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.decorator",
        "documentation": {}
    },
    {
        "label": "lint",
        "kind": 2,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.decorator",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.decorator",
        "peekOfCode": "def lint(fn=None, *, message=None, scope=None, cond=None):\n  \"\"\"Function decorator for user-defined lint assertions.\n  Args:\n    fn: User-defined assertion callback that returns a Boolean. See `Linter.run`\n      for args passed to callback, depending on scope:\n        * For cell-scope: callback(source, cell_data, path).\n        * For file-scope: callback(source, all_data, path)\n    message: Optional string message to include in status report.\n    scope: Determines where the function should be executed, options in\n      `Options.Scope`.",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.decorator",
        "documentation": {}
    },
    {
        "label": "fail",
        "kind": 2,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.decorator",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.decorator",
        "peekOfCode": "def fail(message: Optional[str] = None,\n         always_show: bool = False,\n         fix: Optional[Callable[[], None]] = None,\n         fix_args: Optional[List[Any]] = None) -> None:\n  \"\"\"Signal within a @lint function that the test fails.\n  While sufficient to simply return False from a failing @lint function, this\n  function can add a message to the status log to provide the user additional\n  context. Stack trace available with `--verbose` flag.\n  Failure messages come in two flavors:\n  - conditional: (Default) While this test may fail here, it may succeed",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.decorator",
        "documentation": {}
    },
    {
        "label": "regex_replace_all",
        "kind": 2,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.fix",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.fix",
        "peekOfCode": "def regex_replace_all(args: Dict[str, Any], pattern: Pattern[str],\n                      repl: str) -> None:\n  \"\"\"Replace regex matched content in a file.\n  Args:\n    args: Dict of args passed to the lint function.\n    pattern: Regex pattern containing two groups to match.\n    repl: Replacement text to insert between the two matched groups.\n  \"\"\"\n  fp = args[\"path\"]\n  contents = fp.read_text(encoding=\"utf-8\")",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.fix",
        "documentation": {}
    },
    {
        "label": "regex_between_groups_replace_all",
        "kind": 2,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.fix",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.fix",
        "peekOfCode": "def regex_between_groups_replace_all(args: Dict[str, Any],\n                                     pattern: Pattern[str], repl: str) -> None:\n  \"\"\"Replace content between two matched groups in a file.\n  Regex pattern must contain two groups: r'(foo).*(bar)'\n  and the replacement text is inserted between these matches.\n  Args:\n    args: Dict of args passed to the lint function.\n    pattern: Regex pattern containing two groups to match.\n    repl: Replacement text to insert between the two matched groups.\n  \"\"\"",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.fix",
        "documentation": {}
    },
    {
        "label": "Linter",
        "kind": 6,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.linter",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.linter",
        "peekOfCode": "class Linter:\n  \"\"\"Manages the collection of lints to execute on a notebook.\n  Lint assertions are imported by style modules and dispatched by condition and\n  scope. A Linter can be run on multiple notebooks.\n  Attributes:\n    verbose: Boolean to print more details to console. Default is False.\n  \"\"\"\n  class RunLintStatus(NamedTuple):\n    \"\"\"The return status and metadata from an executed lint function.\n    Attributes:",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.linter",
        "documentation": {}
    },
    {
        "label": "LinterStatus",
        "kind": 6,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.linter",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.linter",
        "peekOfCode": "class LinterStatus:\n  \"\"\"Provides status and reporting of lint tests for a notebook.\n  A new `LinterStatus` object is returned when `Linter.run` is executed on a\n  given notebook. A `LinterStatus` object represents a run of all lints for a\n  single notebook file. Multiple notebook files require multiple `LinterStatus`\n  objects. Though multiple status objects can be created by the same `Linter`.\n  The `LinterStatus` instance manages `LintStatusEntry` objects. These are added\n  in the `Linter.run` for each lint test. Some entries may be a part of a larger\n  lint group that represents a collective pass/fail status.\n  A `LinterStatus` instance is also reponsible for printing status reports for",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.linter",
        "documentation": {}
    },
    {
        "label": "LintDict",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.linter",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.linter",
        "peekOfCode": "LintDict = Dict[decorator.Options.Scope, Dict[decorator.Options.Cond,\n                                              List[decorator.Lint]]]\nclass Linter:\n  \"\"\"Manages the collection of lints to execute on a notebook.\n  Lint assertions are imported by style modules and dispatched by condition and\n  scope. A Linter can be run on multiple notebooks.\n  Attributes:\n    verbose: Boolean to print more details to console. Default is False.\n  \"\"\"\n  class RunLintStatus(NamedTuple):",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.tools.nblint.linter",
        "documentation": {}
    },
    {
        "label": "embed_data",
        "kind": 2,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.vis.embed",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.vis.embed",
        "peekOfCode": "def embed_data(mime: str, data: bytes) -> IPython.display.HTML:\n  \"\"\"Embeds data as an html tag with a data-url.\"\"\"\n  b64 = base64.b64encode(data).decode()\n  if mime.startswith('image'):\n    tag = f'<img src=\"data:{mime};base64,{b64}\"/>'\n  elif mime.startswith('video'):\n    tag = textwrap.dedent(f\"\"\"\n        <video width=\"640\" height=\"480\" controls>\n          <source src=\"data:{mime};base64,{b64}\" type=\"video/mp4\">\n          Your browser does not support the video tag.",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.vis.embed",
        "documentation": {}
    },
    {
        "label": "embed_file",
        "kind": 2,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.vis.embed",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.vis.embed",
        "peekOfCode": "def embed_file(path: os.PathLike) -> IPython.display.HTML:\n  \"\"\"Embeds a file in the notebook as an html tag with a data-url.\"\"\"\n  path = pathlib.Path(path)\n  mime, unused_encoding = mimetypes.guess_type(str(path))\n  data = path.read_bytes()\n  return embed_data(mime, data)",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.vis.embed",
        "documentation": {}
    },
    {
        "label": "Webp",
        "kind": 6,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.vis.webp_animation",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.vis.webp_animation",
        "peekOfCode": "class Webp(object):\n  \"\"\"Builds a webp animation.\n  Attributes:\n    frame_rate: The default frame rate for appended images.\n    shape: The shape of the animation frames. Will default to the size of the\n      first image if not set.\n    result: The binary image data string. Once the animation has been used, it\n      can no longer updated. And the result field contains the webp encoded\n      data.\n  \"\"\"",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.vis.webp_animation",
        "documentation": {}
    },
    {
        "label": "env",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.vis.webp_animation",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.vis.webp_animation",
        "peekOfCode": "env = gym.make('SpaceInvaders-v0')\nobs = env.reset()\ndone = False\nn = 0\nanim = webp_animation.Webp()\nwhile not done:\n  img = env.render(mode = 'rgb_array')\n  anim.append(img)\n  act = env.action_space.sample() # take a random action\n  obs, reward, done, info = env.step(act)",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.vis.webp_animation",
        "documentation": {}
    },
    {
        "label": "obs",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.vis.webp_animation",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.vis.webp_animation",
        "peekOfCode": "obs = env.reset()\ndone = False\nn = 0\nanim = webp_animation.Webp()\nwhile not done:\n  img = env.render(mode = 'rgb_array')\n  anim.append(img)\n  act = env.action_space.sample() # take a random action\n  obs, reward, done, info = env.step(act)\n  n += 1",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.vis.webp_animation",
        "documentation": {}
    },
    {
        "label": "done",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.vis.webp_animation",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.vis.webp_animation",
        "peekOfCode": "done = False\nn = 0\nanim = webp_animation.Webp()\nwhile not done:\n  img = env.render(mode = 'rgb_array')\n  anim.append(img)\n  act = env.action_space.sample() # take a random action\n  obs, reward, done, info = env.step(act)\n  n += 1\nanim.save(\"test.webp\")",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.vis.webp_animation",
        "documentation": {}
    },
    {
        "label": "n",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.vis.webp_animation",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.vis.webp_animation",
        "peekOfCode": "n = 0\nanim = webp_animation.Webp()\nwhile not done:\n  img = env.render(mode = 'rgb_array')\n  anim.append(img)\n  act = env.action_space.sample() # take a random action\n  obs, reward, done, info = env.step(act)\n  n += 1\nanim.save(\"test.webp\")\nanim",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.vis.webp_animation",
        "documentation": {}
    },
    {
        "label": "anim",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.vis.webp_animation",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.vis.webp_animation",
        "peekOfCode": "anim = webp_animation.Webp()\nwhile not done:\n  img = env.render(mode = 'rgb_array')\n  anim.append(img)\n  act = env.action_space.sample() # take a random action\n  obs, reward, done, info = env.step(act)\n  n += 1\nanim.save(\"test.webp\")\nanim\n```",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.vis.webp_animation",
        "documentation": {}
    },
    {
        "label": "WebpTest",
        "kind": 6,
        "importPath": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.vis.webp_test",
        "description": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.vis.webp_test",
        "peekOfCode": "class WebpTest(absltest.TestCase):\n  def test_smoke(self):\n    workdir = self.create_tempdir().full_path\n    img = PIL.Image.fromarray(np.zeros([10, 12, 3], dtype=np.uint8))\n    anim = webp_animation.Webp()\n    anim.append(img)\n    anim.extend([img])\n    anim.save(os.path.join(workdir, 'test.webp'))\nif __name__ == '__main__':\n  absltest.main()",
        "detail": "JupyterNotebooks.docs-master.docs-master.tools.tensorflow_docs.vis.webp_test",
        "documentation": {}
    },
    {
        "label": "project_name",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.setup",
        "description": "JupyterNotebooks.docs-master.docs-master.setup",
        "peekOfCode": "project_name = 'tensorflow-docs'\nversion = '0.0.0'\ntry:\n  version += subprocess.check_output(['git', 'rev-parse',\n                                      'HEAD']).decode('utf-8')\nexcept subprocess.CalledProcessError:\n  pass\nDOCLINES = __doc__.split('\\n')\nREQUIRED_PKGS = [\n    'astor',",
        "detail": "JupyterNotebooks.docs-master.docs-master.setup",
        "documentation": {}
    },
    {
        "label": "version",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.setup",
        "description": "JupyterNotebooks.docs-master.docs-master.setup",
        "peekOfCode": "version = '0.0.0'\ntry:\n  version += subprocess.check_output(['git', 'rev-parse',\n                                      'HEAD']).decode('utf-8')\nexcept subprocess.CalledProcessError:\n  pass\nDOCLINES = __doc__.split('\\n')\nREQUIRED_PKGS = [\n    'astor',\n    'absl-py',",
        "detail": "JupyterNotebooks.docs-master.docs-master.setup",
        "documentation": {}
    },
    {
        "label": "DOCLINES",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.setup",
        "description": "JupyterNotebooks.docs-master.docs-master.setup",
        "peekOfCode": "DOCLINES = __doc__.split('\\n')\nREQUIRED_PKGS = [\n    'astor',\n    'absl-py',\n    'protobuf>=3.14',\n    'pyyaml',\n]\n# Dataclasses is in-built from py >=3.7. This version is a backport for py 3.6.\nif (sys.version_info.major, sys.version_info.minor) == (3, 6):\n  REQUIRED_PKGS.append('dataclasses')",
        "detail": "JupyterNotebooks.docs-master.docs-master.setup",
        "documentation": {}
    },
    {
        "label": "REQUIRED_PKGS",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.setup",
        "description": "JupyterNotebooks.docs-master.docs-master.setup",
        "peekOfCode": "REQUIRED_PKGS = [\n    'astor',\n    'absl-py',\n    'protobuf>=3.14',\n    'pyyaml',\n]\n# Dataclasses is in-built from py >=3.7. This version is a backport for py 3.6.\nif (sys.version_info.major, sys.version_info.minor) == (3, 6):\n  REQUIRED_PKGS.append('dataclasses')\nVIS_REQURE = [",
        "detail": "JupyterNotebooks.docs-master.docs-master.setup",
        "documentation": {}
    },
    {
        "label": "VIS_REQURE",
        "kind": 5,
        "importPath": "JupyterNotebooks.docs-master.docs-master.setup",
        "description": "JupyterNotebooks.docs-master.docs-master.setup",
        "peekOfCode": "VIS_REQURE = [\n    'numpy',\n    'PILLOW',\n    'webp',\n]\n# https://setuptools.readthedocs.io/en/latest/setuptools.html#new-and-changed-setup-keywords\nsetup(\n    name=project_name,\n    version=version,\n    description=DOCLINES[0],",
        "detail": "JupyterNotebooks.docs-master.docs-master.setup",
        "documentation": {}
    },
    {
        "label": "add_resolved_links",
        "kind": 2,
        "importPath": "JupyterNotebooks.Overflow.embed",
        "description": "JupyterNotebooks.Overflow.embed",
        "peekOfCode": "def add_resolved_links(store, drop_defaults):\n    \"\"\"Adds the state of any link models between two models in store\"\"\"\n    for widget_id, widget in Widget.widgets.items():  # go over all widgets\n        if isinstance(widget, Link) and widget_id not in store:\n            if widget.source[0].model_id in store and widget.target[0].model_id in store:\n                store[widget.model_id] = widget._get_embed_state(\n                    drop_defaults=drop_defaults)\ndef dependency_state(widgets, drop_defaults=True):\n    \"\"\"Get the state of all widgets specified, and their dependencies.\n    This uses a simple dependency finder, including:",
        "detail": "JupyterNotebooks.Overflow.embed",
        "documentation": {}
    },
    {
        "label": "dependency_state",
        "kind": 2,
        "importPath": "JupyterNotebooks.Overflow.embed",
        "description": "JupyterNotebooks.Overflow.embed",
        "peekOfCode": "def dependency_state(widgets, drop_defaults=True):\n    \"\"\"Get the state of all widgets specified, and their dependencies.\n    This uses a simple dependency finder, including:\n     - any widget directly referenced in the state of an included widget\n     - any widget in a list/tuple attribute in the state of an included widget\n     - any widget in a dict attribute in the state of an included widget\n     - any jslink/jsdlink between two included widgets\n    What this alogrithm does not do:\n     - Find widget references in nested list/dict structures\n     - Find widget references in other types of attributes",
        "detail": "JupyterNotebooks.Overflow.embed",
        "documentation": {}
    },
    {
        "label": "embed_data",
        "kind": 2,
        "importPath": "JupyterNotebooks.Overflow.embed",
        "description": "JupyterNotebooks.Overflow.embed",
        "peekOfCode": "def embed_data(views, drop_defaults=True, state=None):\n    \"\"\"Gets data for embedding.\n    Use this to get the raw data for embedding if you have special\n    formatting needs.\n    Parameters\n    ----------\n    {views_attribute}\n    drop_defaults: boolean\n        Whether to drop default values from the widget states.\n    state: dict or None (default)",
        "detail": "JupyterNotebooks.Overflow.embed",
        "documentation": {}
    },
    {
        "label": "escape_script",
        "kind": 2,
        "importPath": "JupyterNotebooks.Overflow.embed",
        "description": "JupyterNotebooks.Overflow.embed",
        "peekOfCode": "def escape_script(s):\n    \"\"\"Escape a string that will be the content of an HTML script tag.\n    We replace the opening bracket of <script, </script, and <!-- with the unicode\n    equivalent. This is inspired by the documentation for the script tag at\n    https://html.spec.whatwg.org/multipage/scripting.html#restrictions-for-contents-of-script-elements\n    We only replace these three cases so that most html or other content\n    involving `<` is readable.\n    \"\"\"\n    return script_escape_re.sub(r'\\\\u003c\\1', s)\n@doc_subst(_doc_snippets)",
        "detail": "JupyterNotebooks.Overflow.embed",
        "documentation": {}
    },
    {
        "label": "embed_snippet",
        "kind": 2,
        "importPath": "JupyterNotebooks.Overflow.embed",
        "description": "JupyterNotebooks.Overflow.embed",
        "peekOfCode": "def embed_snippet(views,\n                  drop_defaults=True,\n                  state=None,\n                  indent=2,\n                  embed_url=None,\n                  requirejs=True,\n                  cors=True\n                  ):\n    \"\"\"Return a snippet that can be embedded in an HTML file.\n    Parameters",
        "detail": "JupyterNotebooks.Overflow.embed",
        "documentation": {}
    },
    {
        "label": "embed_minimal_html",
        "kind": 2,
        "importPath": "JupyterNotebooks.Overflow.embed",
        "description": "JupyterNotebooks.Overflow.embed",
        "peekOfCode": "def embed_minimal_html(fp, views, title=u'IPyWidget export', template=None, **kwargs):\n    \"\"\"Write a minimal HTML file with widget views embedded.\n    Parameters\n    ----------\n    fp: filename or file-like object\n        The file to write the HTML output to.\n    {views_attribute}\n    title: title of the html page.\n    template: Template in which to embed the widget state.\n        This should be a Python string with placeholders",
        "detail": "JupyterNotebooks.Overflow.embed",
        "documentation": {}
    },
    {
        "label": "snippet_template",
        "kind": 5,
        "importPath": "JupyterNotebooks.Overflow.embed",
        "description": "JupyterNotebooks.Overflow.embed",
        "peekOfCode": "snippet_template = u\"\"\"\n{load}\n<script type=\"application/vnd.jupyter.widget-state+json\">\n{json_data}\n</script>\n{widget_views}\n\"\"\"\nload_template = u\"\"\"<script src=\"{embed_url}\"{use_cors}></script>\"\"\"\nload_requirejs_template = u\"\"\"\n<!-- Load require.js. Delete this if your page already loads require.js -->",
        "detail": "JupyterNotebooks.Overflow.embed",
        "documentation": {}
    },
    {
        "label": "load_template",
        "kind": 5,
        "importPath": "JupyterNotebooks.Overflow.embed",
        "description": "JupyterNotebooks.Overflow.embed",
        "peekOfCode": "load_template = u\"\"\"<script src=\"{embed_url}\"{use_cors}></script>\"\"\"\nload_requirejs_template = u\"\"\"\n<!-- Load require.js. Delete this if your page already loads require.js -->\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js\" integrity=\"sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=\" crossorigin=\"anonymous\"></script>\n<script src=\"{embed_url}\"{use_cors}></script>\n\"\"\"\nrequirejs_snippet_template = u\"\"\"\n<script type=\"application/vnd.jupyter.widget-state+json\">\n{json_data}\n</script>",
        "detail": "JupyterNotebooks.Overflow.embed",
        "documentation": {}
    },
    {
        "label": "load_requirejs_template",
        "kind": 5,
        "importPath": "JupyterNotebooks.Overflow.embed",
        "description": "JupyterNotebooks.Overflow.embed",
        "peekOfCode": "load_requirejs_template = u\"\"\"\n<!-- Load require.js. Delete this if your page already loads require.js -->\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js\" integrity=\"sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=\" crossorigin=\"anonymous\"></script>\n<script src=\"{embed_url}\"{use_cors}></script>\n\"\"\"\nrequirejs_snippet_template = u\"\"\"\n<script type=\"application/vnd.jupyter.widget-state+json\">\n{json_data}\n</script>\n{widget_views}",
        "detail": "JupyterNotebooks.Overflow.embed",
        "documentation": {}
    },
    {
        "label": "requirejs_snippet_template",
        "kind": 5,
        "importPath": "JupyterNotebooks.Overflow.embed",
        "description": "JupyterNotebooks.Overflow.embed",
        "peekOfCode": "requirejs_snippet_template = u\"\"\"\n<script type=\"application/vnd.jupyter.widget-state+json\">\n{json_data}\n</script>\n{widget_views}\n\"\"\"\nhtml_template = u\"\"\"<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">",
        "detail": "JupyterNotebooks.Overflow.embed",
        "documentation": {}
    },
    {
        "label": "html_template",
        "kind": 5,
        "importPath": "JupyterNotebooks.Overflow.embed",
        "description": "JupyterNotebooks.Overflow.embed",
        "peekOfCode": "html_template = u\"\"\"<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <title>{title}</title>\n</head>\n<body>\n{snippet}\n</body>\n</html>",
        "detail": "JupyterNotebooks.Overflow.embed",
        "documentation": {}
    },
    {
        "label": "widget_view_template",
        "kind": 5,
        "importPath": "JupyterNotebooks.Overflow.embed",
        "description": "JupyterNotebooks.Overflow.embed",
        "peekOfCode": "widget_view_template = u\"\"\"<script type=\"application/vnd.jupyter.widget-view+json\">\n{view_spec}\n</script>\"\"\"\nDEFAULT_EMBED_SCRIPT_URL = u'https://unpkg.com/@jupyter-widgets/html-manager@%s/dist/embed.js' % __html_manager_version__\nDEFAULT_EMBED_REQUIREJS_URL = u'https://unpkg.com/@jupyter-widgets/html-manager@%s/dist/embed-amd.js' % __html_manager_version__\n_doc_snippets = {}\n_doc_snippets['views_attribute'] = \"\"\"\n    views: widget or collection of widgets or None\n        The widgets to include views for. If None, all DOMWidgets are\n        included (not just the displayed ones).",
        "detail": "JupyterNotebooks.Overflow.embed",
        "documentation": {}
    },
    {
        "label": "DEFAULT_EMBED_SCRIPT_URL",
        "kind": 5,
        "importPath": "JupyterNotebooks.Overflow.embed",
        "description": "JupyterNotebooks.Overflow.embed",
        "peekOfCode": "DEFAULT_EMBED_SCRIPT_URL = u'https://unpkg.com/@jupyter-widgets/html-manager@%s/dist/embed.js' % __html_manager_version__\nDEFAULT_EMBED_REQUIREJS_URL = u'https://unpkg.com/@jupyter-widgets/html-manager@%s/dist/embed-amd.js' % __html_manager_version__\n_doc_snippets = {}\n_doc_snippets['views_attribute'] = \"\"\"\n    views: widget or collection of widgets or None\n        The widgets to include views for. If None, all DOMWidgets are\n        included (not just the displayed ones).\n\"\"\"\n_doc_snippets['embed_kwargs'] = \"\"\"\n    drop_defaults: boolean",
        "detail": "JupyterNotebooks.Overflow.embed",
        "documentation": {}
    },
    {
        "label": "DEFAULT_EMBED_REQUIREJS_URL",
        "kind": 5,
        "importPath": "JupyterNotebooks.Overflow.embed",
        "description": "JupyterNotebooks.Overflow.embed",
        "peekOfCode": "DEFAULT_EMBED_REQUIREJS_URL = u'https://unpkg.com/@jupyter-widgets/html-manager@%s/dist/embed-amd.js' % __html_manager_version__\n_doc_snippets = {}\n_doc_snippets['views_attribute'] = \"\"\"\n    views: widget or collection of widgets or None\n        The widgets to include views for. If None, all DOMWidgets are\n        included (not just the displayed ones).\n\"\"\"\n_doc_snippets['embed_kwargs'] = \"\"\"\n    drop_defaults: boolean\n        Whether to drop default values from the widget states.",
        "detail": "JupyterNotebooks.Overflow.embed",
        "documentation": {}
    },
    {
        "label": "_doc_snippets",
        "kind": 5,
        "importPath": "JupyterNotebooks.Overflow.embed",
        "description": "JupyterNotebooks.Overflow.embed",
        "peekOfCode": "_doc_snippets = {}\n_doc_snippets['views_attribute'] = \"\"\"\n    views: widget or collection of widgets or None\n        The widgets to include views for. If None, all DOMWidgets are\n        included (not just the displayed ones).\n\"\"\"\n_doc_snippets['embed_kwargs'] = \"\"\"\n    drop_defaults: boolean\n        Whether to drop default values from the widget states.\n    state: dict or None (default)",
        "detail": "JupyterNotebooks.Overflow.embed",
        "documentation": {}
    },
    {
        "label": "_doc_snippets['views_attribute']",
        "kind": 5,
        "importPath": "JupyterNotebooks.Overflow.embed",
        "description": "JupyterNotebooks.Overflow.embed",
        "peekOfCode": "_doc_snippets['views_attribute'] = \"\"\"\n    views: widget or collection of widgets or None\n        The widgets to include views for. If None, all DOMWidgets are\n        included (not just the displayed ones).\n\"\"\"\n_doc_snippets['embed_kwargs'] = \"\"\"\n    drop_defaults: boolean\n        Whether to drop default values from the widget states.\n    state: dict or None (default)\n        The state to include. When set to None, the state of all widgets",
        "detail": "JupyterNotebooks.Overflow.embed",
        "documentation": {}
    },
    {
        "label": "_doc_snippets['embed_kwargs']",
        "kind": 5,
        "importPath": "JupyterNotebooks.Overflow.embed",
        "description": "JupyterNotebooks.Overflow.embed",
        "peekOfCode": "_doc_snippets['embed_kwargs'] = \"\"\"\n    drop_defaults: boolean\n        Whether to drop default values from the widget states.\n    state: dict or None (default)\n        The state to include. When set to None, the state of all widgets\n        know to the widget manager is included. Otherwise it uses the\n        passed state directly. This allows for end users to include a\n        smaller state, under the responsibility that this state is\n        sufficient to reconstruct the embedded views.\n    indent: integer, string or None",
        "detail": "JupyterNotebooks.Overflow.embed",
        "documentation": {}
    },
    {
        "label": "script_escape_re",
        "kind": 5,
        "importPath": "JupyterNotebooks.Overflow.embed",
        "description": "JupyterNotebooks.Overflow.embed",
        "peekOfCode": "script_escape_re = re.compile(r'<(script|/script|!--)', re.IGNORECASE)\ndef escape_script(s):\n    \"\"\"Escape a string that will be the content of an HTML script tag.\n    We replace the opening bracket of <script, </script, and <!-- with the unicode\n    equivalent. This is inspired by the documentation for the script tag at\n    https://html.spec.whatwg.org/multipage/scripting.html#restrictions-for-contents-of-script-elements\n    We only replace these three cases so that most html or other content\n    involving `<` is readable.\n    \"\"\"\n    return script_escape_re.sub(r'\\\\u003c\\1', s)",
        "detail": "JupyterNotebooks.Overflow.embed",
        "documentation": {}
    },
    {
        "label": "create_directory",
        "kind": 2,
        "importPath": "NEW-NPM-PAK.backup",
        "description": "NEW-NPM-PAK.backup",
        "peekOfCode": "def create_directory(name):\n    if exists(pardir + \"\\\\\" + name):\n        print('Folder already exists... Cannot Overwrite this')\n    else:\n        makedirs(pardir + \"\\\\\" + name)\n# Deletes a directory\ndef delete_directory(name):\n    removedirs(name)\n# Rename a directory\ndef rename_directory(direct, name):",
        "detail": "NEW-NPM-PAK.backup",
        "documentation": {}
    },
    {
        "label": "delete_directory",
        "kind": 2,
        "importPath": "NEW-NPM-PAK.backup",
        "description": "NEW-NPM-PAK.backup",
        "peekOfCode": "def delete_directory(name):\n    removedirs(name)\n# Rename a directory\ndef rename_directory(direct, name):\n    rename(direct, name)\n# Sets the working directory\ndef set_working_directory():\n    chdir(pardir)\n# Backup the folder tree\ndef backup_files(name_dir, folder):",
        "detail": "NEW-NPM-PAK.backup",
        "documentation": {}
    },
    {
        "label": "rename_directory",
        "kind": 2,
        "importPath": "NEW-NPM-PAK.backup",
        "description": "NEW-NPM-PAK.backup",
        "peekOfCode": "def rename_directory(direct, name):\n    rename(direct, name)\n# Sets the working directory\ndef set_working_directory():\n    chdir(pardir)\n# Backup the folder tree\ndef backup_files(name_dir, folder):\n    copytree(pardir, name_dir + ':\\\\' + folder)\n# Move folder to specific location\n# Overwrites the file if it already exists",
        "detail": "NEW-NPM-PAK.backup",
        "documentation": {}
    },
    {
        "label": "set_working_directory",
        "kind": 2,
        "importPath": "NEW-NPM-PAK.backup",
        "description": "NEW-NPM-PAK.backup",
        "peekOfCode": "def set_working_directory():\n    chdir(pardir)\n# Backup the folder tree\ndef backup_files(name_dir, folder):\n    copytree(pardir, name_dir + ':\\\\' + folder)\n# Move folder to specific location\n# Overwrites the file if it already exists\ndef move_folder(filename, name_dir, folder):\n    if not exists(name_dir + \":\\\\\" + folder):\n        makedirs(name_dir + ':\\\\' + folder)",
        "detail": "NEW-NPM-PAK.backup",
        "documentation": {}
    },
    {
        "label": "backup_files",
        "kind": 2,
        "importPath": "NEW-NPM-PAK.backup",
        "description": "NEW-NPM-PAK.backup",
        "peekOfCode": "def backup_files(name_dir, folder):\n    copytree(pardir, name_dir + ':\\\\' + folder)\n# Move folder to specific location\n# Overwrites the file if it already exists\ndef move_folder(filename, name_dir, folder):\n    if not exists(name_dir + \":\\\\\" + folder):\n        makedirs(name_dir + ':\\\\' + folder)\n    move(filename, name_dir + \":\\\\\" + folder + '\\\\')\ncreate_directory(\"test\")\nrename_directory(\"test\",\"demo\")",
        "detail": "NEW-NPM-PAK.backup",
        "documentation": {}
    },
    {
        "label": "move_folder",
        "kind": 2,
        "importPath": "NEW-NPM-PAK.backup",
        "description": "NEW-NPM-PAK.backup",
        "peekOfCode": "def move_folder(filename, name_dir, folder):\n    if not exists(name_dir + \":\\\\\" + folder):\n        makedirs(name_dir + ':\\\\' + folder)\n    move(filename, name_dir + \":\\\\\" + folder + '\\\\')\ncreate_directory(\"test\")\nrename_directory(\"test\",\"demo\")\ncreate_directory(\"test\")\n# delete_directory(\"demo\")\nbackup_files('D', 'backup_project')\nmove_folder(pardir+'\\\\'+'test.txt', 'D', 'name')",
        "detail": "NEW-NPM-PAK.backup",
        "documentation": {}
    },
    {
        "label": "convert_to_wav",
        "kind": 2,
        "importPath": "REACT-AUDIO-REPO.ac-audio-extractor-master.analyze",
        "description": "REACT-AUDIO-REPO.ac-audio-extractor-master.analyze",
        "peekOfCode": "def convert_to_wav(audiofile, samplerate=44100):\n    # Convert to mono WAV using ffmpeg\n    output_filename = '/tmp/{0}-converted.wav'.format(hashlib.md5(audiofile.encode('utf-8')).hexdigest())\n    if not os.path.exists(output_filename):\n        logger.debug('{0}: converting to WAV'.format(audiofile))\n        ffmpeg.input(audiofile).output(output_filename, ac=1).run(quiet=True, overwrite_output=True)            \n    return output_filename\ndef run_freesound_extractor(audiofile):\n    logger.debug('{0}: running Essentia\\'s FreesoundExtractor'.format(audiofile))\n    try:",
        "detail": "REACT-AUDIO-REPO.ac-audio-extractor-master.analyze",
        "documentation": {}
    },
    {
        "label": "run_freesound_extractor",
        "kind": 2,
        "importPath": "REACT-AUDIO-REPO.ac-audio-extractor-master.analyze",
        "description": "REACT-AUDIO-REPO.ac-audio-extractor-master.analyze",
        "peekOfCode": "def run_freesound_extractor(audiofile):\n    logger.debug('{0}: running Essentia\\'s FreesoundExtractor'.format(audiofile))\n    try:\n        fs_pool, _ = FreesoundExtractor()(audiofile)\n    except RuntimeError as e:\n        if MORE_THAN_2_CHANNELS_EXCEPTION_MATCH_TEXT in str(e) or METADATA_READER_EXCEPTION_MATCH_TEXT in (str(e)):\n            converted_audiofile = convert_to_wav(audiofile)\n            fs_pool, _ = FreesoundExtractor()(converted_audiofile)\n        else:\n            raise e",
        "detail": "REACT-AUDIO-REPO.ac-audio-extractor-master.analyze",
        "documentation": {}
    },
    {
        "label": "estimate_number_of_events",
        "kind": 2,
        "importPath": "REACT-AUDIO-REPO.ac-audio-extractor-master.analyze",
        "description": "REACT-AUDIO-REPO.ac-audio-extractor-master.analyze",
        "peekOfCode": "def estimate_number_of_events(audiofile, audio, sample_rate=44100, region_energy_thr=0.5, silence_thr_scale=4.5, group_regions_ms=50):\n    \"\"\"\n    Returns list of activity \"onsets\" for an audio signal based on its energy envelope. \n    This is more like \"activity detecton\" than \"onset detection\".\n    \"\"\"    \n    logger.debug('{0}: estimating number of sound events'.format(audiofile))\n    def group_regions(regions, group_regions_ms):\n        \"\"\"\n        Group together regions which are very close in time (i.e. the end of a region is very close to the start of the following).\n        \"\"\"",
        "detail": "REACT-AUDIO-REPO.ac-audio-extractor-master.analyze",
        "documentation": {}
    },
    {
        "label": "is_single_event",
        "kind": 2,
        "importPath": "REACT-AUDIO-REPO.ac-audio-extractor-master.analyze",
        "description": "REACT-AUDIO-REPO.ac-audio-extractor-master.analyze",
        "peekOfCode": "def is_single_event(audiofile, max_duration=7):\n    '''\n    Estimate if the audio signal contains one single event using the 'estimate_number_of_events'\n    function above. We store the result of 'estimate_number_of_events' in a global variable so\n    it can be reused in the different calls of 'is_single_event'.\n    '''\n    global _is_single_event_cache\n    if _is_single_event_cache is None:\n        sample_rate = 44100\n        try:",
        "detail": "REACT-AUDIO-REPO.ac-audio-extractor-master.analyze",
        "documentation": {}
    },
    {
        "label": "ac_general_description",
        "kind": 2,
        "importPath": "REACT-AUDIO-REPO.ac-audio-extractor-master.analyze",
        "description": "REACT-AUDIO-REPO.ac-audio-extractor-master.analyze",
        "peekOfCode": "def ac_general_description(audiofile, fs_pool, ac_descriptors):\n    logger.debug('{0}: adding basic AudioCommons descriptors'.format(audiofile))\n    # Add Audio Commons descriptors from the fs_pool\n    for ac_name, essenia_name in ac_mapping.items():\n        if fs_pool.containsKey(essenia_name):\n            value = fs_pool[essenia_name]\n            ac_descriptors[ac_name] = value\n    ac_descriptors[\"filesize\"] = os.stat(audiofile).st_size\n    ac_descriptors[\"single_event\"] = is_single_event(audiofile)\ndef ac_rhythm_description(audiofile, fs_pool, ac_descriptors):",
        "detail": "REACT-AUDIO-REPO.ac-audio-extractor-master.analyze",
        "documentation": {}
    },
    {
        "label": "ac_rhythm_description",
        "kind": 2,
        "importPath": "REACT-AUDIO-REPO.ac-audio-extractor-master.analyze",
        "description": "REACT-AUDIO-REPO.ac-audio-extractor-master.analyze",
        "peekOfCode": "def ac_rhythm_description(audiofile, fs_pool, ac_descriptors):\n    logger.debug('{0}: adding rhythm descriptors'.format(audiofile))\n    IS_LOOP_CONFIDENCE_THRESHOLD = 0.95\n    is_loop = fs_pool['rhythm.bpm_loop_confidence.mean'] > IS_LOOP_CONFIDENCE_THRESHOLD\n    ac_descriptors[\"loop\"] = is_loop\n    if is_loop:\n        ac_descriptors[\"tempo\"] = int(round(fs_pool['rhythm.bpm_loop']))\n        ac_descriptors[\"tempo_confidence\"] = fs_pool['rhythm.bpm_loop_confidence.mean']\n    else:\n        ac_descriptors[\"tempo\"] = int(round(fs_pool['rhythm.bpm']))",
        "detail": "REACT-AUDIO-REPO.ac-audio-extractor-master.analyze",
        "documentation": {}
    },
    {
        "label": "ac_tonality_description",
        "kind": 2,
        "importPath": "REACT-AUDIO-REPO.ac-audio-extractor-master.analyze",
        "description": "REACT-AUDIO-REPO.ac-audio-extractor-master.analyze",
        "peekOfCode": "def ac_tonality_description(audiofile, fs_pool, ac_descriptors):\n    logger.debug('{0}: adding tonality descriptors'.format(audiofile))\n    key = fs_pool['tonal.key.key'] + \" \" + fs_pool['tonal.key.scale']\n    ac_descriptors[\"tonality\"] = key\n    ac_descriptors[\"tonality_confidence\"] = fs_pool['tonal.key.strength']\ndef ac_pitch_description(audiofile, fs_pool, ac_descriptors):\n    logger.debug('{0}: adding pitch descriptors'.format(audiofile))\n    def midi_note_to_note(midi_note):\n        # Use convention MIDI value 69 = 440.0 Hz = A4\n        note = midi_note % 12",
        "detail": "REACT-AUDIO-REPO.ac-audio-extractor-master.analyze",
        "documentation": {}
    },
    {
        "label": "ac_pitch_description",
        "kind": 2,
        "importPath": "REACT-AUDIO-REPO.ac-audio-extractor-master.analyze",
        "description": "REACT-AUDIO-REPO.ac-audio-extractor-master.analyze",
        "peekOfCode": "def ac_pitch_description(audiofile, fs_pool, ac_descriptors):\n    logger.debug('{0}: adding pitch descriptors'.format(audiofile))\n    def midi_note_to_note(midi_note):\n        # Use convention MIDI value 69 = 440.0 Hz = A4\n        note = midi_note % 12\n        octave = midi_note / 12\n        return '%s%i' % (['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B'][note], octave - 1)\n    def frequency_to_midi_note(frequency):\n        return int(round(69 + (12 * math.log(frequency / 440.0)) / math.log(2)))\n    pitch_median = float(fs_pool['lowlevel.pitch.median'])",
        "detail": "REACT-AUDIO-REPO.ac-audio-extractor-master.analyze",
        "documentation": {}
    },
    {
        "label": "ac_timbral_models",
        "kind": 2,
        "importPath": "REACT-AUDIO-REPO.ac-audio-extractor-master.analyze",
        "description": "REACT-AUDIO-REPO.ac-audio-extractor-master.analyze",
        "peekOfCode": "def ac_timbral_models(audiofile, ac_descriptors):\n    logger.debug('{0}: computing timbral models'.format(audiofile))\n    converted_filename = convert_to_wav(audiofile)\n    try:\n        timbre = timbral_models.timbral_extractor(converted_filename, clip_output=True, verbose=False)\n        timbre['reverb'] = timbre['reverb'] == 1\n        ac_descriptors.update(timbre)\n    except Exception as e:\n        logger.debug('{0}: timbral models computation failed (\"{1}\")'.format(audiofile, e))\ndef ac_highlevel_music_description(audiofile, ac_descriptors):",
        "detail": "REACT-AUDIO-REPO.ac-audio-extractor-master.analyze",
        "documentation": {}
    },
    {
        "label": "ac_highlevel_music_description",
        "kind": 2,
        "importPath": "REACT-AUDIO-REPO.ac-audio-extractor-master.analyze",
        "description": "REACT-AUDIO-REPO.ac-audio-extractor-master.analyze",
        "peekOfCode": "def ac_highlevel_music_description(audiofile, ac_descriptors):\n    logger.debug('{0}: running Essentia\\'s MusicExtractor'.format(audiofile))\n    me_pool, _ = MusicExtractor(profile='music_extractor_profile.yaml')(audiofile)\n    ac_descriptors[\"genre\"] = me_pool['highlevel.genre_test.value']\n    ac_descriptors[\"mood\"] = me_pool['highlevel.mood_test.value']\ndef build_graph(ac_descriptors, uri=None):\n    g = Graph()\n    audioFile = BNode()\n    if uri is None:\n        availableItemOf = BNode()",
        "detail": "REACT-AUDIO-REPO.ac-audio-extractor-master.analyze",
        "documentation": {}
    },
    {
        "label": "build_graph",
        "kind": 2,
        "importPath": "REACT-AUDIO-REPO.ac-audio-extractor-master.analyze",
        "description": "REACT-AUDIO-REPO.ac-audio-extractor-master.analyze",
        "peekOfCode": "def build_graph(ac_descriptors, uri=None):\n    g = Graph()\n    audioFile = BNode()\n    if uri is None:\n        availableItemOf = BNode()\n    else:\n        availableItemOf = URIRef(uri)\n    g.add((availableItemOf, RDF['type'], AC['AudioClip']))\n    g.add((audioFile, AC['availableItemOf'], availableItemOf))\n    g.add((audioFile, RDF['type'], AC['AudioFile'])) ",
        "detail": "REACT-AUDIO-REPO.ac-audio-extractor-master.analyze",
        "documentation": {}
    },
    {
        "label": "render_jsonld_output",
        "kind": 2,
        "importPath": "REACT-AUDIO-REPO.ac-audio-extractor-master.analyze",
        "description": "REACT-AUDIO-REPO.ac-audio-extractor-master.analyze",
        "peekOfCode": "def render_jsonld_output(g):\n    def dlfake(input):\n        '''This is to avoid a bug in PyLD (should be easy to fix and avoid this hack really..)'''\n        return {'contextUrl': None,'documentUrl': None,'document': input}\n    context = {\n        \"rdf\": str(RDF),\n        \"ac\": str(AC),\n        \"afo\": str(AFO),\n        \"afv\": str(AFV),\n        \"ebucore\": str(EBU),",
        "detail": "REACT-AUDIO-REPO.ac-audio-extractor-master.analyze",
        "documentation": {}
    },
    {
        "label": "analyze",
        "kind": 2,
        "importPath": "REACT-AUDIO-REPO.ac-audio-extractor-master.analyze",
        "description": "REACT-AUDIO-REPO.ac-audio-extractor-master.analyze",
        "peekOfCode": "def analyze(audiofile, outfile, compute_timbral_models=False, compute_descriptors_music_pieces=False, compute_descriptors_music_samples=False, out_format=\"json\", uri=None):\n    logger.info('{0}: starting analysis'.format(audiofile))\n    # Get initial descriptors from Freesound Extractor\n    fs_pool = run_freesound_extractor(audiofile)\n    # Post-process descriptors to get AudioCommons descirptors and compute extra ones\n    ac_descriptors = dict()\n    ac_general_description(audiofile, fs_pool, ac_descriptors)\n    if compute_descriptors_music_pieces or compute_descriptors_music_samples:\n        ac_tonality_description(audiofile, fs_pool, ac_descriptors)\n        ac_rhythm_description(audiofile, fs_pool, ac_descriptors)",
        "detail": "REACT-AUDIO-REPO.ac-audio-extractor-master.analyze",
        "documentation": {}
    },
    {
        "label": "essentia.log.infoActive",
        "kind": 5,
        "importPath": "REACT-AUDIO-REPO.ac-audio-extractor-master.analyze",
        "description": "REACT-AUDIO-REPO.ac-audio-extractor-master.analyze",
        "peekOfCode": "essentia.log.infoActive = False\nessentia.log.warningActive = False\nimport uuid\nimport ffmpeg\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom essentia.standard import MusicExtractor, FreesoundExtractor, MonoLoader, MonoWriter\nfrom rdflib import Graph, URIRef, BNode, Literal, Namespace, plugin\nfrom rdflib.serializer import Serializer\nfrom rdflib.namespace import RDF",
        "detail": "REACT-AUDIO-REPO.ac-audio-extractor-master.analyze",
        "documentation": {}
    },
    {
        "label": "essentia.log.warningActive",
        "kind": 5,
        "importPath": "REACT-AUDIO-REPO.ac-audio-extractor-master.analyze",
        "description": "REACT-AUDIO-REPO.ac-audio-extractor-master.analyze",
        "peekOfCode": "essentia.log.warningActive = False\nimport uuid\nimport ffmpeg\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom essentia.standard import MusicExtractor, FreesoundExtractor, MonoLoader, MonoWriter\nfrom rdflib import Graph, URIRef, BNode, Literal, Namespace, plugin\nfrom rdflib.serializer import Serializer\nfrom rdflib.namespace import RDF\nfrom argparse import ArgumentParser, ArgumentTypeError",
        "detail": "REACT-AUDIO-REPO.ac-audio-extractor-master.analyze",
        "documentation": {}
    },
    {
        "label": "MORE_THAN_2_CHANNELS_EXCEPTION_MATCH_TEXT",
        "kind": 5,
        "importPath": "REACT-AUDIO-REPO.ac-audio-extractor-master.analyze",
        "description": "REACT-AUDIO-REPO.ac-audio-extractor-master.analyze",
        "peekOfCode": "MORE_THAN_2_CHANNELS_EXCEPTION_MATCH_TEXT = 'Audio file has more than 2 channels'\nMETADATA_READER_EXCEPTION_MATCH_TEXT = 'pcmMetadata cannot read files which are neither \"wav\" nor \"aiff\"'\nlogger = logging.getLogger()\nAC = Namespace(\"https://w3id.org/ac-ontology/aco#\")\nAFO = Namespace(\"https://w3id.org/afo/onto/1.1#\")\nAFV = Namespace(\"https://w3id.org/afo/vocab/1.1#\")\nEBU = Namespace(\"http://www.ebu.ch/metadata/ontologies/ebucore/ebucore#\")\nNFO = Namespace(\"http://www.semanticdesktop.org/ontologies/2007/03/22/nfo#\")\nac_mapping = {\n    \"duration\": \"metadata.audio_properties.length\",",
        "detail": "REACT-AUDIO-REPO.ac-audio-extractor-master.analyze",
        "documentation": {}
    },
    {
        "label": "METADATA_READER_EXCEPTION_MATCH_TEXT",
        "kind": 5,
        "importPath": "REACT-AUDIO-REPO.ac-audio-extractor-master.analyze",
        "description": "REACT-AUDIO-REPO.ac-audio-extractor-master.analyze",
        "peekOfCode": "METADATA_READER_EXCEPTION_MATCH_TEXT = 'pcmMetadata cannot read files which are neither \"wav\" nor \"aiff\"'\nlogger = logging.getLogger()\nAC = Namespace(\"https://w3id.org/ac-ontology/aco#\")\nAFO = Namespace(\"https://w3id.org/afo/onto/1.1#\")\nAFV = Namespace(\"https://w3id.org/afo/vocab/1.1#\")\nEBU = Namespace(\"http://www.ebu.ch/metadata/ontologies/ebucore/ebucore#\")\nNFO = Namespace(\"http://www.semanticdesktop.org/ontologies/2007/03/22/nfo#\")\nac_mapping = {\n    \"duration\": \"metadata.audio_properties.length\",\n    \"lossless\": \"metadata.audio_properties.lossless\",",
        "detail": "REACT-AUDIO-REPO.ac-audio-extractor-master.analyze",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "REACT-AUDIO-REPO.ac-audio-extractor-master.analyze",
        "description": "REACT-AUDIO-REPO.ac-audio-extractor-master.analyze",
        "peekOfCode": "logger = logging.getLogger()\nAC = Namespace(\"https://w3id.org/ac-ontology/aco#\")\nAFO = Namespace(\"https://w3id.org/afo/onto/1.1#\")\nAFV = Namespace(\"https://w3id.org/afo/vocab/1.1#\")\nEBU = Namespace(\"http://www.ebu.ch/metadata/ontologies/ebucore/ebucore#\")\nNFO = Namespace(\"http://www.semanticdesktop.org/ontologies/2007/03/22/nfo#\")\nac_mapping = {\n    \"duration\": \"metadata.audio_properties.length\",\n    \"lossless\": \"metadata.audio_properties.lossless\",\n    \"codec\": \"metadata.audio_properties.codec\",",
        "detail": "REACT-AUDIO-REPO.ac-audio-extractor-master.analyze",
        "documentation": {}
    },
    {
        "label": "AC",
        "kind": 5,
        "importPath": "REACT-AUDIO-REPO.ac-audio-extractor-master.analyze",
        "description": "REACT-AUDIO-REPO.ac-audio-extractor-master.analyze",
        "peekOfCode": "AC = Namespace(\"https://w3id.org/ac-ontology/aco#\")\nAFO = Namespace(\"https://w3id.org/afo/onto/1.1#\")\nAFV = Namespace(\"https://w3id.org/afo/vocab/1.1#\")\nEBU = Namespace(\"http://www.ebu.ch/metadata/ontologies/ebucore/ebucore#\")\nNFO = Namespace(\"http://www.semanticdesktop.org/ontologies/2007/03/22/nfo#\")\nac_mapping = {\n    \"duration\": \"metadata.audio_properties.length\",\n    \"lossless\": \"metadata.audio_properties.lossless\",\n    \"codec\": \"metadata.audio_properties.codec\",\n    \"bitrate\": \"metadata.audio_properties.bit_rate\",",
        "detail": "REACT-AUDIO-REPO.ac-audio-extractor-master.analyze",
        "documentation": {}
    },
    {
        "label": "AFO",
        "kind": 5,
        "importPath": "REACT-AUDIO-REPO.ac-audio-extractor-master.analyze",
        "description": "REACT-AUDIO-REPO.ac-audio-extractor-master.analyze",
        "peekOfCode": "AFO = Namespace(\"https://w3id.org/afo/onto/1.1#\")\nAFV = Namespace(\"https://w3id.org/afo/vocab/1.1#\")\nEBU = Namespace(\"http://www.ebu.ch/metadata/ontologies/ebucore/ebucore#\")\nNFO = Namespace(\"http://www.semanticdesktop.org/ontologies/2007/03/22/nfo#\")\nac_mapping = {\n    \"duration\": \"metadata.audio_properties.length\",\n    \"lossless\": \"metadata.audio_properties.lossless\",\n    \"codec\": \"metadata.audio_properties.codec\",\n    \"bitrate\": \"metadata.audio_properties.bit_rate\",\n    \"samplerate\": \"metadata.audio_properties.sample_rate\",",
        "detail": "REACT-AUDIO-REPO.ac-audio-extractor-master.analyze",
        "documentation": {}
    },
    {
        "label": "AFV",
        "kind": 5,
        "importPath": "REACT-AUDIO-REPO.ac-audio-extractor-master.analyze",
        "description": "REACT-AUDIO-REPO.ac-audio-extractor-master.analyze",
        "peekOfCode": "AFV = Namespace(\"https://w3id.org/afo/vocab/1.1#\")\nEBU = Namespace(\"http://www.ebu.ch/metadata/ontologies/ebucore/ebucore#\")\nNFO = Namespace(\"http://www.semanticdesktop.org/ontologies/2007/03/22/nfo#\")\nac_mapping = {\n    \"duration\": \"metadata.audio_properties.length\",\n    \"lossless\": \"metadata.audio_properties.lossless\",\n    \"codec\": \"metadata.audio_properties.codec\",\n    \"bitrate\": \"metadata.audio_properties.bit_rate\",\n    \"samplerate\": \"metadata.audio_properties.sample_rate\",\n    \"channels\": \"metadata.audio_properties.number_channels\",",
        "detail": "REACT-AUDIO-REPO.ac-audio-extractor-master.analyze",
        "documentation": {}
    },
    {
        "label": "EBU",
        "kind": 5,
        "importPath": "REACT-AUDIO-REPO.ac-audio-extractor-master.analyze",
        "description": "REACT-AUDIO-REPO.ac-audio-extractor-master.analyze",
        "peekOfCode": "EBU = Namespace(\"http://www.ebu.ch/metadata/ontologies/ebucore/ebucore#\")\nNFO = Namespace(\"http://www.semanticdesktop.org/ontologies/2007/03/22/nfo#\")\nac_mapping = {\n    \"duration\": \"metadata.audio_properties.length\",\n    \"lossless\": \"metadata.audio_properties.lossless\",\n    \"codec\": \"metadata.audio_properties.codec\",\n    \"bitrate\": \"metadata.audio_properties.bit_rate\",\n    \"samplerate\": \"metadata.audio_properties.sample_rate\",\n    \"channels\": \"metadata.audio_properties.number_channels\",\n    \"audio_md5\": \"metadata.audio_properties.md5_encoded\",",
        "detail": "REACT-AUDIO-REPO.ac-audio-extractor-master.analyze",
        "documentation": {}
    },
    {
        "label": "NFO",
        "kind": 5,
        "importPath": "REACT-AUDIO-REPO.ac-audio-extractor-master.analyze",
        "description": "REACT-AUDIO-REPO.ac-audio-extractor-master.analyze",
        "peekOfCode": "NFO = Namespace(\"http://www.semanticdesktop.org/ontologies/2007/03/22/nfo#\")\nac_mapping = {\n    \"duration\": \"metadata.audio_properties.length\",\n    \"lossless\": \"metadata.audio_properties.lossless\",\n    \"codec\": \"metadata.audio_properties.codec\",\n    \"bitrate\": \"metadata.audio_properties.bit_rate\",\n    \"samplerate\": \"metadata.audio_properties.sample_rate\",\n    \"channels\": \"metadata.audio_properties.number_channels\",\n    \"audio_md5\": \"metadata.audio_properties.md5_encoded\",\n    \"loudness\": \"lowlevel.loudness_ebu128.integrated\",",
        "detail": "REACT-AUDIO-REPO.ac-audio-extractor-master.analyze",
        "documentation": {}
    },
    {
        "label": "ac_mapping",
        "kind": 5,
        "importPath": "REACT-AUDIO-REPO.ac-audio-extractor-master.analyze",
        "description": "REACT-AUDIO-REPO.ac-audio-extractor-master.analyze",
        "peekOfCode": "ac_mapping = {\n    \"duration\": \"metadata.audio_properties.length\",\n    \"lossless\": \"metadata.audio_properties.lossless\",\n    \"codec\": \"metadata.audio_properties.codec\",\n    \"bitrate\": \"metadata.audio_properties.bit_rate\",\n    \"samplerate\": \"metadata.audio_properties.sample_rate\",\n    \"channels\": \"metadata.audio_properties.number_channels\",\n    \"audio_md5\": \"metadata.audio_properties.md5_encoded\",\n    \"loudness\": \"lowlevel.loudness_ebu128.integrated\",\n    \"dynamic_range\": \"lowlevel.loudness_ebu128.loudness_range\",",
        "detail": "REACT-AUDIO-REPO.ac-audio-extractor-master.analyze",
        "documentation": {}
    },
    {
        "label": "_is_single_event_cache",
        "kind": 5,
        "importPath": "REACT-AUDIO-REPO.ac-audio-extractor-master.analyze",
        "description": "REACT-AUDIO-REPO.ac-audio-extractor-master.analyze",
        "peekOfCode": "_is_single_event_cache = None\ndef is_single_event(audiofile, max_duration=7):\n    '''\n    Estimate if the audio signal contains one single event using the 'estimate_number_of_events'\n    function above. We store the result of 'estimate_number_of_events' in a global variable so\n    it can be reused in the different calls of 'is_single_event'.\n    '''\n    global _is_single_event_cache\n    if _is_single_event_cache is None:\n        sample_rate = 44100",
        "detail": "REACT-AUDIO-REPO.ac-audio-extractor-master.analyze",
        "documentation": {}
    },
    {
        "label": "input_file",
        "kind": 5,
        "importPath": "_REPO.APRESS.js-data-structures-and-algorithms.clean_js",
        "description": "_REPO.APRESS.js-data-structures-and-algorithms.clean_js",
        "peekOfCode": "input_file = 'raw.js'\nwith open(input_file, \"r\") as f:\n\tcontent = f.read()\n\twith open(\"output.js\", \"w\") as w_f:\n\t\tfor a_line in content.split(\"\\n\"):\n\t\t\ta_line = a_line.split(\" \")\n\t\t\t#print (a_line)\n\t\t\ti = 0\n\t\t\tfor a_char in a_line:\n\t\t\t\tif a_char.isdigit():",
        "detail": "_REPO.APRESS.js-data-structures-and-algorithms.clean_js",
        "documentation": {}
    },
    {
        "label": "\tcontent",
        "kind": 5,
        "importPath": "_REPO.APRESS.js-data-structures-and-algorithms.clean_js",
        "description": "_REPO.APRESS.js-data-structures-and-algorithms.clean_js",
        "peekOfCode": "\tcontent = f.read()\n\twith open(\"output.js\", \"w\") as w_f:\n\t\tfor a_line in content.split(\"\\n\"):\n\t\t\ta_line = a_line.split(\" \")\n\t\t\t#print (a_line)\n\t\t\ti = 0\n\t\t\tfor a_char in a_line:\n\t\t\t\tif a_char.isdigit():\n\t\t\t\t\tbreak\n\t\t\t\ti += 1",
        "detail": "_REPO.APRESS.js-data-structures-and-algorithms.clean_js",
        "documentation": {}
    },
    {
        "label": "\t\t\ta_line",
        "kind": 5,
        "importPath": "_REPO.APRESS.js-data-structures-and-algorithms.clean_js",
        "description": "_REPO.APRESS.js-data-structures-and-algorithms.clean_js",
        "peekOfCode": "\t\t\ta_line = a_line.split(\" \")\n\t\t\t#print (a_line)\n\t\t\ti = 0\n\t\t\tfor a_char in a_line:\n\t\t\t\tif a_char.isdigit():\n\t\t\t\t\tbreak\n\t\t\t\ti += 1\n\t\t\t\t#print(i)\n\t\t\tprint \" \".join(a_line[i+1:])\n\t\t\tw_f.write(\" \".join(a_line[i+1:]) + \"\\n\")",
        "detail": "_REPO.APRESS.js-data-structures-and-algorithms.clean_js",
        "documentation": {}
    },
    {
        "label": "\t\t\ti",
        "kind": 5,
        "importPath": "_REPO.APRESS.js-data-structures-and-algorithms.clean_js",
        "description": "_REPO.APRESS.js-data-structures-and-algorithms.clean_js",
        "peekOfCode": "\t\t\ti = 0\n\t\t\tfor a_char in a_line:\n\t\t\t\tif a_char.isdigit():\n\t\t\t\t\tbreak\n\t\t\t\ti += 1\n\t\t\t\t#print(i)\n\t\t\tprint \" \".join(a_line[i+1:])\n\t\t\tw_f.write(\" \".join(a_line[i+1:]) + \"\\n\")",
        "detail": "_REPO.APRESS.js-data-structures-and-algorithms.clean_js",
        "documentation": {}
    },
    {
        "label": "gen_data",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.bin_packing",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.bin_packing",
        "peekOfCode": "def gen_data(n):\n    R, T = [], 0\n    for i in range(n):\n        RR = [randint(6, 10), randint(200, 500)]\n        T += RR[0] * RR[1]\n        R.append(RR)\n    return R, randint(1200, 1500)\nfrom my_or_tools import newSolver, ObjVal, SolVal\ndef solve_model(D, W, symmetry_break=False, knapsack=True):\n    s = newSolver(\"Bin Packing\", True)",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.bin_packing",
        "documentation": {}
    },
    {
        "label": "solve_model",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.bin_packing",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.bin_packing",
        "peekOfCode": "def solve_model(D, W, symmetry_break=False, knapsack=True):\n    s = newSolver(\"Bin Packing\", True)\n    nbC, nbP = len(D), sum([P[0] for P in D])\n    w = [e for sub in [[d[1]] * d[0] for d in D] for e in sub]\n    nbT, nbTmin = bound_trucks(w, W)\n    x = [[[s.IntVar(0, 1, \"\") for _ in range(nbT)] for _ in range(d[0])] for d in D]\n    y = [s.IntVar(0, 1, \"\") for _ in range(nbT)]\n    for k in range(nbT):\n        sxk = sum(D[i][1] * x[i][j][k] for i in range(nbC) for j in range(D[i][0]))\n        s.Add(sxk <= W * y[k])",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.bin_packing",
        "documentation": {}
    },
    {
        "label": "bound_trucks",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.bin_packing",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.bin_packing",
        "peekOfCode": "def bound_trucks(w, W):\n    nb, tot = 1, 0\n    for i in range(len(w)):\n        if tot + w[i] < W:\n            tot += w[i]\n        else:\n            tot = w[i]\n            nb = nb + 1\n    return nb, ceil(sum(w) / W)",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.bin_packing",
        "documentation": {}
    },
    {
        "label": "gen_data_content",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.blend_multi",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.blend_multi",
        "peekOfCode": "def gen_data_content(m, n):\n    # Oils down, acids accross (more oils than acids  m > n)\n    R = []\n    for i in range(m):\n        RR = []\n        P = 100\n        for j in range(n - 1):\n            if P > 1:\n                acid = randint(1, min(70, P)) * randint(0, 1)\n            else:",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.blend_multi",
        "documentation": {}
    },
    {
        "label": "gen_data_target",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.blend_multi",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.blend_multi",
        "peekOfCode": "def gen_data_target(C):\n    F = []\n    R0, R1 = [], []\n    m, n = len(C), len(C[0])\n    P = 100\n    R = [0 for j in range(n)]\n    for i in range(m - 1):\n        if P:\n            f = randint(1, min(20, P))\n        else:",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.blend_multi",
        "documentation": {}
    },
    {
        "label": "gen_data_cost",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.blend_multi",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.blend_multi",
        "peekOfCode": "def gen_data_cost(m, k):\n    # Oils down, months accross\n    R = []\n    for i in range(m):\n        RR = []\n        for j in range(k):\n            cost = randint(100, 200)\n            RR.append(cost)\n        R.append(RR)\n    return R",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.blend_multi",
        "documentation": {}
    },
    {
        "label": "gen_data_inventory",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.blend_multi",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.blend_multi",
        "peekOfCode": "def gen_data_inventory(m):\n    # Oils down\n    R = []\n    for i in range(m):\n        cost = [randint(0, 200)]\n        R.append(cost)\n    return R\nfrom my_or_tools import SolVal, ObjVal, newSolver\ndef solve_model(Part, Target, Cost, Inventory, D, SC, SL):\n    s = newSolver(\"Multi-period soap blending problem\")",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.blend_multi",
        "documentation": {}
    },
    {
        "label": "solve_model",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.blend_multi",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.blend_multi",
        "peekOfCode": "def solve_model(Part, Target, Cost, Inventory, D, SC, SL):\n    s = newSolver(\"Multi-period soap blending problem\")\n    Oils = range(len(Part))\n    Periods, Acids = range(len(Cost[0])), range(len(Part[0]))\n    Buy = [[s.NumVar(0, D, \"\") for _ in Periods] for _ in Oils]\n    Blnd = [[s.NumVar(0, D, \"\") for _ in Periods] for _ in Oils]\n    Hold = [[s.NumVar(0, D, \"\") for _ in Periods] for _ in Oils]\n    Prod = [s.NumVar(0, D, \"\") for _ in Periods]\n    CostP = [s.NumVar(0, D * 1000, \"\") for _ in Periods]\n    CostS = [s.NumVar(0, D * 1000, \"\") for _ in Periods]",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.blend_multi",
        "documentation": {}
    },
    {
        "label": "solve_coexistence",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.coexistence",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.coexistence",
        "peekOfCode": "def solve_coexistence():\n    t = \"Amphibian coexistence\"\n    s = pywraplp.Solver(t, pywraplp.Solver.GLOP_LINEAR_PROGRAMMING)\n    x = [s.NumVar(0, 1000, \"x[%i]\" % i) for i in range(3)]\n    pop = s.NumVar(0, 3000, \"pop\")\n    s.Add(2 * x[0] + x[1] + x[2] <= 1500)\n    s.Add(x[0] + 3 * x[1] + 2 * x[2] <= 3000)\n    s.Add(x[0] + 2 * x[1] + 3 * x[2] <= 4000)\n    s.Add(pop == x[0] + x[1] + x[2])\n    s.Maximize(pop)",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.coexistence",
        "documentation": {}
    },
    {
        "label": "gen_data",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.curve_fit",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.curve_fit",
        "peekOfCode": "def gen_data(myfunc, n):\n    R = []\n    for i in range(n):\n        RR = []\n        t = i + uniform(-0.2, 0.2)\n        RR.append(t)\n        RR.append(myfunc(t) * uniform(0.8, 1.2))\n        R.append(RR)\n    return R\nfrom my_or_tools import ObjVal, SolVal, newSolver",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.curve_fit",
        "documentation": {}
    },
    {
        "label": "solve_model",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.curve_fit",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.curve_fit",
        "peekOfCode": "def solve_model(D, deg=1, objective=0):\n    s, n = newSolver(\"Polynomial fitting\"), len(D)\n    b = s.infinity()\n    a = [s.NumVar(-b, b, \"a[%i]\" % i) for i in range(1 + deg)]\n    u = [s.NumVar(0, b, \"u[%i]\" % i) for i in range(n)]\n    v = [s.NumVar(0, b, \"v[%i]\" % i) for i in range(n)]\n    e = s.NumVar(0, b, \"e\")\n    for i in range(n):\n        s.Add(D[i][1] == u[i] - v[i] + sum(a[j] * D[i][0] ** j for j in range(1 + deg)))\n    for i in range(n):",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.curve_fit",
        "documentation": {}
    },
    {
        "label": "gen_data",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.cutting_stock",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.cutting_stock",
        "peekOfCode": "def gen_data(n):\n    R = []\n    S = 0\n    for i in range(n):\n        R.append([randint(1, 12), randint(5, 40)])\n    return R\nfrom my_or_tools import ObjVal, SolVal, newSolver\ndef solve_model(D):\n    s, n = newSolver(\"Cutting Stock\", True), len(D)\n    k, b = bounds(D)",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.cutting_stock",
        "documentation": {}
    },
    {
        "label": "solve_model",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.cutting_stock",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.cutting_stock",
        "peekOfCode": "def solve_model(D):\n    s, n = newSolver(\"Cutting Stock\", True), len(D)\n    k, b = bounds(D)\n    y = [s.IntVar(0, 1, \"\") for i in range(k[1])]\n    x = [[s.IntVar(0, b[i], \"\") for j in range(k[1])] for i in range(n)]\n    w = [s.NumVar(0, 100, \"\") for j in range(k[1])]\n    nb = s.IntVar(k[0], k[1], \"\")\n    for i in range(n):\n        s.Add(sum(x[i][j] for j in range(k[1])) >= D[i][0])\n    for j in range(k[1]):",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.cutting_stock",
        "documentation": {}
    },
    {
        "label": "bounds",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.cutting_stock",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.cutting_stock",
        "peekOfCode": "def bounds(D):\n    n, b, T, k, TT = len(D), [], 0, [0, 1], 0\n    for i in range(n):\n        q, w = D[i][0], D[i][1]\n        b.append(min(D[i][0], int(round(100 / D[i][1]))))\n        if T + q * w <= 100:\n            T, TT = T + q * w, TT + q * w\n        else:\n            while q:\n                if T + w <= 100:",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.cutting_stock",
        "documentation": {}
    },
    {
        "label": "rolls",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.cutting_stock",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.cutting_stock",
        "peekOfCode": "def rolls(nb, x, w, D):\n    R, n = [], len(x)\n    for j in range(len(x[0])):\n        RR = [abs(w[j])] + [int(x[i][j]) * [D[i][1]] for i in range(n) if x[i][j] > 0]\n        R.append(RR)\n    return R\nfrom my_or_tools import ObjVal, SolVal, newSolver\nfrom math import ceil\ndef solve_large_model(D):\n    n, iter = len(D), 0",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.cutting_stock",
        "documentation": {}
    },
    {
        "label": "solve_large_model",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.cutting_stock",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.cutting_stock",
        "peekOfCode": "def solve_large_model(D):\n    n, iter = len(D), 0\n    A = get_initial_patterns(D)\n    while iter < 20:\n        rc, y, l = solve_master(A, [D[i][0] for i in range(n)])\n        iter = iter + 1\n        a, v = get_new_pattern(l, [D[i][1] for i in range(n)])\n        for i in range(n):\n            A[i].append(a[i])\n    rc, y, l = solve_master(A, [D[i][0] for i in range(n)], True)",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.cutting_stock",
        "documentation": {}
    },
    {
        "label": "solve_master",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.cutting_stock",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.cutting_stock",
        "peekOfCode": "def solve_master(C, b, integer=False):\n    t = \"Cutting stock master problem\"\n    m, n, u = len(C), len(C[0]), []\n    s = newSolver(t, integer)\n    y = [s.IntVar(0, 1000, \"\") for j in range(n)]  # right bound?\n    Cost = sum(y[j] for j in range(n))\n    s.Minimize(Cost)\n    for i in range(m):\n        u.append(s.Add(sum(C[i][j] * y[j] for j in range(n)) >= b[i]))\n    rc = s.Solve()",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.cutting_stock",
        "documentation": {}
    },
    {
        "label": "get_new_pattern",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.cutting_stock",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.cutting_stock",
        "peekOfCode": "def get_new_pattern(l, w):\n    s = newSolver(\"Cutting stock slave\", True)\n    n = len(l)\n    a = [s.IntVar(0, 100, \"\") for i in range(n)]\n    Cost = sum(l[i] * a[i] for i in range(n))\n    s.Maximize(Cost)\n    s.Add(sum(w[i] * a[i] for i in range(n)) <= 100)\n    rc = s.Solve()\n    return SolVal(a), ObjVal(s)\ndef get_initial_patterns(D):",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.cutting_stock",
        "documentation": {}
    },
    {
        "label": "get_initial_patterns",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.cutting_stock",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.cutting_stock",
        "peekOfCode": "def get_initial_patterns(D):\n    n = len(D)\n    return [[0 if j != i else 1 for j in range(n)] for i in range(n)]\ndef rolls_patterns(C, y, D):\n    R, m, n = [], len(C), len(y)\n    for j in range(n):\n        for _ in range(y[j]):\n            RR = []\n            for i in range(m):\n                if C[i][j] > 0:",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.cutting_stock",
        "documentation": {}
    },
    {
        "label": "rolls_patterns",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.cutting_stock",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.cutting_stock",
        "peekOfCode": "def rolls_patterns(C, y, D):\n    R, m, n = [], len(C), len(y)\n    for j in range(n):\n        for _ in range(y[j]):\n            RR = []\n            for i in range(m):\n                if C[i][j] > 0:\n                    RR.extend([D[i][1]] * int(C[i][j]))\n            w = sum(RR)\n            R.append([100 - w, RR])",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.cutting_stock",
        "documentation": {}
    },
    {
        "label": "gen_diet_problem",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.diet_problem",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.diet_problem",
        "peekOfCode": "def gen_diet_problem(nb_foods=5, nb_nutrients=4):\n    from random import randint, uniform\n    data = []\n    ranges = [10 ** randint(2, 4) for i in range(nb_nutrients)]\n    x = [randint(15, 25) for i in range(nb_foods)]  # this must be feasible\n    MinNutrient = [0] * nb_nutrients\n    MaxNutrient = [0] * nb_nutrients\n    for food in range(nb_foods):\n        nutrients = [randint(10, ranges[i]) for i in range(nb_nutrients)]\n        minmax = [randint(0, x[food]), randint(x[food], 2 * x[food])]",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.diet_problem",
        "documentation": {}
    },
    {
        "label": "solve_diet",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.diet_problem",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.diet_problem",
        "peekOfCode": "def solve_diet(N):\n    s = newSolver(\"Diet\")\n    nbF, nbN = len(N) - 2, len(N[0]) - 3\n    FMin, FMax, FCost, NMin, NMax = nbN, nbN + 1, nbN + 2, nbF, nbF + 1\n    f = [s.NumVar(N[i][FMin], N[i][FMax], \"\") for i in range(nbF)]\n    for j in range(nbN):\n        s.Add(N[NMin][j] <= s.Sum([f[i] * N[i][j] for i in range(nbF)]))\n        s.Add(s.Sum([f[i] * N[i][j] for i in range(nbF)]) <= N[NMax][j])\n    s.Minimize(s.Sum([f[i] * N[i][FCost] for i in range(nbF)]))\n    rc = s.Solve()",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.diet_problem",
        "documentation": {}
    },
    {
        "label": "gen_dcost",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.facility_location",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.facility_location",
        "peekOfCode": "def gen_dcost(m, n):\n    R = []\n    S = 0\n    for i in range(m):\n        RR = []\n        for j in range(n):\n            RR.append(randint(10, 30))\n        RR.append(randint(500, 700))\n        R.append(RR)\n        S += RR[-1]",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.facility_location",
        "documentation": {}
    },
    {
        "label": "gen_fcost",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.facility_location",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.facility_location",
        "peekOfCode": "def gen_fcost(m):\n    return [randint(4200, 6500) for i in range(m)]\nfrom my_or_tools import ObjVal, SolVal, newSolver\ndef solve_model(D, F):\n    s = newSolver(\"Facility location problem\", True)\n    m, n = len(D) - 1, len(D[0]) - 1\n    B = sum(D[-1][j] * max(D[i][j] for i in range(m)) for j in range(n))\n    x = [[s.NumVar(0, D[i][-1], \"\") for j in range(n)] for i in range(m)]\n    y = [s.IntVar(0, 1, \"\") for i in range(m)]\n    Fcost, Dcost = s.NumVar(0, B, \"\"), s.NumVar(0, B, \"\")",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.facility_location",
        "documentation": {}
    },
    {
        "label": "solve_model",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.facility_location",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.facility_location",
        "peekOfCode": "def solve_model(D, F):\n    s = newSolver(\"Facility location problem\", True)\n    m, n = len(D) - 1, len(D[0]) - 1\n    B = sum(D[-1][j] * max(D[i][j] for i in range(m)) for j in range(n))\n    x = [[s.NumVar(0, D[i][-1], \"\") for j in range(n)] for i in range(m)]\n    y = [s.IntVar(0, 1, \"\") for i in range(m)]\n    Fcost, Dcost = s.NumVar(0, B, \"\"), s.NumVar(0, B, \"\")\n    for i in range(m):\n        s.Add(D[i][-1] * y[i] >= sum(x[i][j] for j in range(n)))\n    for j in range(n):",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.facility_location",
        "documentation": {}
    },
    {
        "label": "inner",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.features",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.features",
        "peekOfCode": "def inner(a, b):\n    s = 0\n    for i in range(len(a)):\n        s += a[i] * b[i]\n    return s\ndef gen_features(n, m):\n    # Generating n vectors of m features linearly separable\n    a = gen_hyperplane(m)\n    A, B, i = [], [], 0\n    while len(A) < n:",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.features",
        "documentation": {}
    },
    {
        "label": "gen_features",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.features",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.features",
        "peekOfCode": "def gen_features(n, m):\n    # Generating n vectors of m features linearly separable\n    a = gen_hyperplane(m)\n    A, B, i = [], [], 0\n    while len(A) < n:\n        x = [randint(-10, 10) for _ in range(m)]\n        if inner(a[0:m], x) < a[m] - 1:\n            A.append(x)\n    while len(B) < n:\n        x = [randint(-10, 10) for _ in range(m)]",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.features",
        "documentation": {}
    },
    {
        "label": "gen_hyperplane",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.features",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.features",
        "peekOfCode": "def gen_hyperplane(m):\n    return [randint(-10, 10) for _ in range(m + 1)]\nfrom my_or_tools import SolVal, ObjVal, newSolver\ndef solve_classification(A, B):\n    n, ma, mb = len(A[0]), len(A), len(B)\n    s = newSolver(\"Classification\")\n    ya = [s.NumVar(0, 99, \"\") for _ in range(ma)]\n    yb = [s.NumVar(0, 99, \"\") for _ in range(mb)]\n    a = [s.NumVar(-99, 99, \"\") for _ in range(n + 1)]\n    for i in range(ma):",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.features",
        "documentation": {}
    },
    {
        "label": "solve_classification",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.features",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.features",
        "peekOfCode": "def solve_classification(A, B):\n    n, ma, mb = len(A[0]), len(A), len(B)\n    s = newSolver(\"Classification\")\n    ya = [s.NumVar(0, 99, \"\") for _ in range(ma)]\n    yb = [s.NumVar(0, 99, \"\") for _ in range(mb)]\n    a = [s.NumVar(-99, 99, \"\") for _ in range(n + 1)]\n    for i in range(ma):\n        s.Add(ya[i] >= a[n] + 1 - s.Sum(a[j] * A[i][j] for j in range(n)))\n    for i in range(mb):\n        s.Add(yb[i] >= s.Sum(a[j] * B[i][j] for j in range(n)) - a[n] + 1)",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.features",
        "documentation": {}
    },
    {
        "label": "gen_raw",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.gas_blend",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.gas_blend",
        "peekOfCode": "def gen_raw(n):\n    R = []\n    for i in range(n):\n        R.append([randint(80, 99), randint(600, 1000), 0])\n    avgr = sum([R[i][0] for i in range(n)]) / float(n)\n    for i in range(n):\n        p = randint(50, 55) + 4 * R[i][0] / avgr\n        R[i][2] = round(p, 2)\n    return R\nfrom random import randint",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.gas_blend",
        "documentation": {}
    },
    {
        "label": "gen_refined",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.gas_blend",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.gas_blend",
        "peekOfCode": "def gen_refined(n):\n    R = []\n    for i in range(n):\n        R.append([randint(82, 96), randint(100, 500), randint(600, 20000), 0])\n    avgr = sum([R[i][0] for i in range(n)]) / float(n)\n    for i in range(n):\n        p = 61.0 + R[i][0] / avgr\n        R[i][3] = round(p, 2)\n    return R\nfrom my_or_tools import SolVal, ObjVal, newSolver",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.gas_blend",
        "documentation": {}
    },
    {
        "label": "solve_gas",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.gas_blend",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.gas_blend",
        "peekOfCode": "def solve_gas(C, D):\n    s = newSolver(\"Gas blending problem\")\n    nR, nF = len(C), len(D)\n    Roc, Rmax, Rcost = 0, 1, 2\n    Foc, Fmin, Fmax, Fprice = 0, 1, 2, 3\n    G = [[s.NumVar(0.0, 10000, \"\") for j in range(nF)] for i in range(nR)]\n    R = [s.NumVar(0, C[i][Rmax], \"\") for i in range(nR)]\n    F = [s.NumVar(D[j][Fmin], D[j][Fmax], \"\") for j in range(nF)]\n    for i in range(nR):\n        s.Add(R[i] == sum(G[i][j] for j in range(nF)))",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.gas_blend",
        "documentation": {}
    },
    {
        "label": "gen_diet_problem",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.gen_diet_problem",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.gen_diet_problem",
        "peekOfCode": "def gen_diet_problem(nb_foods=5, nb_nutrients=3):\n    from random import randint, uniform\n    data = []\n    ranges = [10 ** randint(1, 4) for i in range(nb_nutrients)]\n    MinMax = [0] * nb_nutrients\n    for food in range(nb_foods):\n        nutrients = [round(randint(1, ranges[i])) for i in range(nb_nutrients)]\n        for i in range(len(nutrients)):\n            MinMax[i] += nutrients[i]\n        minmax = [randint(0, 3), randint(3, 10)]",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.gen_diet_problem",
        "documentation": {}
    },
    {
        "label": "gen_data",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.job_shop",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.job_shop",
        "peekOfCode": "def gen_data(m, n):\n    # m is number of jobs, n is the number of machines\n    R = []\n    for j in range(m):\n        p = list(range(n))\n        p = sample(p, len(p))\n        RR = []\n        for i in range(n):\n            RR.append((p[i], randint(5, 10)))\n        R.append(RR)",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.job_shop",
        "documentation": {}
    },
    {
        "label": "solve_model",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.job_shop",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.job_shop",
        "peekOfCode": "def solve_model(D):\n    s = newSolver(\"Job Shop Scheduling\", True)\n    nJ, nM = len(D), len(D[0])\n    M = sum([D[i][k][1] for i in range(nJ) for k in range(nM)])\n    x = [[s.NumVar(0, M, \"\") for k in range(nM)] for i in range(nJ)]\n    p = [[D[i][k][0] for k in range(nM)] for i in range(nJ)]\n    d = [[D[i][k][1] for k in range(nM)] for i in range(nJ)]\n    z = [\n        [[s.IntVar(0, 1, \"\") for k in range(nM)] for j in range(nJ)] for i in range(nJ)\n    ]",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.job_shop",
        "documentation": {}
    },
    {
        "label": "solve_margins_classification",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.margins",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.margins",
        "peekOfCode": "def solve_margins_classification(A, B):\n    n, ma, mb = len(A[0]), len(A), len(B)\n    s = newSolver(\"Classification\")\n    ua = [s.NumVar(0, 99, \"\") for _ in range(ma)]\n    la = [s.NumVar(0, 99, \"\") for _ in range(ma)]\n    ub = [s.NumVar(0, 99, \"\") for _ in range(mb)]\n    lb = [s.NumVar(0, 99, \"\") for _ in range(mb)]\n    a = [s.NumVar(-99, 99, \"\") for _ in range(n + 1)]\n    e = s.NumVar(-99, 99, \"\")\n    for i in range(ma):",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.margins",
        "documentation": {}
    },
    {
        "label": "gen_data",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.maxflow",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.maxflow",
        "peekOfCode": "def gen_data(n):\n    R, S, T = [], [], []\n    for i in range(n):\n        RR = []\n        if i == 0:  # 0 is always a source\n            S.append(i)\n        elif i == n - 1:  # last is always a sink\n            T.append(i)\n        elif randint(0, 4) == 0:\n            S.append(i)",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.maxflow",
        "documentation": {}
    },
    {
        "label": "solve_model",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.maxflow",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.maxflow",
        "peekOfCode": "def solve_model(C, S, T, unique=True):\n    s, n = newSolver(\"Maximum flow problem\"), len(C)\n    x = [[s.NumVar(0, C[i][j], \"\") for j in range(n)] for i in range(n)]\n    B = sum(C[i][j] for i in range(n) for j in range(n))\n    Flowout, Flowin = s.NumVar(0, B, \"\"), s.NumVar(0, B, \"\")\n    for i in range(n):\n        if i not in S and i not in T:\n            s.Add(sum(x[i][j] for j in range(n)) == sum(x[j][i] for j in range(n)))\n    s.Add(Flowout == s.Sum(x[i][j] for i in S for j in range(n)))\n    s.Add(Flowin == s.Sum(x[j][i] for i in S for j in range(n)))",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.maxflow",
        "documentation": {}
    },
    {
        "label": "gen_data",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.mincost",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.mincost",
        "peekOfCode": "def gen_data(m, n):\n    R = []\n    S = 0\n    for i in range(m):\n        RR = []\n        for j in range(n):\n            yesno = 1 - randint(0, 1) * randint(0, 1)\n            RR.append(randint(10, 30) * yesno)\n        RR.append(randint(500, 700))\n        R.append(RR)",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.mincost",
        "documentation": {}
    },
    {
        "label": "solve_model",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.mincost",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.mincost",
        "peekOfCode": "def solve_model(D):\n    s = newSolver(\"Mincost flow problem\")\n    m, n = len(D) - 1, len(D[0]) - 1\n    B = sum([D[-1][j] for j in range(n)])\n    G = [[s.NumVar(0, B if D[i][j] else 0, \"\") for j in range(n)] for i in range(m)]\n    for i in range(m):\n        s.Add(D[i][-1] >= sum(G[i][j] for j in range(n)))\n    for j in range(n):\n        s.Add(D[-1][j] == sum(G[i][j] for i in range(m)))\n    Cost = s.Sum(G[i][j] * D[i][j] for i in range(m) for j in range(n))",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.mincost",
        "documentation": {}
    },
    {
        "label": "gen_data",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.multi_commodity_flow",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.multi_commodity_flow",
        "peekOfCode": "def gen_data(n, K):\n    C = [transship_dist.gen_data(n, False) for _ in range(K)]\n    X = [[0 for _ in range(n)] for _ in range(n)]\n    for k in range(K):\n        rc, Val, x = transship_dist.solve_model(C[k])\n        if rc == 0:\n            for i in range(n):\n                for j in range(n):\n                    X[i][j] += x[i][j]\n    Cap = max([e for row in X for e in row])",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.multi_commodity_flow",
        "documentation": {}
    },
    {
        "label": "solve_model",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.multi_commodity_flow",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.multi_commodity_flow",
        "peekOfCode": "def solve_model(C, D=None, Z=False):\n    s = newSolver(\"Multi-commodity mincost flow problem\", Z)\n    K, n = (len(C), len(C[0]) - 1)\n    B = [sum(C[k][-1][j] for j in range(n)) for k in range(K)]\n    x = [\n        [\n            [\n                s.IntVar(0, B[k] if C[k][i][j] else 0, \"\")\n                if Z\n                else s.NumVar(0, B[k] if C[k][i][j] else 0, \"\")",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.multi_commodity_flow",
        "documentation": {}
    },
    {
        "label": "solve_all_pairs",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.multi_commodity_flow",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.multi_commodity_flow",
        "peekOfCode": "def solve_all_pairs(D, sources=None):\n    n, C = len(D), []\n    if sources is None:\n        sources = [i for i in range(n)]\n    for node in sources:\n        C0 = [\n            [0 if n in [i, j] else D[i][j] for j in range(n + 1)] for i in range(n + 1)\n        ]\n        C0[node][-1] = n - 1\n        for j in range(n):",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.multi_commodity_flow",
        "documentation": {}
    },
    {
        "label": "newSolver",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.my_or_tools",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.my_or_tools",
        "peekOfCode": "def newSolver(name, integer=False):\n    return pywraplp.Solver(\n        name,\n        pywraplp.Solver.CBC_MIXED_INTEGER_PROGRAMMING\n        if integer\n        else pywraplp.Solver.GLOP_LINEAR_PROGRAMMING,\n    )\ndef SolVal(x):\n    if type(x) is not list:\n        return (",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.my_or_tools",
        "documentation": {}
    },
    {
        "label": "SolVal",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.my_or_tools",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.my_or_tools",
        "peekOfCode": "def SolVal(x):\n    if type(x) is not list:\n        return (\n            0\n            if x is None\n            else x\n            if isinstance(x, (int, float))\n            else x.SolutionValue()\n            if x.Integer() is False\n            else int(x.SolutionValue())",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.my_or_tools",
        "documentation": {}
    },
    {
        "label": "ObjVal",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.my_or_tools",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.my_or_tools",
        "peekOfCode": "def ObjVal(x):\n    return x.Objective().Value()\ndef pairs(tuple, accum=[]):\n    if len(tuple) == 0:\n        return accum\n    else:\n        accum.extend((tuple[0], e) for e in tuple[1:])\n        return pairs(tuple[1:], accum)\nfrom my_or_tools import ObjVal, SolVal, newSolver\ndef k_out_of_n(solver, k, x, rel=\"==\"):",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.my_or_tools",
        "documentation": {}
    },
    {
        "label": "pairs",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.my_or_tools",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.my_or_tools",
        "peekOfCode": "def pairs(tuple, accum=[]):\n    if len(tuple) == 0:\n        return accum\n    else:\n        accum.extend((tuple[0], e) for e in tuple[1:])\n        return pairs(tuple[1:], accum)\nfrom my_or_tools import ObjVal, SolVal, newSolver\ndef k_out_of_n(solver, k, x, rel=\"==\"):\n    n = len(x)\n    binary = (",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.my_or_tools",
        "documentation": {}
    },
    {
        "label": "k_out_of_n",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.my_or_tools",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.my_or_tools",
        "peekOfCode": "def k_out_of_n(solver, k, x, rel=\"==\"):\n    n = len(x)\n    binary = (\n        sum(x[i].Lb() == 0 for i in range(n)) == n\n        and sum(x[i].Ub() == 1 for i in range(n)) == n\n    )\n    if binary:\n        l = x\n    else:\n        l = [solver.IntVar(0, 1, \"\") for i in range(n)]",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.my_or_tools",
        "documentation": {}
    },
    {
        "label": "sosn",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.my_or_tools",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.my_or_tools",
        "peekOfCode": "def sosn(solver, k, x, rel=\"<=\"):\n    def sosnrecur(solver, k, l):\n        n = len(l)\n        d = [solver.IntVar(0, 1, \"\") for _ in range(n - 1)]\n        for i in range(n):\n            solver.Add(\n                l[i] <= sum(d[j] for j in range(max(0, i - 1), min(n - 2, i + 1)))\n            )\n        solver.Add(k == sum(d[i] for i in range(n - 1)))\n        return d if k <= 1 else [d, sosnrecur(solver, k - 1, d)]",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.my_or_tools",
        "documentation": {}
    },
    {
        "label": "bounds_on_box",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.my_or_tools",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.my_or_tools",
        "peekOfCode": "def bounds_on_box(a, x, b):\n    Bounds, n = [None, None], len(a)\n    s = pywraplp.Solver(\"Box\", pywraplp.Solver.GLOP_LINEAR_PROGRAMMING)\n    xx = [s.NumVar(x[i].Lb(), x[i].Ub(), \"\") for i in range(n)]\n    S = s.Sum([-b] + [a[i] * xx[i] for i in range(n)])\n    s.Maximize(S)\n    rc = s.Solve()\n    Bounds[1] = None if rc != 0 else ObjVal(s)\n    s.Minimize(S)\n    s.Solve()",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.my_or_tools",
        "documentation": {}
    },
    {
        "label": "reify_force",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.my_or_tools",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.my_or_tools",
        "peekOfCode": "def reify_force(s, a, x, b, delta=None, rel=\"<=\", bnds=None):\n    # delta == 1 ---> a*x <= b\n    n = len(a)\n    if delta is None:\n        delta = s.IntVar(0, 1, \"\")\n    if bnds is None:\n        bnds = bounds_on_box(a, x, b)\n    if rel in [\"<=\", \"==\"]:\n        s.Add(sum(a[i] * x[i] for i in range(n)) <= b + bnds[1] * (1 - delta))\n    if rel in [\">=\", \"==\"]:",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.my_or_tools",
        "documentation": {}
    },
    {
        "label": "reify_raise",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.my_or_tools",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.my_or_tools",
        "peekOfCode": "def reify_raise(s, a, x, b, delta=None, rel=\"<=\", bnds=None, eps=1):\n    # a*x <= b ---> delta == 1\n    n = len(a)\n    if delta is None:\n        delta = s.IntVar(0, 1, \"\")\n    if bnds is None:\n        bnds = bounds_on_box(a, x, b)\n    if rel == \"<=\":\n        s.Add(\n            sum(a[i] * x[i] for i in range(n))",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.my_or_tools",
        "documentation": {}
    },
    {
        "label": "reify",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.my_or_tools",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.my_or_tools",
        "peekOfCode": "def reify(s, a, x, b, d=None, rel=\"<=\", bs=None, eps=1):\n    # d == 1 <---> a*x <= b\n    return reify_raise(s, a, x, b, reify_force(s, a, x, b, d, rel, bs), rel, bs, eps)\ndef maximax(s, a, x, b):\n    n = len(a)\n    d = [bounds_on_box(a[i], x, b[i]) for i in range(n)]\n    zbound = [min(d[i][0] for i in range(n)), max(d[i][1] for i in range(n))]\n    z = s.NumVar(zbound[0], zbound[1], \"\")\n    delta = [reify(s, a[i] + [-1], x + [z], b[i], None, \"==\") for i in range(n)]\n    k_out_of_n(s, 1, delta)",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.my_or_tools",
        "documentation": {}
    },
    {
        "label": "maximax",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.my_or_tools",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.my_or_tools",
        "peekOfCode": "def maximax(s, a, x, b):\n    n = len(a)\n    d = [bounds_on_box(a[i], x, b[i]) for i in range(n)]\n    zbound = [min(d[i][0] for i in range(n)), max(d[i][1] for i in range(n))]\n    z = s.NumVar(zbound[0], zbound[1], \"\")\n    delta = [reify(s, a[i] + [-1], x + [z], b[i], None, \"==\") for i in range(n)]\n    k_out_of_n(s, 1, delta)\n    s.Maximize(z)\n    return z, delta",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.my_or_tools",
        "documentation": {}
    },
    {
        "label": "newSolver",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.my_or_tools_a",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.my_or_tools_a",
        "peekOfCode": "def newSolver(name, integer=False):\n    return pywraplp.Solver(\n        name,\n        pywraplp.Solver.CBC_MIXED_INTEGER_PROGRAMMING\n        if integer\n        else pywraplp.Solver.GLOP_LINEAR_PROGRAMMING,\n    )\ndef SolVal(x):\n    if type(x) is not list:\n        return (",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.my_or_tools_a",
        "documentation": {}
    },
    {
        "label": "SolVal",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.my_or_tools_a",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.my_or_tools_a",
        "peekOfCode": "def SolVal(x):\n    if type(x) is not list:\n        return (\n            0\n            if x is None\n            else x\n            if isinstance(x, (int, float))\n            else x.SolutionValue()\n            if x.Integer() is False\n            else int(x.SolutionValue())",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.my_or_tools_a",
        "documentation": {}
    },
    {
        "label": "ObjVal",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.my_or_tools_a",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.my_or_tools_a",
        "peekOfCode": "def ObjVal(x):\n    return x.Objective().Value()",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.my_or_tools_a",
        "documentation": {}
    },
    {
        "label": "k_out_of_n",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.my_or_tools_c",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.my_or_tools_c",
        "peekOfCode": "def k_out_of_n(solver, k, x, rel=\"==\"):\n    n = len(x)\n    binary = (\n        sum(x[i].Lb() == 0 for i in range(n)) == n\n        and sum(x[i].Ub() == 1 for i in range(n)) == n\n    )\n    if binary:\n        l = x\n    else:\n        l = [solver.IntVar(0, 1, \"\") for i in range(n)]",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.my_or_tools_c",
        "documentation": {}
    },
    {
        "label": "sosn",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.my_or_tools_c",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.my_or_tools_c",
        "peekOfCode": "def sosn(solver, k, x, rel=\"<=\"):\n    def sosnrecur(solver, k, l):\n        n = len(l)\n        d = [solver.IntVar(0, 1, \"\") for _ in range(n - 1)]\n        for i in range(n):\n            solver.Add(\n                l[i] <= sum(d[j] for j in range(max(0, i - 1), min(n - 2, i + 1)))\n            )\n        solver.Add(k == sum(d[i] for i in range(n - 1)))\n        return d if k <= 1 else [d, sosnrecur(solver, k - 1, d)]",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.my_or_tools_c",
        "documentation": {}
    },
    {
        "label": "bounds_on_box",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.my_or_tools_c",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.my_or_tools_c",
        "peekOfCode": "def bounds_on_box(a, x, b):\n    Bounds, n = [None, None], len(a)\n    s = pywraplp.Solver(\"Box\", pywraplp.Solver.GLOP_LINEAR_PROGRAMMING)\n    xx = [s.NumVar(x[i].Lb(), x[i].Ub(), \"\") for i in range(n)]\n    S = s.Sum([-b] + [a[i] * xx[i] for i in range(n)])\n    s.Maximize(S)\n    rc = s.Solve()\n    Bounds[1] = None if rc != 0 else ObjVal(s)\n    s.Minimize(S)\n    s.Solve()",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.my_or_tools_c",
        "documentation": {}
    },
    {
        "label": "reify_force",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.my_or_tools_c",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.my_or_tools_c",
        "peekOfCode": "def reify_force(s, a, x, b, delta=None, rel=\"<=\", bnds=None):\n    # delta == 1 ---> a*x <= b\n    n = len(a)\n    if delta is None:\n        delta = s.IntVar(0, 1, \"\")\n    if bnds is None:\n        bnds = bounds_on_box(a, x, b)\n    if rel in [\"<=\", \"==\"]:\n        s.Add(sum(a[i] * x[i] for i in range(n)) <= b + bnds[1] * (1 - delta))\n    if rel in [\">=\", \"==\"]:",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.my_or_tools_c",
        "documentation": {}
    },
    {
        "label": "reify_raise",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.my_or_tools_c",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.my_or_tools_c",
        "peekOfCode": "def reify_raise(s, a, x, b, delta=None, rel=\"<=\", bnds=None, eps=1):\n    # a*x <= b ---> delta == 1\n    n = len(a)\n    if delta is None:\n        delta = s.IntVar(0, 1, \"\")\n    if bnds is None:\n        bnds = bounds_on_box(a, x, b)\n    if rel == \"<=\":\n        s.Add(\n            sum(a[i] * x[i] for i in range(n))",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.my_or_tools_c",
        "documentation": {}
    },
    {
        "label": "reify",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.my_or_tools_c",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.my_or_tools_c",
        "peekOfCode": "def reify(s, a, x, b, d=None, rel=\"<=\", bs=None, eps=1):\n    # d == 1 <---> a*x <= b\n    return reify_raise(s, a, x, b, reify_force(s, a, x, b, d, rel, bs), rel, bs, eps)\ndef maximax(s, a, x, b):\n    n = len(a)\n    d = [bounds_on_box(a[i], x, b[i]) for i in range(n)]\n    zbound = [min(d[i][0] for i in range(n)), max(d[i][1] for i in range(n))]\n    z = s.NumVar(zbound[0], zbound[1], \"\")\n    delta = [reify(s, a[i] + [-1], x + [z], b[i], None, \"==\") for i in range(n)]\n    k_out_of_n(s, 1, delta)",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.my_or_tools_c",
        "documentation": {}
    },
    {
        "label": "maximax",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.my_or_tools_c",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.my_or_tools_c",
        "peekOfCode": "def maximax(s, a, x, b):\n    n = len(a)\n    d = [bounds_on_box(a[i], x, b[i]) for i in range(n)]\n    zbound = [min(d[i][0] for i in range(n)), max(d[i][1] for i in range(n))]\n    z = s.NumVar(zbound[0], zbound[1], \"\")\n    delta = [reify(s, a[i] + [-1], x + [z], b[i], None, \"==\") for i in range(n)]\n    k_out_of_n(s, 1, delta)\n    s.Maximize(z)\n    return z, delta",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.my_or_tools_c",
        "documentation": {}
    },
    {
        "label": "gen_data",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.piecewise",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.piecewise",
        "peekOfCode": "def gen_data(n, convex=True):\n    R = []\n    SQ, SP, TP = 0, 20, 0\n    for i in range(n):\n        Q = randint(100, 200)\n        P = randint(1, 5)\n        if convex:\n            SP1 = SP + P\n        else:\n            SP1 = SP - P",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.piecewise",
        "documentation": {}
    },
    {
        "label": "minimize_piecewise_linear_convex",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.piecewise",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.piecewise",
        "peekOfCode": "def minimize_piecewise_linear_convex(Points, B):\n    s, n = newSolver(\"Piecewise\"), len(Points)\n    x = s.NumVar(Points[0][0], Points[n - 1][0], \"x\")\n    l = [s.NumVar(0.0, 1, \"l[%i]\" % (i,)) for i in range(n)]\n    s.Add(1 == sum(l[i] for i in range(n)))\n    s.Add(x == sum(l[i] * Points[i][0] for i in range(n)))\n    s.Add(x >= B)\n    Cost = s.Sum(l[i] * Points[i][1] for i in range(n))\n    s.Minimize(Cost)\n    s.Solve()",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.piecewise",
        "documentation": {}
    },
    {
        "label": "minimize_non_linear",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.piecewise",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.piecewise",
        "peekOfCode": "def minimize_non_linear(my_function, left, right, precision):\n    n = 5\n    while right - left > precision:\n        dta = (right - left) / (n - 1.0)\n        points = [(left + dta * i, my_function(left + dta * i)) for i in range(n)]\n        G = minimize_piecewise_linear_convex(points, left)\n        x = sum([G[i] * points[i][0] for i in range(n)])\n        left = points[max(0, [i - 1 for i in range(n) if G[i] > 0][0])][0]\n        right = points[min(n - 1, [i + 1 for i in range(n - 1, 0, -1) if G[i] > 0][0])][\n            0",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.piecewise",
        "documentation": {}
    },
    {
        "label": "verbose_minimize_non_linear",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.piecewise",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.piecewise",
        "peekOfCode": "def verbose_minimize_non_linear(my_function, left, right, precision):\n    n, T, iter = 5, [], 0\n    while right - left > precision:\n        delta = (right - left) / (n - 1.0)\n        points = [(left + delta * i, my_function(left + delta * i)) for i in range(n)]\n        T.append([points[i][0] for i in range(n)])\n        T.append([points[i][1] for i in range(n)])\n        G = minimize_piecewise_linear_convex(points, left)\n        x = sum([G[i] * points[i][0] for i in range(n)])\n        y = my_function(x)",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.piecewise",
        "documentation": {}
    },
    {
        "label": "minimize_piecewise_linear",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.piecewise_ncvx",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.piecewise_ncvx",
        "peekOfCode": "def minimize_piecewise_linear(Points, B, convex=True):\n    s, n = newSolver(\"Piecewise\", True), len(Points)\n    x = s.NumVar(Points[0][0], Points[n - 1][0], \"x\")\n    l = [s.NumVar(0, 1, \"l[%i]\" % (i,)) for i in range(n)]\n    s.Add(1 == sum(l[i] for i in range(n)))\n    d = sosn(s, 2, l)\n    s.Add(x == sum(l[i] * Points[i][0] for i in range(n)))\n    s.Add(x >= B)\n    Cost = s.Sum(l[i] * Points[i][1] for i in range(n))\n    s.Minimize(Cost)",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.piecewise_ncvx",
        "documentation": {}
    },
    {
        "label": "gen_data",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.project_management",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.project_management",
        "peekOfCode": "def gen_data(n):\n    R = []\n    S = 0\n    for i in range(n):\n        RR = [i]  # Task number\n        RR.append(randint(2, 8))  # Duration\n        P = []\n        for j in range(i):\n            if randint(0, 1) * randint(0, 1):\n                P.append(j)",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.project_management",
        "documentation": {}
    },
    {
        "label": "solve_model",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.project_management",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.project_management",
        "peekOfCode": "def solve_model(D):\n    s = newSolver(\"Project management\")\n    n = len(D)\n    max = sum(D[i][1] for i in range(n))\n    t = [s.NumVar(0, max, \"t[%i]\" % i) for i in range(n)]\n    Total = s.NumVar(0, max, \"Total\")\n    for i in range(n):\n        s.Add(t[i] + D[i][1] <= Total)\n        for j in D[i][2]:\n            s.Add(t[j] + D[j][1] <= t[i])",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.project_management",
        "documentation": {}
    },
    {
        "label": "solve_model_clp",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.project_management",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.project_management",
        "peekOfCode": "def solve_model_clp(D):\n    t = \"Project management\"\n    s = pywraplp.Solver(t, pywraplp.Solver.CLP_LINEAR_PROGRAMMING)\n    n = len(D)\n    max = sum(D[i][1] for i in range(n))\n    t = [s.NumVar(0, max, \"t[%i]\" % i) for i in range(n)]\n    Total = s.NumVar(0, max, \"Total\")\n    for i in range(n):\n        s.Add(t[i] + D[i][1] <= Total)\n        for j in D[i][2]:",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.project_management",
        "documentation": {}
    },
    {
        "label": "get_row",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.puzzle",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.puzzle",
        "peekOfCode": "def get_row(x, i):\n    return [x[i][j] for j in range(len(x[0]))]\ndef get_column(x, i):\n    return [x[j][i] for j in range(len(x[0]))]\ndef solve_maxrook(n):\n    s = newSolver(\"Maxrook\", True)\n    x = [[s.IntVar(0, 1, \"\") for _ in range(n)] for _ in range(n)]\n    for i in range(n):\n        k_out_of_n(s, 1, get_row(x, i), \"<=\")\n        k_out_of_n(s, 1, get_column(x, i), \"<=\")",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.puzzle",
        "documentation": {}
    },
    {
        "label": "get_column",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.puzzle",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.puzzle",
        "peekOfCode": "def get_column(x, i):\n    return [x[j][i] for j in range(len(x[0]))]\ndef solve_maxrook(n):\n    s = newSolver(\"Maxrook\", True)\n    x = [[s.IntVar(0, 1, \"\") for _ in range(n)] for _ in range(n)]\n    for i in range(n):\n        k_out_of_n(s, 1, get_row(x, i), \"<=\")\n        k_out_of_n(s, 1, get_column(x, i), \"<=\")\n    Count = s.Sum(x[i][j] for i in range(n) for j in range(n))\n    s.Maximize(Count)",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.puzzle",
        "documentation": {}
    },
    {
        "label": "solve_maxrook",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.puzzle",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.puzzle",
        "peekOfCode": "def solve_maxrook(n):\n    s = newSolver(\"Maxrook\", True)\n    x = [[s.IntVar(0, 1, \"\") for _ in range(n)] for _ in range(n)]\n    for i in range(n):\n        k_out_of_n(s, 1, get_row(x, i), \"<=\")\n        k_out_of_n(s, 1, get_column(x, i), \"<=\")\n    Count = s.Sum(x[i][j] for i in range(n) for j in range(n))\n    s.Maximize(Count)\n    rc = s.Solve()\n    y = [[[\" \", \"R\"][int(SolVal(x[i][j]))] for j in range(n)] for i in range(n)]",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.puzzle",
        "documentation": {}
    },
    {
        "label": "get_se",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.puzzle",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.puzzle",
        "peekOfCode": "def get_se(x, i, j, n):\n    return [x[i + k % n][j + k % n] for k in range(n - i - j)]\ndef get_ne(x, i, j, n):\n    return [x[i - k % n][j + k % n] for k in range(i + 1 - j)]\ndef solve_maxpiece(n, p):\n    s = newSolver(\"Maxpiece\", True)\n    x = [[s.IntVar(0, 1, \"\") for _ in range(n)] for _ in range(n)]\n    for i in range(n):\n        if p in [\"R\", \"Q\"]:\n            k_out_of_n(s, 1, get_row(x, i), \"<=\")",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.puzzle",
        "documentation": {}
    },
    {
        "label": "get_ne",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.puzzle",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.puzzle",
        "peekOfCode": "def get_ne(x, i, j, n):\n    return [x[i - k % n][j + k % n] for k in range(i + 1 - j)]\ndef solve_maxpiece(n, p):\n    s = newSolver(\"Maxpiece\", True)\n    x = [[s.IntVar(0, 1, \"\") for _ in range(n)] for _ in range(n)]\n    for i in range(n):\n        if p in [\"R\", \"Q\"]:\n            k_out_of_n(s, 1, get_row(x, i), \"<=\")\n            k_out_of_n(s, 1, get_column(x, i), \"<=\")\n        if p in [\"B\", \"Q\"]:",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.puzzle",
        "documentation": {}
    },
    {
        "label": "solve_maxpiece",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.puzzle",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.puzzle",
        "peekOfCode": "def solve_maxpiece(n, p):\n    s = newSolver(\"Maxpiece\", True)\n    x = [[s.IntVar(0, 1, \"\") for _ in range(n)] for _ in range(n)]\n    for i in range(n):\n        if p in [\"R\", \"Q\"]:\n            k_out_of_n(s, 1, get_row(x, i), \"<=\")\n            k_out_of_n(s, 1, get_column(x, i), \"<=\")\n        if p in [\"B\", \"Q\"]:\n            for j in range(n):\n                if i in [0, n - 1] or j in [0, n - 1]:",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.puzzle",
        "documentation": {}
    },
    {
        "label": "get_subgrid",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.puzzle",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.puzzle",
        "peekOfCode": "def get_subgrid(x, i, j):\n    return [x[k][l] for k in range(i * 3, i * 3 + 3) for l in range(j * 3, j * 3 + 3)]\ndef all_diff(s, x):\n    for k in range(1, len(x[0])):\n        s.Add(sum([e[k] for e in x]) <= 1)\ndef solve_sudoku(G):\n    s, n, x = newSolver(\"Sudoku\", True), len(G), []\n    for i in range(n):\n        row = []\n        for j in range(n):",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.puzzle",
        "documentation": {}
    },
    {
        "label": "all_diff",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.puzzle",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.puzzle",
        "peekOfCode": "def all_diff(s, x):\n    for k in range(1, len(x[0])):\n        s.Add(sum([e[k] for e in x]) <= 1)\ndef solve_sudoku(G):\n    s, n, x = newSolver(\"Sudoku\", True), len(G), []\n    for i in range(n):\n        row = []\n        for j in range(n):\n            if G[i][j] == None:\n                v = [s.IntVar(1, n + 1, \"\")] + [s.IntVar(0, 1, \"\") for _ in range(n)]",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.puzzle",
        "documentation": {}
    },
    {
        "label": "solve_sudoku",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.puzzle",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.puzzle",
        "peekOfCode": "def solve_sudoku(G):\n    s, n, x = newSolver(\"Sudoku\", True), len(G), []\n    for i in range(n):\n        row = []\n        for j in range(n):\n            if G[i][j] == None:\n                v = [s.IntVar(1, n + 1, \"\")] + [s.IntVar(0, 1, \"\") for _ in range(n)]\n                s.Add(v[0] == sum(k * v[k] for k in range(1, n + 1)))\n            else:\n                v = [G[i][j]] + [0 if k != G[i][j] else 1 for k in range(1, n + 1)]",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.puzzle",
        "documentation": {}
    },
    {
        "label": "newIntVar",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.puzzle",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.puzzle",
        "peekOfCode": "def newIntVar(s, lb, ub):\n    l = ub - lb + 1\n    x = [s.IntVar(lb, ub, \"\")] + [s.IntVar(0, 1, \"\") for _ in range(l)]\n    s.Add(1 == sum(x[k] for k in range(1, l + 1)))\n    s.Add(x[0] == sum((lb + k - 1) * x[k] for k in range(1, l + 1)))\n    return x\ndef all_different(s, x):\n    lb = min(int(e[0].Lb()) for e in x)\n    ub = max(int(e[0].Ub()) for e in x)\n    for v in range(lb, ub + 1):",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.puzzle",
        "documentation": {}
    },
    {
        "label": "all_different",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.puzzle",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.puzzle",
        "peekOfCode": "def all_different(s, x):\n    lb = min(int(e[0].Lb()) for e in x)\n    ub = max(int(e[0].Ub()) for e in x)\n    for v in range(lb, ub + 1):\n        all = []\n        for e in x:\n            if e[0].Lb() <= v <= e[0].Ub():\n                all.append(e[1 + v - int(e[0].Lb())])\n        s.Add(sum(all) <= 1)\ndef neq(s, x, value):",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.puzzle",
        "documentation": {}
    },
    {
        "label": "neq",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.puzzle",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.puzzle",
        "peekOfCode": "def neq(s, x, value):\n    s.Add(x[1 + value - int(x[0].Lb())] == 0)\ndef solve_smm():\n    s = newSolver(\"Send more money\", True)\n    ALL = [S, E, N, D, M, O, R, Y] = [newIntVar(s, 0, 9) for k in range(8)]\n    s.Add(\n        1000 * S[0]\n        + 100 * E[0]\n        + 10 * N[0]\n        + D[0]",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.puzzle",
        "documentation": {}
    },
    {
        "label": "solve_smm",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.puzzle",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.puzzle",
        "peekOfCode": "def solve_smm():\n    s = newSolver(\"Send more money\", True)\n    ALL = [S, E, N, D, M, O, R, Y] = [newIntVar(s, 0, 9) for k in range(8)]\n    s.Add(\n        1000 * S[0]\n        + 100 * E[0]\n        + 10 * N[0]\n        + D[0]\n        + 1000 * M[0]\n        + 100 * O[0]",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.puzzle",
        "documentation": {}
    },
    {
        "label": "solve_lady_or_tiger",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.puzzle",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.puzzle",
        "peekOfCode": "def solve_lady_or_tiger():\n    s = newSolver(\"Lady or tiger\", True)\n    Rooms = range(1, 10)\n    R = [None] + [newIntVar(s, 0, 2) for _ in Rooms]\n    S = [None] + [s.IntVar(0, 1, \"\") for _ in Rooms]\n    i_empty, i_lady, i_tiger = 1, 2, 3\n    k_out_of_n(s, 1, [R[i][i_lady] for i in Rooms])\n    for i in Rooms:\n        reify_force(s, [1], [R[i][i_tiger]], 0, S[i], \"<=\")\n        reify_raise(s, [1], [R[i][i_lady]], 1, S[i], \">=\")",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.puzzle",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.runpuzzle",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.runpuzzle",
        "peekOfCode": "def main():\n    n0, S, X = 8, 7, 3\n    N, T = [], []\n    for i in range(S):\n        n = n0 * 2 ** i\n        N.append(n)\n        t0 = time()\n        for _ in range(X):\n            rc = solve_maxrook(n)\n        t = (time() - t0) / X",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.runpuzzle",
        "documentation": {}
    },
    {
        "label": "gen_data",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.set_cover",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.set_cover",
        "peekOfCode": "def gen_data(m, n):\n    # m is number of subsets, n is the size of universe\n    All = [0 for i in range(n)]\n    while sum(All) < n:\n        R = []\n        All = [0 for i in range(n)]\n        p = 0.8\n        for i in range(m):\n            RR = []\n            for j in range(n):",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.set_cover",
        "documentation": {}
    },
    {
        "label": "solve_model",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.set_cover",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.set_cover",
        "peekOfCode": "def solve_model(D, C=None):\n    t = \"Set Cover\"\n    s = pywraplp.Solver.CBC_MIXED_INTEGER_PROGRAMMING\n    s = pywraplp.Solver(t, s)\n    nbSup = len(D)\n    nbParts = max([e for d in D for e in d]) + 1\n    S = [s.IntVar(0, 1, \"\") for i in range(nbSup)]\n    for j in range(nbParts):\n        s.Add(1 <= sum(S[i] for i in range(nbSup) if j in D[i]))\n    s.Minimize(s.Sum(S[i] * (1 if C is None else C[i]) for i in range(nbSup)))",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.set_cover",
        "documentation": {}
    },
    {
        "label": "gen_data",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.set_packing",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.set_packing",
        "peekOfCode": "def gen_data(m, n, k):\n    # m is number of subsets, n is the size of universe, k is the size of each subset\n    R = []\n    for i in range(m):\n        RR = []\n        while len(RR) < k:\n            p = randint(0, n)\n            if p not in RR:\n                RR.append(randint(0, n))\n        RR.sort()",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.set_packing",
        "documentation": {}
    },
    {
        "label": "solve_model",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.set_packing",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.set_packing",
        "peekOfCode": "def solve_model(D, C=None):\n    s = newSolver(\"Set Packing\", True)\n    nbRosters, nbCrew = len(D), max([e for d in D for e in d]) + 1\n    S = [s.IntVar(0, 1, \"\") for i in range(nbRosters)]\n    for j in range(nbCrew):\n        s.Add(1 >= sum(S[i] for i in range(nbRosters) if j in D[i]))\n    s.Maximize(s.Sum(S[i] * (1 if C == None else C[i]) for i in range(nbRosters)))\n    rc = s.Solve()\n    Rosters = [i for i in range(nbRosters) if S[i].SolutionValue() > 0]\n    return rc, s.Objective().Value(), Rosters",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.set_packing",
        "documentation": {}
    },
    {
        "label": "dist",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.shortest_path",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.shortest_path",
        "peekOfCode": "def dist(p1, p2):\n    return int(round(sqrt((p1[0] - p2[0]) ** 2 + (p1[1] - p2[1]) ** 2)) / 10)\ndef gen_data(n):\n    points = [(randint(1, 1000), randint(1, 1000)) for i in range(n)]\n    points.sort()\n    R = []\n    S = 0\n    for i in range(n):\n        RR = []\n        for j in range(n):",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.shortest_path",
        "documentation": {}
    },
    {
        "label": "gen_data",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.shortest_path",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.shortest_path",
        "peekOfCode": "def gen_data(n):\n    points = [(randint(1, 1000), randint(1, 1000)) for i in range(n)]\n    points.sort()\n    R = []\n    S = 0\n    for i in range(n):\n        RR = []\n        for j in range(n):\n            if i == j or abs(i - j) > 0.5 * n:\n                d = 0",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.shortest_path",
        "documentation": {}
    },
    {
        "label": "solve_model",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.shortest_path",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.shortest_path",
        "peekOfCode": "def solve_model(D, Start=None, End=None):\n    s, n = newSolver(\"Shortest path problem\"), len(D)\n    if Start is None:\n        Start, End = 0, len(D) - 1\n    G = [[s.NumVar(0, 1 if D[i][j] else 0, \"\") for j in range(n)] for i in range(n)]\n    for i in range(n):\n        if i == Start:\n            s.Add(1 == sum(G[Start][j] for j in range(n)))\n            s.Add(0 == sum(G[j][Start] for j in range(n)))\n        elif i == End:",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.shortest_path",
        "documentation": {}
    },
    {
        "label": "critical_tasks",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.shortest_path",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.shortest_path",
        "peekOfCode": "def critical_tasks(D, t):\n    s = set([t[i] + D[i][1] for i in range(len(t))] + [t[i] for i in range(len(t))])\n    n, ix, start, end, times = len(s), 0, min(s), max(s), {}\n    for e in s:\n        times[e] = ix\n        ix += 1\n    M = [[0 for _ in range(n)] for _ in range(n)]\n    for i in range(len(t)):\n        M[times[t[i]]][times[t[i] + D[i][1]]] = -D[i][1]\n    rc, v, Path, Cost, Cumul = solve_model(M, times[start], times[end])",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.shortest_path",
        "documentation": {}
    },
    {
        "label": "solve_tree_model",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.shortest_path",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.shortest_path",
        "peekOfCode": "def solve_tree_model(D, Start=None):\n    s, n = newSolver(\"Shortest paths tree problem\"), len(D)\n    Start = 0 if Start is None else Start\n    G = [\n        [s.NumVar(0, 0 if D[i][j] is None else min(n, D[i][j]), \"\") for j in range(n)]\n        for i in range(n)\n    ]\n    for i in range(n):\n        if i == Start:\n            s.Add(n - 1 == sum(G[Start][j] for j in range(n)))",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.shortest_path",
        "documentation": {}
    },
    {
        "label": "solve_all_pairs",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.shortest_path",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.shortest_path",
        "peekOfCode": "def solve_all_pairs(D):\n    n = len(D)\n    Costs = [[None if i != j else 0 for i in range(n)] for j in range(n)]\n    Paths = [[None for i in range(n)] for j in range(n)]\n    for start in range(n):\n        for end in range(n):\n            if start != end and Costs[start][end] is None:\n                rc, Value, Path, Cost, Cumul = solve_model(D, start, end)\n                if rc == 0:\n                    for k in range(len(Path) - 1):",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.shortest_path",
        "documentation": {}
    },
    {
        "label": "compute_weeks",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.sports_timetabling",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.sports_timetabling",
        "peekOfCode": "def compute_weeks(T, P):\n    from math import ceil\n    nbTeams = sum([1 for sub in T for e in sub])\n    nbIntra = P[0]\n    nbInter = P[1]\n    nbPerWeek = P[2]\n    nbGames = 0\n    nbWeeks = 0\n    d = 1000\n    for i in range(len(T)):",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.sports_timetabling",
        "documentation": {}
    },
    {
        "label": "gen_data",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.sports_timetabling",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.sports_timetabling",
        "peekOfCode": "def gen_data(m, n):\n    R, team = [], 0\n    for i in range(m):\n        RR = []\n        nb = choice(n)\n        for j in range(nb):\n            RR.append(team)\n            team = team + 1\n        R.append(RR)\n    X = randint(1, 3)",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.sports_timetabling",
        "documentation": {}
    },
    {
        "label": "solve_model",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.sports_timetabling",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.sports_timetabling",
        "peekOfCode": "def solve_model(Teams, params):\n    (nbIntra, nbInter, nbPerWeek, nbWeeks) = params\n    nbTeams = sum([1 for sub in Teams for e in sub])\n    nbDiv, Cal = len(Teams), []\n    s = newSolver(\"Sports schedule\", True)\n    x = [\n        [\n            [s.IntVar(0, 1, \"\") if i < j else None for _ in range(nbWeeks)]\n            for j in range(nbTeams)\n        ]",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.sports_timetabling",
        "documentation": {}
    },
    {
        "label": "add_intra",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.sports_timetabling",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.sports_timetabling",
        "peekOfCode": "def add_intra(s, Teams, nbWeeks, nbIntra, x):\n    for Div in Teams:\n        for i in Div:\n            for j in Div:\n                if i < j:\n                    s.Add(sum(x[i][j][w] for w in range(nbWeeks)) == nbIntra)\ndef add_inter(s, Teams, nbDiv, nbWeeks, nbInter, x):\n    for d in range(nbDiv - 1):\n        for e in range(d + 1, nbDiv):\n            for i in Teams[d]:",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.sports_timetabling",
        "documentation": {}
    },
    {
        "label": "add_inter",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.sports_timetabling",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.sports_timetabling",
        "peekOfCode": "def add_inter(s, Teams, nbDiv, nbWeeks, nbInter, x):\n    for d in range(nbDiv - 1):\n        for e in range(d + 1, nbDiv):\n            for i in Teams[d]:\n                for j in Teams[e]:\n                    s.Add(sum(x[i][j][w] for w in range(nbWeeks)) == nbInter)\ndef add_games_bound(s, nbWeeks, nbTeams, nbPerWeek, x):\n    for w in range(nbWeeks):\n        for i in range(nbTeams):\n            s.Add(",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.sports_timetabling",
        "documentation": {}
    },
    {
        "label": "add_games_bound",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.sports_timetabling",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.sports_timetabling",
        "peekOfCode": "def add_games_bound(s, nbWeeks, nbTeams, nbPerWeek, x):\n    for w in range(nbWeeks):\n        for i in range(nbTeams):\n            s.Add(\n                sum(x[i][j][w] for j in range(nbTeams) if i < j)\n                + sum(x[j][i][w] for j in range(nbTeams) if j < i)\n                <= nbPerWeek\n            )\ndef add_objective(s, Teams, nbWeeks, x, nbIntra, nbPerWeek):\n    Value = [",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.sports_timetabling",
        "documentation": {}
    },
    {
        "label": "add_objective",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.sports_timetabling",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.sports_timetabling",
        "peekOfCode": "def add_objective(s, Teams, nbWeeks, x, nbIntra, nbPerWeek):\n    Value = [\n        x[i][j][w]\n        for Div in Teams\n        for i in Div\n        for j in Div\n        for w in range(nbWeeks - len(Div) * nbIntra // nbPerWeek, nbWeeks)\n        if i < j\n    ]\n    return Value",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.sports_timetabling",
        "documentation": {}
    },
    {
        "label": "basic_model",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.sports_timetabling",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.sports_timetabling",
        "peekOfCode": "def basic_model(\n    s, Teams, nbTeams, nbWeeks, nbPerWeek, nbIntra, nbDiv, nbInter, cuts, x\n):\n    add_intra(s, Teams, nbWeeks, nbIntra, x)\n    add_inter(s, Teams, nbDiv, nbWeeks, nbInter, x)\n    add_games_bound(s, nbWeeks, nbTeams, nbPerWeek, x)\n    for t, w in cuts:\n        s.Add(sum(x[p[0]][p[1]][w[0]] for p in pairs(t, [])) <= w[1])\n    Value = add_objective(s, Teams, nbWeeks, x, nbIntra, nbPerWeek)\n    s.Maximize(s.Sum(Value))",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.sports_timetabling",
        "documentation": {}
    },
    {
        "label": "solve_model_big",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.sports_timetabling",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.sports_timetabling",
        "peekOfCode": "def solve_model_big(Teams, params):\n    (nbIntra, nbInter, nbPerWeek, nbWeeks) = params\n    nbTeams = sum([1 for sub in Teams for e in sub])\n    nbDiv, cuts = len(Teams), []\n    for iter in range(2):\n        s = newSolver(\"Sports schedule\", False)\n        x = [\n            [\n                [s.NumVar(0, 1, \"\") if i < j else None for _ in range(nbWeeks)]\n                for j in range(nbTeams)",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.sports_timetabling",
        "documentation": {}
    },
    {
        "label": "gen_data",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.staffing",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.staffing",
        "peekOfCode": "def gen_data(m, n, n0):\n    # m is number of time intervals, n is number of shifts\n    R = [[0 for _ in range(n + 1)] for _ in range(m + 1)]\n    for i in range(m):  # Staffing needs\n        R[i][-1] = randint(10, 20)\n    n1 = n - n0  # Part-time\n    d0 = int(round(m / n0) + 1)  # Full-time shift\n    d1 = int(round(d0 / 2))  # Part-time shift\n    for j in range(n0):  # Pay for full-time-shift\n        R[-1][j] = round(uniform(15, 20) * d0, 2)",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.staffing",
        "documentation": {}
    },
    {
        "label": "solve_model",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.staffing",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.staffing",
        "peekOfCode": "def solve_model(M, nf, Q=None, P=None, no_part=False):\n    s = newSolver(\"Staffing\", True)\n    nbt, n = len(M) - 1, len(M[0]) - 1\n    B = sum(M[t][-1] for t in range(len(M) - 1))\n    x = [s.IntVar(0, B, \"\") for i in range(n)]\n    for t in range(nbt):\n        s.Add(sum([M[t][i] * x[i] for i in range(n)]) >= M[t][-1])\n    if Q:\n        for i in range(n):\n            s.Add(x[i] >= Q[i])",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.staffing",
        "documentation": {}
    },
    {
        "label": "gen_section",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.staff_scheduling",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.staff_scheduling",
        "peekOfCode": "def gen_section(n):\n    R = []\n    section = 0\n    for c in range(n):\n        for j in range(randint(1, 4)):\n            RR = [section, c, randint(1, 20)]\n            R.append(RR)\n            section = section + 1\n    return R, section\nfrom random import randint",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.staff_scheduling",
        "documentation": {}
    },
    {
        "label": "gen_instructor",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.staff_scheduling",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.staff_scheduling",
        "peekOfCode": "def gen_instructor(m, n, p, pp):\n    R = []\n    for i in range(m):\n        RR = [\n            i,\n            [randint(1, 2), randint(2, 3)],\n            [randint(0, 1) * randint(-10, 10) for _ in range(p)],\n            [randint(0, 1) * randint(-10, 10) for _ in range(n)],\n            [randint(0, 1) * randint(-10, 10) for _ in range(pp)],\n        ]",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.staff_scheduling",
        "documentation": {}
    },
    {
        "label": "gen_sets",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.staff_scheduling",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.staff_scheduling",
        "peekOfCode": "def gen_sets(n, ns):\n    R = []\n    for i in range(ns):\n        RR = [i, [j for j in range(n) if randint(0, 1)]]\n        R.append(RR)\n    return R\nfrom random import randint\ndef gen_pairs(pp, n):\n    R = []\n    for i in range(pp):",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.staff_scheduling",
        "documentation": {}
    },
    {
        "label": "gen_pairs",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.staff_scheduling",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.staff_scheduling",
        "peekOfCode": "def gen_pairs(pp, n):\n    R = []\n    for i in range(pp):\n        q = 4\n        c0 = 0\n        RR = []\n        for j in range(q):\n            c0 = randint(c0, int(3 * n / q))\n            c1 = randint(c0 + 1, n - 1)\n            if (c0, c1) not in RR:",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.staff_scheduling",
        "documentation": {}
    },
    {
        "label": "solve_model",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.staff_scheduling",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.staff_scheduling",
        "peekOfCode": "def solve_model(S, I, R, P):\n    s = newSolver(\"Staff Scheduling\", True)\n    nbS, nbI, nbSets, nbPairs = len(S), len(I), len(R), len(P)\n    nbC, nbT = S[-1][1] + 1, 1 + max(e[2] for e in S)\n    x = [[s.IntVar(0, 1, \"\") for _ in range(nbS)] for _ in range(nbI)]\n    z = [\n        [[s.IntVar(0, 1, \"\") for _ in range(len(P[p][1]))] for p in range(nbPairs)]\n        for _ in range(nbI)\n    ]\n    for j in range(nbS):",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.staff_scheduling",
        "documentation": {}
    },
    {
        "label": "ss_ret",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.staff_scheduling",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.staff_scheduling",
        "peekOfCode": "def ss_ret(x, z, nbI, nbSets, nbS, nbPairs, I, S, R, P):\n    xs = []\n    for i in range(nbI):\n        xs.append(\n            [\n                i,\n                [\n                    [\n                        j,\n                        (",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.staff_scheduling",
        "documentation": {}
    },
    {
        "label": "flatten",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.tableutils",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.tableutils",
        "peekOfCode": "def flatten(l):\n    return [e for s in l for e in s]\ndef set2string(S):\n    s = \"{ \"\n    if S is not None:\n        for i in range(len(S)):\n            s = s + str(S[i])\n            if i < len(S) - 1:\n                s = s + \"; \"\n            else:",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.tableutils",
        "documentation": {}
    },
    {
        "label": "set2string",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.tableutils",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.tableutils",
        "peekOfCode": "def set2string(S):\n    s = \"{ \"\n    if S is not None:\n        for i in range(len(S)):\n            s = s + str(S[i])\n            if i < len(S) - 1:\n                s = s + \"; \"\n            else:\n                s = s + \" \"\n    s = s + \"}\"",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.tableutils",
        "documentation": {}
    },
    {
        "label": "wrapmat",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.tableutils",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.tableutils",
        "peekOfCode": "def wrapmat(M, left, header):\n    T = copy.deepcopy(M)\n    m, n = len(T), len(T[0])\n    for i in range(len(left)):\n        T[i].insert(0, left[i])\n    if header != None:\n        if len(header) < len(T[0]):\n            T.insert(0, [\"\"] + header)\n        else:\n            T.insert(0, header)",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.tableutils",
        "documentation": {}
    },
    {
        "label": "formatmat",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.tableutils",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.tableutils",
        "peekOfCode": "def formatmat(M, zeroes=False, decimals=4):\n    T = copy.deepcopy(M)\n    for i in range(len(M)):\n        for j in range(len(M[i])):\n            el = T[i][j]\n            if type(el) == int:\n                if el or zeroes:\n                    el = \"{0:4d}\".format(el)\n                else:\n                    el = \"\"",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.tableutils",
        "documentation": {}
    },
    {
        "label": "printmat",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.tableutils",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.tableutils",
        "peekOfCode": "def printmat(M, zeroes=False, decimals=4):\n    T = formatmat(M, zeroes, decimals)\n    output = []\n    for row in T:\n        l = \"\"\n        for i in range(len(row)):\n            l = l + str(row[i])\n            if i < len(row) - 1:\n                l = l + \",\"\n        print(l)",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.tableutils",
        "documentation": {}
    },
    {
        "label": "splitwrapmat",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.tableutils",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.tableutils",
        "peekOfCode": "def splitwrapmat(M, left, header):\n    T = wrapmat(M, left, None)\n    if len(T) % 2:\n        T.append([])\n    T2 = [T[i] + T[i + 1] for i in range(0, len(T), 2)]\n    return wrapmat(T2, [], header + header)",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.tableutils",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_bin_packing",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_bin_packing",
        "peekOfCode": "def main():\n    import sys\n    import random\n    import tableutils\n    n = 3\n    if len(sys.argv) <= 1:\n        print(\"Usage is main [data|run] [seed]\")\n        return\n    elif len(sys.argv) > 2:\n        random.seed(int(sys.argv[2]))",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_bin_packing",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_blend_multi",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_blend_multi",
        "peekOfCode": "def main():\n    import sys\n    import random\n    import tableutils\n    m = 9\n    n = 7\n    k = 5\n    if len(sys.argv) <= 1:\n        print(\"Usage is main [content|target|cost|inventory|run] [seed]\")\n        return",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_blend_multi",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_classification",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_classification",
        "peekOfCode": "def main():\n    n = 12\n    m = 2\n    if len(sys.argv) <= 1:\n        print(\"Usage is main [gen|run] [seed]\")\n        return\n    elif len(sys.argv) >= 2:\n        if len(sys.argv) >= 3:\n            random.seed(int(sys.argv[2]))\n        A, B, a = gen_features(n, m)",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_classification",
        "documentation": {}
    },
    {
        "label": "T",
        "kind": 5,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_coexistence",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_coexistence",
        "peekOfCode": "T = [[\"Specie\", \"Count\"]]\nfor i in range(3):\n    T.append([[\"Toads\", \"Salamanders\", \"Caecilians\"][i], x[i]])\nT.append([\"Total\", pop])\nfor e in T:\n    print(e[0], e[1])",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_coexistence",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_curve_fit",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_curve_fit",
        "peekOfCode": "def main():\n    import sys\n    import random\n    import tableutils\n    n = 10\n    degree = 2\n    if len(sys.argv) <= 1:\n        print(\"Usage is main [data|run] [seed]\")\n        return\n    elif len(sys.argv) >= 2:",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_curve_fit",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_cutting_stock",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_cutting_stock",
        "peekOfCode": "def main():\n    import sys\n    import random\n    import tableutils\n    n = 7\n    if len(sys.argv) <= 1:\n        print(\"Usage is main [data|run|large] [seed]\")\n        return\n    elif len(sys.argv) >= 3:\n        random.seed(int(sys.argv[2]))",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_cutting_stock",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_diet_problem",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_diet_problem",
        "peekOfCode": "def main():\n    if len(sys.argv) == 1:\n        return\n    elif len(sys.argv) == 3:\n        random.seed(int(sys.argv[2]))\n    nbfoods = 5\n    nbnutrients = 4\n    header = (\n        [\"\"]\n        + [\"N\" + str(i) for i in range(nbnutrients)]",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_diet_problem",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_facility_location",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_facility_location",
        "peekOfCode": "def main():\n    import sys\n    import random\n    import tableutils\n    m = 10\n    n = 7\n    if len(sys.argv) <= 1:\n        print(\"Usage is main [dcost|fcost|run] [seed]\")\n        return\n    elif len(sys.argv) >= 2:",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_facility_location",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_gas_blend",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_gas_blend",
        "peekOfCode": "def main():\n    import sys\n    import random\n    import tableutils\n    n = 8\n    m = 3\n    if len(sys.argv) <= 1:\n        print(\"Usage is main [raw|ref|run] [seed]\")\n        return\n    elif len(sys.argv) >= 3:",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_gas_blend",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_job_shop",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_job_shop",
        "peekOfCode": "def main():\n    import sys\n    import random\n    import tableutils\n    m = 4\n    n = 3\n    if len(sys.argv) <= 1:\n        print(\"Usage is main [data|run] [seed]\")\n        return\n    elif len(sys.argv) > 2:",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_job_shop",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_maxflow",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_maxflow",
        "peekOfCode": "def main():\n    import sys\n    import random\n    import tableutils\n    n = 7\n    header = []\n    if len(sys.argv) <= 1:\n        print(\"Usage is main [data|run0|run1] [seed]\")\n        return\n    elif len(sys.argv) >= 2:",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_maxflow",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_mincost",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_mincost",
        "peekOfCode": "def main():\n    import sys\n    import random\n    import tableutils\n    m = 3\n    n = 7\n    if len(sys.argv) <= 1:\n        print(\"Usage is main [data|run] [seed]\")\n        return\n    elif len(sys.argv) >= 2:",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_mincost",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_multi_commodity_flow",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_multi_commodity_flow",
        "peekOfCode": "def main():\n    import sys\n    import random\n    import tableutils\n    n = 5\n    m = 3\n    C = []\n    if len(sys.argv) <= 1:\n        print(\"Usage is main [data|run|pairs] [seed]\")\n        return",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_multi_commodity_flow",
        "documentation": {}
    },
    {
        "label": "my_function",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_piecewise",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_piecewise",
        "peekOfCode": "def my_function(x):\n    from math import sin, exp\n    return sin(x) * exp(x)\ndef main():\n    import sys\n    import random\n    import tableutils\n    n = 6\n    if len(sys.argv) <= 1:\n        print(\"Usage is main [data|run|non|ncvx] [seed] [bound] [False]\")",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_piecewise",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_piecewise",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_piecewise",
        "peekOfCode": "def main():\n    import sys\n    import random\n    import tableutils\n    n = 6\n    if len(sys.argv) <= 1:\n        print(\"Usage is main [data|run|non|ncvx] [seed] [bound] [False]\")\n        return\n    elif len(sys.argv) >= 3:\n        random.seed(int(sys.argv[2]))",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_piecewise",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_project_management",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_project_management",
        "peekOfCode": "def main():\n    import sys\n    import random\n    import tableutils\n    n = 12\n    if len(sys.argv) <= 1:\n        print(\"Usage is main [data|run] [seed]\")\n        return\n    elif len(sys.argv) >= 3:\n        random.seed(int(sys.argv[2]))",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_project_management",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_puzzle",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_puzzle",
        "peekOfCode": "def main():\n    import sys, random, tableutils, time\n    if len(sys.argv) <= 1:\n        print(\n            \"Usage is main [maxrook|rook|queen|bishop|sudoku|sudokus|smm|lady] [seed]\"\n        )\n        return\n    elif len(sys.argv) >= 2:\n        n = int(sys.argv[2])\n        header = [i + 1 for i in range(n)]",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_puzzle",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_set_cover",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_set_cover",
        "peekOfCode": "def main():\n    import sys\n    import random\n    import tableutils\n    m = 15\n    n = 25\n    if len(sys.argv) <= 1:\n        print(\"Usage is main [data|run] [seed]\")\n        return\n    elif len(sys.argv) > 2:",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_set_cover",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_set_packing",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_set_packing",
        "peekOfCode": "def main():\n    import sys\n    import random\n    import tableutils\n    m = 15\n    n = 40\n    k = 3\n    if len(sys.argv) <= 1:\n        print(\"Usage is main [data|run] [seed]\")\n        return",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_set_packing",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_shortest_path",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_shortest_path",
        "peekOfCode": "def main():\n    import sys\n    import random\n    import tableutils\n    n = 13\n    header = [\"P\" + str(i) for i in range(n)]\n    if len(sys.argv) <= 1:\n        print(\"Usage is main [data|run|all|tree|pm] [seed]\")\n        return\n    elif len(sys.argv) > 2:",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_shortest_path",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_sports_timetabling",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_sports_timetabling",
        "peekOfCode": "def main():\n    import sys\n    import random\n    import tableutils\n    nbdiv = 2\n    nbteam = [6, 7, 8]\n    if len(sys.argv) <= 1:\n        print(\"Usage is main [data|run|big] [seed]\")\n        return\n    elif len(sys.argv) >= 3:",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_sports_timetabling",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_staffing",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_staffing",
        "peekOfCode": "def main():\n    import sys\n    import random\n    import tableutils\n    m = 12  # Number of time intervals\n    n = 7  # Number of shifts\n    n0 = 4  # Number of full-time shifts\n    header = [\"Shift \" + str(j) for j in range(n)]\n    left = [\"{0:02}h\".format(i * 2) for i in range(m)] + [\"Cost\"]\n    if len(sys.argv) <= 1:",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_staffing",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_staff_scheduling",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_staff_scheduling",
        "peekOfCode": "def main():\n    import sys\n    import random\n    import tableutils\n    nbcourse = 7\n    nbsets = 6\n    nbinstructor = 5\n    nbpairs = 2\n    if len(sys.argv) <= 1:\n        print(\"Usage is main [section|sets|instructor|pairs|run] [seed]\")",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_staff_scheduling",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_transship_dist",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_transship_dist",
        "peekOfCode": "def main():\n    import sys\n    import random\n    import tableutils\n    n = 8\n    if len(sys.argv) <= 1:\n        print(\"Usage is main [data|run] [seed]\")\n        return\n    elif len(sys.argv) >= 2:\n        random.seed(int(sys.argv[2]))",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_transship_dist",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_tricks",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_tricks",
        "peekOfCode": "def main():\n    t = \"k out of n\"\n    n = 9\n    seed(100)\n    bound = [randint(5, 15) for _ in range(n)]\n    tableutils.printmat([[\"Max sum of\"] + bound])\n    for k in range(1, n + 1):\n        s = pywraplp.Solver(t, pywraplp.Solver.CBC_MIXED_INTEGER_PROGRAMMING)\n        x = [s.NumVar(0, bound[i], \"\") for i in range(n)]\n        y = [s.NumVar(0, bound[i], \"\") for i in range(n)]",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_tricks",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_tricks_0",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_tricks_0",
        "peekOfCode": "def main():\n    a, b = [2, 3], 5\n    s = pywraplp.Solver(\"Test Box\", pywraplp.Solver.GLOP_LINEAR_PROGRAMMING)\n    x = [s.NumVar(-1, 6, \"\"), s.NumVar(-3, 5, \"\")]\n    bounds = bounds_on_box(a, x, b)\n    print(bounds == [-16, 22])\nmain()",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_tricks_0",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_tricks_1",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_tricks_1",
        "peekOfCode": "def main():\n    bounds = []\n    s = pywraplp.Solver(\"\", pywraplp.Solver.GLOP_LINEAR_PROGRAMMING)\n    a = [1, 2]\n    x = [s.NumVar(3, 5, \"x[%i]\" % i) for i in range(2)]\n    b = 10\n    bounds = bounds_on_box(a, x, b)\n    print(bounds == [-1, 5])\nmain()",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_tricks_1",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_tricks_2",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_tricks_2",
        "peekOfCode": "def main():\n    # Test force\n    bounds = []\n    s = pywraplp.Solver(\"\", pywraplp.Solver.CBC_MIXED_INTEGER_PROGRAMMING)\n    a = [[0, 1], [1, 0]]\n    b = [4, 5]\n    x = [s.IntVar(0, 10, \"x[%i]\" % i) for i in range(2)]\n    bounds, delta, gamma = [], [], []\n    for j in range(len(a)):\n        bounds.append(bounds_on_box(a[j], x, b[j]))",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_tricks_2",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_tricks_3",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_tricks_3",
        "peekOfCode": "def main():\n    bounds = []\n    s = pywraplp.Solver(\"\", pywraplp.Solver.CBC_MIXED_INTEGER_PROGRAMMING)\n    a = [[2], [-2]]\n    b = [3, -12]\n    x = s.NumVar(2, 5, \"x\")\n    z, l = maximax(s, a, [x], b)\n    rc = s.Solve()\n    print(\"x = \", SolVal(x))\n    print(\"z = \", SolVal(z))",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_tricks_3",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_tricks_5",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_tricks_5",
        "peekOfCode": "def main():\n    s = newSolver(\"Test reify force\", True)\n    x = [s.NumVar(0, 10, \"\"), s.NumVar(0, 10, \"\")]\n    delta_1 = reify_force(s, [1, 1], x, 3, None, \"==\")\n    delta_2 = reify_force(s, [1, 1], x, 5, None, \"==\")\n    s.Add(delta_1 + delta_2 == 1)\n    s.Maximize(2 * x[0] + 3 * x[1])\n    s.Solve()\n    print(\n        [",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_tricks_5",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_tsp",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_tsp",
        "peekOfCode": "def main():\n    import sys\n    import random\n    import tableutils\n    n = 10\n    if len(sys.argv) <= 1:\n        print(\"Usage is main [data|display|run|path|star] [seed]\")\n        return\n    elif len(sys.argv) > 2:\n        random.seed(int(sys.argv[2]))",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.test_tsp",
        "documentation": {}
    },
    {
        "label": "gen_data",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.transship_dist",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.transship_dist",
        "peekOfCode": "def gen_data(n, zap=True):\n    R, Cap = [], []\n    S, D = 0, 0\n    for i in range(n):\n        RR = []\n        for j in range(n):\n            if zap:\n                yesno = randint(0, 1)\n            else:\n                yesno = 1",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.transship_dist",
        "documentation": {}
    },
    {
        "label": "solve_model",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.transship_dist",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.transship_dist",
        "peekOfCode": "def solve_model(D):\n    s = newSolver(\"Transshipment problem\")\n    n = len(D[0]) - 1\n    B = sum([D[-1][j] for j in range(n)])\n    G = [[s.NumVar(0, B if D[i][j] else 0, \"\") for j in range(n)] for i in range(n)]\n    for i in range(n):\n        s.Add(\n            D[i][-1] - D[-1][i]\n            == sum(G[i][j] for j in range(n)) - sum(G[j][i] for j in range(n))\n        )",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.transship_dist",
        "documentation": {}
    },
    {
        "label": "dist",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.tsp",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.tsp",
        "peekOfCode": "def dist(p1, p2):\n    return int(round(10 * sqrt((p1[0] - p2[0]) ** 2 + (p1[1] - p2[1]) ** 2)))\ndef gen_data(n):\n    points = [(randint(1, 100), randint(1, 100)) for i in range(n)]\n    R = [[None for i in range(n)] for j in range(n)]\n    for i in range(n):\n        for j in range(n):\n            perturb = uniform(0.8, 1.2)\n            if i != j and perturb > 0:\n                R[i][j] = int(dist(points[i], points[j]) * perturb)",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.tsp",
        "documentation": {}
    },
    {
        "label": "gen_data",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.tsp",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.tsp",
        "peekOfCode": "def gen_data(n):\n    points = [(randint(1, 100), randint(1, 100)) for i in range(n)]\n    R = [[None for i in range(n)] for j in range(n)]\n    for i in range(n):\n        for j in range(n):\n            perturb = uniform(0.8, 1.2)\n            if i != j and perturb > 0:\n                R[i][j] = int(dist(points[i], points[j]) * perturb)\n    return R, points\nfrom my_or_tools import ObjVal, SolVal, newSolver",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.tsp",
        "documentation": {}
    },
    {
        "label": "solve_model_eliminate",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.tsp",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.tsp",
        "peekOfCode": "def solve_model_eliminate(D, Subtours=[]):\n    s, n = newSolver(\"TSP\", True), len(D)\n    x = [\n        [s.IntVar(0, 0 if D[i][j] is None else 1, \"\") for j in range(n)]\n        for i in range(n)\n    ]\n    for i in range(n):\n        s.Add(1 == sum(x[i][j] for j in range(n)))\n        s.Add(1 == sum(x[j][i] for j in range(n)))\n        s.Add(0 == x[i][i])",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.tsp",
        "documentation": {}
    },
    {
        "label": "extract_tours",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.tsp",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.tsp",
        "peekOfCode": "def extract_tours(R, n):\n    node, tours, allnodes = 0, [[0]], [0] + [1] * (n - 1)\n    while sum(allnodes) > 0:\n        next = [i for i in range(n) if R[node][i] == 1][0]\n        if next not in tours[-1]:\n            tours[-1].append(next)\n            node = next\n        else:\n            node = allnodes.index(1)\n            tours.append([node])",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.tsp",
        "documentation": {}
    },
    {
        "label": "solve_model",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.tsp",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.tsp",
        "peekOfCode": "def solve_model(D):\n    subtours, tours = [], []\n    while len(tours) != 1:\n        rc, Value, tours = solve_model_eliminate(D, subtours)\n        if rc == 0:\n            subtours.extend(tours)\n    return rc, Value, tours[0]\ndef solve_model_p(D):\n    n, n1 = len(D), len(D) + 1\n    E = [[0 if n in (i, j) else D[i][j] for j in range(n1)] for i in range(n1)]",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.tsp",
        "documentation": {}
    },
    {
        "label": "solve_model_p",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.tsp",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.tsp",
        "peekOfCode": "def solve_model_p(D):\n    n, n1 = len(D), len(D) + 1\n    E = [[0 if n in (i, j) else D[i][j] for j in range(n1)] for i in range(n1)]\n    rc, Value, tour = solve_model(E)\n    i = tour.index(n)\n    path = [tour[j] for j in range(i + 1, n1)] + [tour[j] for j in range(i)]\n    return rc, Value, path\ndef solve_model_star(D):\n    import shortest_path\n    n = len(D)",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.tsp",
        "documentation": {}
    },
    {
        "label": "solve_model_star",
        "kind": 2,
        "importPath": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.tsp",
        "description": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.tsp",
        "peekOfCode": "def solve_model_star(D):\n    import shortest_path\n    n = len(D)\n    Paths, Costs = shortest_path.solve_all_pairs(D)\n    rc, Value, tour = solve_model(Costs)\n    Tour = []\n    for i in range(len(tour)):\n        Tour.extend(Paths[tour[i]][tour[(i + 1) % len(tour)]][0:-1])\n    return rc, Value, Tour",
        "detail": "_REPO.APRESS.practical-python-ai-projects.Apress-AI-master.tsp",
        "documentation": {}
    },
    {
        "label": "Card",
        "kind": 6,
        "importPath": "_REPO.FCC.CurriculumExpansion.basic-python-blackjack.blackjack",
        "description": "_REPO.FCC.CurriculumExpansion.basic-python-blackjack.blackjack",
        "peekOfCode": "class Card:\n    def __init__(self, suit, rank):\n        self.suit = suit\n        self.rank = rank\n    def __str__(self):\n        return f\"{self.rank['rank']} of {self.suit}\"\nclass Deck:\n    def __init__(self):\n        self.cards = []\n        suits = [\"♠\", \"♣️\", \"♥️\", \"♦️\"]",
        "detail": "_REPO.FCC.CurriculumExpansion.basic-python-blackjack.blackjack",
        "documentation": {}
    },
    {
        "label": "Deck",
        "kind": 6,
        "importPath": "_REPO.FCC.CurriculumExpansion.basic-python-blackjack.blackjack",
        "description": "_REPO.FCC.CurriculumExpansion.basic-python-blackjack.blackjack",
        "peekOfCode": "class Deck:\n    def __init__(self):\n        self.cards = []\n        suits = [\"♠\", \"♣️\", \"♥️\", \"♦️\"]\n        ranks = [\n            {\"rank\": \"A\", \"value\": 11},\n            {\"rank\": \"2\", \"value\": 2},\n            {\"rank\": \"3\", \"value\": 3},\n            {\"rank\": \"4\", \"value\": 4},\n            {\"rank\": \"5\", \"value\": 5},",
        "detail": "_REPO.FCC.CurriculumExpansion.basic-python-blackjack.blackjack",
        "documentation": {}
    },
    {
        "label": "Hand",
        "kind": 6,
        "importPath": "_REPO.FCC.CurriculumExpansion.basic-python-blackjack.blackjack",
        "description": "_REPO.FCC.CurriculumExpansion.basic-python-blackjack.blackjack",
        "peekOfCode": "class Hand:\n    def __init__(self, dealer=False):\n        self.dealer = dealer\n        self.cards = []\n        self.value = 0\n    def add_card(self, card):\n        self.cards.append(card)\n    def calculate_value(self):\n        self.value = 0\n        has_ace = False",
        "detail": "_REPO.FCC.CurriculumExpansion.basic-python-blackjack.blackjack",
        "documentation": {}
    },
    {
        "label": "Game",
        "kind": 6,
        "importPath": "_REPO.FCC.CurriculumExpansion.basic-python-blackjack.blackjack",
        "description": "_REPO.FCC.CurriculumExpansion.basic-python-blackjack.blackjack",
        "peekOfCode": "class Game:\n    def play(self):\n        game_number = 0\n        games_to_play = 0\n        while games_to_play <= 0:\n            try:\n                games_to_play = int(input(\"How many games do you want to play?: \"))\n            except:\n                print(\"You must enter a number.\")\n        while game_number < games_to_play:",
        "detail": "_REPO.FCC.CurriculumExpansion.basic-python-blackjack.blackjack",
        "documentation": {}
    },
    {
        "label": "g",
        "kind": 5,
        "importPath": "_REPO.FCC.CurriculumExpansion.basic-python-blackjack.blackjack",
        "description": "_REPO.FCC.CurriculumExpansion.basic-python-blackjack.blackjack",
        "peekOfCode": "g = Game()\ng.play()",
        "detail": "_REPO.FCC.CurriculumExpansion.basic-python-blackjack.blackjack",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "_REPO.FCC.CurriculumExpansion.demographic-data-anaylzer.demographic-pandas-solution",
        "description": "_REPO.FCC.CurriculumExpansion.demographic-data-anaylzer.demographic-pandas-solution",
        "peekOfCode": "data = pd.read_csv(\"adult.data.csv\")\n# How many of each race (race feature) are represented in this dataset?\nrace_count = data[\"race\"].value_counts()\n# What is the average age (age feature) of men?\naverage_age_men = data.loc[data[\"sex\"] == \"Male\", \"age\"].mean()\n# What is the percentage of United States citizens (native-country feature)?\npercentage_US = (\n    float(((data[\"native-country\"] == \"United-States\").sum()) / data.shape[0]) * 100\n)\n# What are mean value and standard deviation of the age of those who recieve more than 50K per year (salary feature) and those who receive less than 50K per year?",
        "detail": "_REPO.FCC.CurriculumExpansion.demographic-data-anaylzer.demographic-pandas-solution",
        "documentation": {}
    },
    {
        "label": "race_count",
        "kind": 5,
        "importPath": "_REPO.FCC.CurriculumExpansion.demographic-data-anaylzer.demographic-pandas-solution",
        "description": "_REPO.FCC.CurriculumExpansion.demographic-data-anaylzer.demographic-pandas-solution",
        "peekOfCode": "race_count = data[\"race\"].value_counts()\n# What is the average age (age feature) of men?\naverage_age_men = data.loc[data[\"sex\"] == \"Male\", \"age\"].mean()\n# What is the percentage of United States citizens (native-country feature)?\npercentage_US = (\n    float(((data[\"native-country\"] == \"United-States\").sum()) / data.shape[0]) * 100\n)\n# What are mean value and standard deviation of the age of those who recieve more than 50K per year (salary feature) and those who receive less than 50K per year?\nages_high = data.loc[data[\"salary\"] == \">50K\", \"age\"]\nages_low = data.loc[data[\"salary\"] == \"<=50K\", \"age\"]",
        "detail": "_REPO.FCC.CurriculumExpansion.demographic-data-anaylzer.demographic-pandas-solution",
        "documentation": {}
    },
    {
        "label": "average_age_men",
        "kind": 5,
        "importPath": "_REPO.FCC.CurriculumExpansion.demographic-data-anaylzer.demographic-pandas-solution",
        "description": "_REPO.FCC.CurriculumExpansion.demographic-data-anaylzer.demographic-pandas-solution",
        "peekOfCode": "average_age_men = data.loc[data[\"sex\"] == \"Male\", \"age\"].mean()\n# What is the percentage of United States citizens (native-country feature)?\npercentage_US = (\n    float(((data[\"native-country\"] == \"United-States\").sum()) / data.shape[0]) * 100\n)\n# What are mean value and standard deviation of the age of those who recieve more than 50K per year (salary feature) and those who receive less than 50K per year?\nages_high = data.loc[data[\"salary\"] == \">50K\", \"age\"]\nages_low = data.loc[data[\"salary\"] == \"<=50K\", \"age\"]\nages_high_mean = ages_high.mean()\nages_low_mean = ages_low.mean()",
        "detail": "_REPO.FCC.CurriculumExpansion.demographic-data-anaylzer.demographic-pandas-solution",
        "documentation": {}
    },
    {
        "label": "percentage_US",
        "kind": 5,
        "importPath": "_REPO.FCC.CurriculumExpansion.demographic-data-anaylzer.demographic-pandas-solution",
        "description": "_REPO.FCC.CurriculumExpansion.demographic-data-anaylzer.demographic-pandas-solution",
        "peekOfCode": "percentage_US = (\n    float(((data[\"native-country\"] == \"United-States\").sum()) / data.shape[0]) * 100\n)\n# What are mean value and standard deviation of the age of those who recieve more than 50K per year (salary feature) and those who receive less than 50K per year?\nages_high = data.loc[data[\"salary\"] == \">50K\", \"age\"]\nages_low = data.loc[data[\"salary\"] == \"<=50K\", \"age\"]\nages_high_mean = ages_high.mean()\nages_low_mean = ages_low.mean()\nages_high_std = ages_high.std()\nages_low_std = ages_low.std()",
        "detail": "_REPO.FCC.CurriculumExpansion.demographic-data-anaylzer.demographic-pandas-solution",
        "documentation": {}
    },
    {
        "label": "ages_high",
        "kind": 5,
        "importPath": "_REPO.FCC.CurriculumExpansion.demographic-data-anaylzer.demographic-pandas-solution",
        "description": "_REPO.FCC.CurriculumExpansion.demographic-data-anaylzer.demographic-pandas-solution",
        "peekOfCode": "ages_high = data.loc[data[\"salary\"] == \">50K\", \"age\"]\nages_low = data.loc[data[\"salary\"] == \"<=50K\", \"age\"]\nages_high_mean = ages_high.mean()\nages_low_mean = ages_low.mean()\nages_high_std = ages_high.std()\nages_low_std = ages_low.std()\n# What is the minumum number of hours a person works per week (hours-per-week feature)?\n# What percentage of the people that work the minumum number of hours per week have a salary of >50K?\nmin_work = data[\"hours-per-week\"].min()\nnum_min_workers = data[data[\"hours-per-week\"] == min_work].shape[0]",
        "detail": "_REPO.FCC.CurriculumExpansion.demographic-data-anaylzer.demographic-pandas-solution",
        "documentation": {}
    },
    {
        "label": "ages_low",
        "kind": 5,
        "importPath": "_REPO.FCC.CurriculumExpansion.demographic-data-anaylzer.demographic-pandas-solution",
        "description": "_REPO.FCC.CurriculumExpansion.demographic-data-anaylzer.demographic-pandas-solution",
        "peekOfCode": "ages_low = data.loc[data[\"salary\"] == \"<=50K\", \"age\"]\nages_high_mean = ages_high.mean()\nages_low_mean = ages_low.mean()\nages_high_std = ages_high.std()\nages_low_std = ages_low.std()\n# What is the minumum number of hours a person works per week (hours-per-week feature)?\n# What percentage of the people that work the minumum number of hours per week have a salary of >50K?\nmin_work = data[\"hours-per-week\"].min()\nnum_min_workers = data[data[\"hours-per-week\"] == min_work].shape[0]\nrich_percentage = (",
        "detail": "_REPO.FCC.CurriculumExpansion.demographic-data-anaylzer.demographic-pandas-solution",
        "documentation": {}
    },
    {
        "label": "ages_high_mean",
        "kind": 5,
        "importPath": "_REPO.FCC.CurriculumExpansion.demographic-data-anaylzer.demographic-pandas-solution",
        "description": "_REPO.FCC.CurriculumExpansion.demographic-data-anaylzer.demographic-pandas-solution",
        "peekOfCode": "ages_high_mean = ages_high.mean()\nages_low_mean = ages_low.mean()\nages_high_std = ages_high.std()\nages_low_std = ages_low.std()\n# What is the minumum number of hours a person works per week (hours-per-week feature)?\n# What percentage of the people that work the minumum number of hours per week have a salary of >50K?\nmin_work = data[\"hours-per-week\"].min()\nnum_min_workers = data[data[\"hours-per-week\"] == min_work].shape[0]\nrich_percentage = (\n    float(",
        "detail": "_REPO.FCC.CurriculumExpansion.demographic-data-anaylzer.demographic-pandas-solution",
        "documentation": {}
    },
    {
        "label": "ages_low_mean",
        "kind": 5,
        "importPath": "_REPO.FCC.CurriculumExpansion.demographic-data-anaylzer.demographic-pandas-solution",
        "description": "_REPO.FCC.CurriculumExpansion.demographic-data-anaylzer.demographic-pandas-solution",
        "peekOfCode": "ages_low_mean = ages_low.mean()\nages_high_std = ages_high.std()\nages_low_std = ages_low.std()\n# What is the minumum number of hours a person works per week (hours-per-week feature)?\n# What percentage of the people that work the minumum number of hours per week have a salary of >50K?\nmin_work = data[\"hours-per-week\"].min()\nnum_min_workers = data[data[\"hours-per-week\"] == min_work].shape[0]\nrich_percentage = (\n    float(\n        data[(data[\"hours-per-week\"] == min_work) & (data[\"salary\"] == \">50K\")].shape[0]",
        "detail": "_REPO.FCC.CurriculumExpansion.demographic-data-anaylzer.demographic-pandas-solution",
        "documentation": {}
    },
    {
        "label": "ages_high_std",
        "kind": 5,
        "importPath": "_REPO.FCC.CurriculumExpansion.demographic-data-anaylzer.demographic-pandas-solution",
        "description": "_REPO.FCC.CurriculumExpansion.demographic-data-anaylzer.demographic-pandas-solution",
        "peekOfCode": "ages_high_std = ages_high.std()\nages_low_std = ages_low.std()\n# What is the minumum number of hours a person works per week (hours-per-week feature)?\n# What percentage of the people that work the minumum number of hours per week have a salary of >50K?\nmin_work = data[\"hours-per-week\"].min()\nnum_min_workers = data[data[\"hours-per-week\"] == min_work].shape[0]\nrich_percentage = (\n    float(\n        data[(data[\"hours-per-week\"] == min_work) & (data[\"salary\"] == \">50K\")].shape[0]\n    )",
        "detail": "_REPO.FCC.CurriculumExpansion.demographic-data-anaylzer.demographic-pandas-solution",
        "documentation": {}
    },
    {
        "label": "ages_low_std",
        "kind": 5,
        "importPath": "_REPO.FCC.CurriculumExpansion.demographic-data-anaylzer.demographic-pandas-solution",
        "description": "_REPO.FCC.CurriculumExpansion.demographic-data-anaylzer.demographic-pandas-solution",
        "peekOfCode": "ages_low_std = ages_low.std()\n# What is the minumum number of hours a person works per week (hours-per-week feature)?\n# What percentage of the people that work the minumum number of hours per week have a salary of >50K?\nmin_work = data[\"hours-per-week\"].min()\nnum_min_workers = data[data[\"hours-per-week\"] == min_work].shape[0]\nrich_percentage = (\n    float(\n        data[(data[\"hours-per-week\"] == min_work) & (data[\"salary\"] == \">50K\")].shape[0]\n    )\n    / num_min_workers",
        "detail": "_REPO.FCC.CurriculumExpansion.demographic-data-anaylzer.demographic-pandas-solution",
        "documentation": {}
    },
    {
        "label": "min_work",
        "kind": 5,
        "importPath": "_REPO.FCC.CurriculumExpansion.demographic-data-anaylzer.demographic-pandas-solution",
        "description": "_REPO.FCC.CurriculumExpansion.demographic-data-anaylzer.demographic-pandas-solution",
        "peekOfCode": "min_work = data[\"hours-per-week\"].min()\nnum_min_workers = data[data[\"hours-per-week\"] == min_work].shape[0]\nrich_percentage = (\n    float(\n        data[(data[\"hours-per-week\"] == min_work) & (data[\"salary\"] == \">50K\")].shape[0]\n    )\n    / num_min_workers\n) * 100\n# Identify the top occupation for those who earn a little and a lot (salary) for each country (native-country).\ntop_occupations_by_country = []",
        "detail": "_REPO.FCC.CurriculumExpansion.demographic-data-anaylzer.demographic-pandas-solution",
        "documentation": {}
    },
    {
        "label": "num_min_workers",
        "kind": 5,
        "importPath": "_REPO.FCC.CurriculumExpansion.demographic-data-anaylzer.demographic-pandas-solution",
        "description": "_REPO.FCC.CurriculumExpansion.demographic-data-anaylzer.demographic-pandas-solution",
        "peekOfCode": "num_min_workers = data[data[\"hours-per-week\"] == min_work].shape[0]\nrich_percentage = (\n    float(\n        data[(data[\"hours-per-week\"] == min_work) & (data[\"salary\"] == \">50K\")].shape[0]\n    )\n    / num_min_workers\n) * 100\n# Identify the top occupation for those who earn a little and a lot (salary) for each country (native-country).\ntop_occupations_by_country = []\nfor (country, salary), sub_df in data.groupby([\"native-country\", \"salary\"]):",
        "detail": "_REPO.FCC.CurriculumExpansion.demographic-data-anaylzer.demographic-pandas-solution",
        "documentation": {}
    },
    {
        "label": "rich_percentage",
        "kind": 5,
        "importPath": "_REPO.FCC.CurriculumExpansion.demographic-data-anaylzer.demographic-pandas-solution",
        "description": "_REPO.FCC.CurriculumExpansion.demographic-data-anaylzer.demographic-pandas-solution",
        "peekOfCode": "rich_percentage = (\n    float(\n        data[(data[\"hours-per-week\"] == min_work) & (data[\"salary\"] == \">50K\")].shape[0]\n    )\n    / num_min_workers\n) * 100\n# Identify the top occupation for those who earn a little and a lot (salary) for each country (native-country).\ntop_occupations_by_country = []\nfor (country, salary), sub_df in data.groupby([\"native-country\", \"salary\"]):\n    top_occupations_by_country.append(",
        "detail": "_REPO.FCC.CurriculumExpansion.demographic-data-anaylzer.demographic-pandas-solution",
        "documentation": {}
    },
    {
        "label": "top_occupations_by_country",
        "kind": 5,
        "importPath": "_REPO.FCC.CurriculumExpansion.demographic-data-anaylzer.demographic-pandas-solution",
        "description": "_REPO.FCC.CurriculumExpansion.demographic-data-anaylzer.demographic-pandas-solution",
        "peekOfCode": "top_occupations_by_country = []\nfor (country, salary), sub_df in data.groupby([\"native-country\", \"salary\"]):\n    top_occupations_by_country.append(\n        f\"{country} {salary} {sub_df['occupation'].value_counts().keys()[0]}\"\n    )\n# DO NOT MODIFY BELOW THIS LINE\nprint(\"Number of each race:\\n\", race_count)\nprint(\"Average age of men:\", average_age_men)\nprint(\"Percentage United States citizens:\", percentage_US)\nprint(",
        "detail": "_REPO.FCC.CurriculumExpansion.demographic-data-anaylzer.demographic-pandas-solution",
        "documentation": {}
    },
    {
        "label": "ContactDatabase",
        "kind": 6,
        "importPath": "_REPO.FCC.CurriculumExpansion.intermediate-python-contact-book.contactbook",
        "description": "_REPO.FCC.CurriculumExpansion.intermediate-python-contact-book.contactbook",
        "peekOfCode": "class ContactDatabase(object):\n    def __init__(self, filename=\"example-contactbook.db\"):\n        self.dbfilename = filename\n        db = sqlite3.connect(self.dbfilename)\n        c = db.cursor()\n        c.execute(\n            \"CREATE TABLE IF NOT EXISTS contacts \\\n            ( name          TEXT PRIMARY KEY, \\\n              email         TEXT, \\\n              phone         TEXT \\",
        "detail": "_REPO.FCC.CurriculumExpansion.intermediate-python-contact-book.contactbook",
        "documentation": {}
    },
    {
        "label": "Application",
        "kind": 6,
        "importPath": "_REPO.FCC.CurriculumExpansion.intermediate-python-contact-book.contactbook",
        "description": "_REPO.FCC.CurriculumExpansion.intermediate-python-contact-book.contactbook",
        "peekOfCode": "class Application(object):\n    def __init__(self, file_name):\n        self.database = ContactDatabase(file_name)\n    def add(self):\n        name, email, phone = self.get_info()\n        self.database.add_contact(name=name, email=email, phone=phone)\n    def viewall(self):\n        contacts = self.database.list_all_contacts()\n        for contact in contacts:\n            self.print_contact(contact)",
        "detail": "_REPO.FCC.CurriculumExpansion.intermediate-python-contact-book.contactbook",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "_REPO.FCC.CurriculumExpansion.intermediate-python-contact-book.contactbook",
        "description": "_REPO.FCC.CurriculumExpansion.intermediate-python-contact-book.contactbook",
        "peekOfCode": "def main():\n    contactbook = Application(\"contactbook.db\")\n    choice = \"\"\n    while choice != \"7\":\n        print(contactbook)\n        choice = input(\"Choose: \")\n        if choice == \"1\":\n            contactbook.add()\n        elif choice == \"2\":\n            contactbook.viewall()",
        "detail": "_REPO.FCC.CurriculumExpansion.intermediate-python-contact-book.contactbook",
        "documentation": {}
    },
    {
        "label": "df",
        "kind": 5,
        "importPath": "_REPO.FCC.CurriculumExpansion.medical-data-visualizer.visualize_data",
        "description": "_REPO.FCC.CurriculumExpansion.medical-data-visualizer.visualize_data",
        "peekOfCode": "df = pd.read_csv(\"medical_examination.csv\")\ndf_uniques = pd.melt(\n    frame=df,\n    value_vars=[\"gender\", \"cholesterol\", \"gluc\", \"smoke\", \"alco\", \"active\"],\n    id_vars=[\"cardio\"],\n)\ndf_uniques = (\n    pd.DataFrame(df_uniques.groupby([\"variable\", \"value\", \"cardio\"])[\"value\"].count())\n    .sort_index(level=[0, 1])\n    .rename(columns={\"value\": \"count\"})",
        "detail": "_REPO.FCC.CurriculumExpansion.medical-data-visualizer.visualize_data",
        "documentation": {}
    },
    {
        "label": "df_uniques",
        "kind": 5,
        "importPath": "_REPO.FCC.CurriculumExpansion.medical-data-visualizer.visualize_data",
        "description": "_REPO.FCC.CurriculumExpansion.medical-data-visualizer.visualize_data",
        "peekOfCode": "df_uniques = pd.melt(\n    frame=df,\n    value_vars=[\"gender\", \"cholesterol\", \"gluc\", \"smoke\", \"alco\", \"active\"],\n    id_vars=[\"cardio\"],\n)\ndf_uniques = (\n    pd.DataFrame(df_uniques.groupby([\"variable\", \"value\", \"cardio\"])[\"value\"].count())\n    .sort_index(level=[0, 1])\n    .rename(columns={\"value\": \"count\"})\n    .reset_index()",
        "detail": "_REPO.FCC.CurriculumExpansion.medical-data-visualizer.visualize_data",
        "documentation": {}
    },
    {
        "label": "df_uniques",
        "kind": 5,
        "importPath": "_REPO.FCC.CurriculumExpansion.medical-data-visualizer.visualize_data",
        "description": "_REPO.FCC.CurriculumExpansion.medical-data-visualizer.visualize_data",
        "peekOfCode": "df_uniques = (\n    pd.DataFrame(df_uniques.groupby([\"variable\", \"value\", \"cardio\"])[\"value\"].count())\n    .sort_index(level=[0, 1])\n    .rename(columns={\"value\": \"count\"})\n    .reset_index()\n)\nsns.catplot(\n    x=\"variable\", y=\"count\", hue=\"value\", col=\"cardio\", data=df_uniques, kind=\"bar\"\n)\ndf[\"BMI\"] = df[\"weight\"] / (df[\"height\"] / 100) ** 2",
        "detail": "_REPO.FCC.CurriculumExpansion.medical-data-visualizer.visualize_data",
        "documentation": {}
    },
    {
        "label": "df[\"BMI\"]",
        "kind": 5,
        "importPath": "_REPO.FCC.CurriculumExpansion.medical-data-visualizer.visualize_data",
        "description": "_REPO.FCC.CurriculumExpansion.medical-data-visualizer.visualize_data",
        "peekOfCode": "df[\"BMI\"] = df[\"weight\"] / (df[\"height\"] / 100) ** 2\nfiltered_df = df[\n    (df[\"ap_lo\"] <= df[\"ap_hi\"])\n    & (df[\"height\"] >= df[\"height\"].quantile(0.025))\n    & (df[\"height\"] <= df[\"height\"].quantile(0.975))\n    & (df[\"weight\"] >= df[\"weight\"].quantile(0.025))\n    & (df[\"weight\"] <= df[\"weight\"].quantile(0.975))\n]\n# Calculate the correlation matrix\ncorr = filtered_df.corr(method=\"pearson\")",
        "detail": "_REPO.FCC.CurriculumExpansion.medical-data-visualizer.visualize_data",
        "documentation": {}
    },
    {
        "label": "filtered_df",
        "kind": 5,
        "importPath": "_REPO.FCC.CurriculumExpansion.medical-data-visualizer.visualize_data",
        "description": "_REPO.FCC.CurriculumExpansion.medical-data-visualizer.visualize_data",
        "peekOfCode": "filtered_df = df[\n    (df[\"ap_lo\"] <= df[\"ap_hi\"])\n    & (df[\"height\"] >= df[\"height\"].quantile(0.025))\n    & (df[\"height\"] <= df[\"height\"].quantile(0.975))\n    & (df[\"weight\"] >= df[\"weight\"].quantile(0.025))\n    & (df[\"weight\"] <= df[\"weight\"].quantile(0.975))\n]\n# Calculate the correlation matrix\ncorr = filtered_df.corr(method=\"pearson\")\nplt.subplots(figsize=(12, 9))",
        "detail": "_REPO.FCC.CurriculumExpansion.medical-data-visualizer.visualize_data",
        "documentation": {}
    },
    {
        "label": "corr",
        "kind": 5,
        "importPath": "_REPO.FCC.CurriculumExpansion.medical-data-visualizer.visualize_data",
        "description": "_REPO.FCC.CurriculumExpansion.medical-data-visualizer.visualize_data",
        "peekOfCode": "corr = filtered_df.corr(method=\"pearson\")\nplt.subplots(figsize=(12, 9))\nsns.heatmap(corr, annot=True, fmt=\".1f\", square=True)\nplt.show()",
        "detail": "_REPO.FCC.CurriculumExpansion.medical-data-visualizer.visualize_data",
        "documentation": {}
    },
    {
        "label": "Tile",
        "kind": 6,
        "importPath": "_REPO.FCC.CurriculumExpansion.oop-python-minesweeper.minesweeper",
        "description": "_REPO.FCC.CurriculumExpansion.oop-python-minesweeper.minesweeper",
        "peekOfCode": "class Tile:\n    \"\"\"A single tile in the minesweeper grid\"\"\"\n    def __init__(self, displayCharacter):\n        self.displayCharacter = displayCharacter\n        self.isCovered = True\n        self.containsMine = False\n        self.neighboringMineCount = 0\nclass Board:\n    \"\"\"Board class represents a board for the MineSweeper Game\"\"\"\n    def __init__(self):",
        "detail": "_REPO.FCC.CurriculumExpansion.oop-python-minesweeper.minesweeper",
        "documentation": {}
    },
    {
        "label": "Board",
        "kind": 6,
        "importPath": "_REPO.FCC.CurriculumExpansion.oop-python-minesweeper.minesweeper",
        "description": "_REPO.FCC.CurriculumExpansion.oop-python-minesweeper.minesweeper",
        "peekOfCode": "class Board:\n    \"\"\"Board class represents a board for the MineSweeper Game\"\"\"\n    def __init__(self):\n        self.freeTileCount = NUMBER_OF_TILES - NUMBER_OF_MINES\n        self.grid = [Tile(\"😀\") for _ in range(NUMBER_OF_TILES)]\n        self.generateMines()\n        self.calculateNeighboringMines()\n    def generateMines(self):\n        \"\"\"Places mines at random tile positions in the entire grid list\"\"\"\n        for _ in range(NUMBER_OF_MINES):",
        "detail": "_REPO.FCC.CurriculumExpansion.oop-python-minesweeper.minesweeper",
        "documentation": {}
    },
    {
        "label": "Game",
        "kind": 6,
        "importPath": "_REPO.FCC.CurriculumExpansion.oop-python-minesweeper.minesweeper",
        "description": "_REPO.FCC.CurriculumExpansion.oop-python-minesweeper.minesweeper",
        "peekOfCode": "class Game:\n    \"\"\"Represents the minesweeper game using the Board class\"\"\"\n    def __init__(self):\n        self.board = Board()\n        self.GAME_OVER = False\n        self.WIN = False\n    def getUserChoice(self):\n        \"\"\"Get and validate user input\"\"\"\n        while True:\n            userIn = input(f\"Please select a tile between 1 and {NUMBER_OF_TILES}: \")",
        "detail": "_REPO.FCC.CurriculumExpansion.oop-python-minesweeper.minesweeper",
        "documentation": {}
    },
    {
        "label": "ROW_SIZE",
        "kind": 5,
        "importPath": "_REPO.FCC.CurriculumExpansion.oop-python-minesweeper.minesweeper",
        "description": "_REPO.FCC.CurriculumExpansion.oop-python-minesweeper.minesweeper",
        "peekOfCode": "ROW_SIZE = 10\nNUMBER_OF_TILES = ROW_SIZE * ROW_SIZE\nNUMBER_OF_MINES = NUMBER_OF_TILES // 10\nclass Tile:\n    \"\"\"A single tile in the minesweeper grid\"\"\"\n    def __init__(self, displayCharacter):\n        self.displayCharacter = displayCharacter\n        self.isCovered = True\n        self.containsMine = False\n        self.neighboringMineCount = 0",
        "detail": "_REPO.FCC.CurriculumExpansion.oop-python-minesweeper.minesweeper",
        "documentation": {}
    },
    {
        "label": "NUMBER_OF_TILES",
        "kind": 5,
        "importPath": "_REPO.FCC.CurriculumExpansion.oop-python-minesweeper.minesweeper",
        "description": "_REPO.FCC.CurriculumExpansion.oop-python-minesweeper.minesweeper",
        "peekOfCode": "NUMBER_OF_TILES = ROW_SIZE * ROW_SIZE\nNUMBER_OF_MINES = NUMBER_OF_TILES // 10\nclass Tile:\n    \"\"\"A single tile in the minesweeper grid\"\"\"\n    def __init__(self, displayCharacter):\n        self.displayCharacter = displayCharacter\n        self.isCovered = True\n        self.containsMine = False\n        self.neighboringMineCount = 0\nclass Board:",
        "detail": "_REPO.FCC.CurriculumExpansion.oop-python-minesweeper.minesweeper",
        "documentation": {}
    },
    {
        "label": "NUMBER_OF_MINES",
        "kind": 5,
        "importPath": "_REPO.FCC.CurriculumExpansion.oop-python-minesweeper.minesweeper",
        "description": "_REPO.FCC.CurriculumExpansion.oop-python-minesweeper.minesweeper",
        "peekOfCode": "NUMBER_OF_MINES = NUMBER_OF_TILES // 10\nclass Tile:\n    \"\"\"A single tile in the minesweeper grid\"\"\"\n    def __init__(self, displayCharacter):\n        self.displayCharacter = displayCharacter\n        self.isCovered = True\n        self.containsMine = False\n        self.neighboringMineCount = 0\nclass Board:\n    \"\"\"Board class represents a board for the MineSweeper Game\"\"\"",
        "detail": "_REPO.FCC.CurriculumExpansion.oop-python-minesweeper.minesweeper",
        "documentation": {}
    },
    {
        "label": "game",
        "kind": 5,
        "importPath": "_REPO.FCC.CurriculumExpansion.oop-python-minesweeper.minesweeper",
        "description": "_REPO.FCC.CurriculumExpansion.oop-python-minesweeper.minesweeper",
        "peekOfCode": "game = Game()\ngame.run()",
        "detail": "_REPO.FCC.CurriculumExpansion.oop-python-minesweeper.minesweeper",
        "documentation": {}
    },
    {
        "label": "move",
        "kind": 2,
        "importPath": "_REPO.FCC.CurriculumExpansion.recursion-hanoi.hanoi",
        "description": "_REPO.FCC.CurriculumExpansion.recursion-hanoi.hanoi",
        "peekOfCode": "def move(n, source, target, auxiliary):\n    if n > 0:\n        # move n - 1 disks from source to auxiliary, so they are out of the way\n        move(n - 1, source, auxiliary, target)\n        # move the nth disk from source to target\n        target.append(source.pop())\n        # Display our progress\n        print(A, B, C, \"--------------\", sep=\"\\n\")\n        # move the n - 1 disks that we left on auxiliary onto target\n        move(n - 1, auxiliary, target, source)",
        "detail": "_REPO.FCC.CurriculumExpansion.recursion-hanoi.hanoi",
        "documentation": {}
    },
    {
        "label": "NUMBER_OF_DISKS",
        "kind": 5,
        "importPath": "_REPO.FCC.CurriculumExpansion.recursion-hanoi.hanoi",
        "description": "_REPO.FCC.CurriculumExpansion.recursion-hanoi.hanoi",
        "peekOfCode": "NUMBER_OF_DISKS = 5\nA = list(range(NUMBER_OF_DISKS, 0, -1))\nB = []\nC = []\ndef move(n, source, target, auxiliary):\n    if n > 0:\n        # move n - 1 disks from source to auxiliary, so they are out of the way\n        move(n - 1, source, auxiliary, target)\n        # move the nth disk from source to target\n        target.append(source.pop())",
        "detail": "_REPO.FCC.CurriculumExpansion.recursion-hanoi.hanoi",
        "documentation": {}
    },
    {
        "label": "A",
        "kind": 5,
        "importPath": "_REPO.FCC.CurriculumExpansion.recursion-hanoi.hanoi",
        "description": "_REPO.FCC.CurriculumExpansion.recursion-hanoi.hanoi",
        "peekOfCode": "A = list(range(NUMBER_OF_DISKS, 0, -1))\nB = []\nC = []\ndef move(n, source, target, auxiliary):\n    if n > 0:\n        # move n - 1 disks from source to auxiliary, so they are out of the way\n        move(n - 1, source, auxiliary, target)\n        # move the nth disk from source to target\n        target.append(source.pop())\n        # Display our progress",
        "detail": "_REPO.FCC.CurriculumExpansion.recursion-hanoi.hanoi",
        "documentation": {}
    },
    {
        "label": "B",
        "kind": 5,
        "importPath": "_REPO.FCC.CurriculumExpansion.recursion-hanoi.hanoi",
        "description": "_REPO.FCC.CurriculumExpansion.recursion-hanoi.hanoi",
        "peekOfCode": "B = []\nC = []\ndef move(n, source, target, auxiliary):\n    if n > 0:\n        # move n - 1 disks from source to auxiliary, so they are out of the way\n        move(n - 1, source, auxiliary, target)\n        # move the nth disk from source to target\n        target.append(source.pop())\n        # Display our progress\n        print(A, B, C, \"--------------\", sep=\"\\n\")",
        "detail": "_REPO.FCC.CurriculumExpansion.recursion-hanoi.hanoi",
        "documentation": {}
    },
    {
        "label": "C",
        "kind": 5,
        "importPath": "_REPO.FCC.CurriculumExpansion.recursion-hanoi.hanoi",
        "description": "_REPO.FCC.CurriculumExpansion.recursion-hanoi.hanoi",
        "peekOfCode": "C = []\ndef move(n, source, target, auxiliary):\n    if n > 0:\n        # move n - 1 disks from source to auxiliary, so they are out of the way\n        move(n - 1, source, auxiliary, target)\n        # move the nth disk from source to target\n        target.append(source.pop())\n        # Display our progress\n        print(A, B, C, \"--------------\", sep=\"\\n\")\n        # move the n - 1 disks that we left on auxiliary onto target",
        "detail": "_REPO.FCC.CurriculumExpansion.recursion-hanoi.hanoi",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "_REPO.FCC.mail-for-good.tools.setup.initial_setup",
        "description": "_REPO.FCC.mail-for-good.tools.setup.initial_setup",
        "peekOfCode": "def main():\n    # Cancel if a .env file exists\n    if os.path.exists(\"../../.env\"):\n        return\n    # Should probably verify that all variables are declared here\n    # At this stage, the .env file is incorrect.\n    print(\n        \"\"\"\\033[93m\n    |==========================================================================================================|\n    | This is a short guide for setting up M4G. We'll check a few things to ensure you have things configured. |",
        "detail": "_REPO.FCC.mail-for-good.tools.setup.initial_setup",
        "documentation": {}
    },
    {
        "label": "template_m4g",
        "kind": 5,
        "importPath": "_REPO.FCC.mail-for-good.tools.setup.initial_setup",
        "description": "_REPO.FCC.mail-for-good.tools.setup.initial_setup",
        "peekOfCode": "template_m4g = Template(\"\\033[37m $str \\033[32m\")\ndef main():\n    # Cancel if a .env file exists\n    if os.path.exists(\"../../.env\"):\n        return\n    # Should probably verify that all variables are declared here\n    # At this stage, the .env file is incorrect.\n    print(\n        \"\"\"\\033[93m\n    |==========================================================================================================|",
        "detail": "_REPO.FCC.mail-for-good.tools.setup.initial_setup",
        "documentation": {}
    },
    {
        "label": "fail",
        "kind": 2,
        "importPath": "_REPO.GITHUB.codescanning-jira-integration.cli",
        "description": "_REPO.GITHUB.codescanning-jira-integration.cli",
        "peekOfCode": "def fail(msg):\n    print(msg)\n    sys.exit(1)\ndef direction_str_to_num(dstr):\n    if dstr == \"gh2jira\":\n        return DIRECTION_G2J\n    elif dstr == \"jira2gh\":\n        return DIRECTION_J2G\n    elif dstr == \"both\":\n        return DIRECTION_BOTH",
        "detail": "_REPO.GITHUB.codescanning-jira-integration.cli",
        "documentation": {}
    },
    {
        "label": "direction_str_to_num",
        "kind": 2,
        "importPath": "_REPO.GITHUB.codescanning-jira-integration.cli",
        "description": "_REPO.GITHUB.codescanning-jira-integration.cli",
        "peekOfCode": "def direction_str_to_num(dstr):\n    if dstr == \"gh2jira\":\n        return DIRECTION_G2J\n    elif dstr == \"jira2gh\":\n        return DIRECTION_J2G\n    elif dstr == \"both\":\n        return DIRECTION_BOTH\n    else:\n        fail('Unknown direction argument \"{direction}\"!'.format(direction=dstr))\ndef serve(args):",
        "detail": "_REPO.GITHUB.codescanning-jira-integration.cli",
        "documentation": {}
    },
    {
        "label": "serve",
        "kind": 2,
        "importPath": "_REPO.GITHUB.codescanning-jira-integration.cli",
        "description": "_REPO.GITHUB.codescanning-jira-integration.cli",
        "peekOfCode": "def serve(args):\n    if not args.gh_url or not args.jira_url:\n        fail(\"Both GitHub and JIRA URL have to be specified!\")\n    if not args.gh_token:\n        fail(\"No GitHub token specified!\")\n    if not args.jira_user or not args.jira_token:\n        fail(\"No JIRA credentials specified!\")\n    if not args.jira_project:\n        fail(\"No JIRA project specified!\")\n    if not args.secret:",
        "detail": "_REPO.GITHUB.codescanning-jira-integration.cli",
        "documentation": {}
    },
    {
        "label": "sync",
        "kind": 2,
        "importPath": "_REPO.GITHUB.codescanning-jira-integration.cli",
        "description": "_REPO.GITHUB.codescanning-jira-integration.cli",
        "peekOfCode": "def sync(args):\n    if not args.gh_url or not args.jira_url:\n        fail(\"Both GitHub and JIRA URL have to be specified!\")\n    if not args.gh_token:\n        fail(\"No GitHub credentials specified!\")\n    if not args.jira_user or not args.jira_token:\n        fail(\"No JIRA credentials specified!\")\n    if not args.jira_project:\n        fail(\"No JIRA project specified!\")\n    if not args.gh_org:",
        "detail": "_REPO.GITHUB.codescanning-jira-integration.cli",
        "documentation": {}
    },
    {
        "label": "check_hooks",
        "kind": 2,
        "importPath": "_REPO.GITHUB.codescanning-jira-integration.cli",
        "description": "_REPO.GITHUB.codescanning-jira-integration.cli",
        "peekOfCode": "def check_hooks(args):\n    pass\ndef install_hooks(args):\n    if not args.hook_url:\n        fail(\"No hook URL specified!\")\n    if not args.secret:\n        fail(\"No hook secret specified!\")\n    if not args.gh_url and not args.jira_url:\n        fail(\"Neither GitHub nor JIRA URL specified!\")\n    # user wants to install a github hook",
        "detail": "_REPO.GITHUB.codescanning-jira-integration.cli",
        "documentation": {}
    },
    {
        "label": "install_hooks",
        "kind": 2,
        "importPath": "_REPO.GITHUB.codescanning-jira-integration.cli",
        "description": "_REPO.GITHUB.codescanning-jira-integration.cli",
        "peekOfCode": "def install_hooks(args):\n    if not args.hook_url:\n        fail(\"No hook URL specified!\")\n    if not args.secret:\n        fail(\"No hook secret specified!\")\n    if not args.gh_url and not args.jira_url:\n        fail(\"Neither GitHub nor JIRA URL specified!\")\n    # user wants to install a github hook\n    if args.gh_url:\n        if not args.gh_token:",
        "detail": "_REPO.GITHUB.codescanning-jira-integration.cli",
        "documentation": {}
    },
    {
        "label": "list_hooks",
        "kind": 2,
        "importPath": "_REPO.GITHUB.codescanning-jira-integration.cli",
        "description": "_REPO.GITHUB.codescanning-jira-integration.cli",
        "peekOfCode": "def list_hooks(args):\n    if not args.gh_url and not args.jira_url:\n        fail(\"Neither GitHub nor JIRA URL specified!\")\n    # user wants to list github hooks\n    if args.gh_url:\n        if not args.gh_token:\n            fail(\"No GitHub token specified!\")\n        if not args.gh_org:\n            fail(\"No GitHub organization specified!\")\n        github = ghlib.GitHub(args.gh_url, args.gh_token)",
        "detail": "_REPO.GITHUB.codescanning-jira-integration.cli",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "_REPO.GITHUB.codescanning-jira-integration.cli",
        "description": "_REPO.GITHUB.codescanning-jira-integration.cli",
        "peekOfCode": "def main():\n    credential_base = argparse.ArgumentParser(add_help=False)\n    credential_base.add_argument(\"--gh-org\", help=\"GitHub organization\")\n    credential_base.add_argument(\"--gh-repo\", help=\"GitHub repository\")\n    credential_base.add_argument(\"--gh-url\", help=\"API URL of GitHub instance\")\n    credential_base.add_argument(\n        \"--gh-token\",\n        help=\"GitHub API token. Alternatively, the GH2JIRA_GH_TOKEN may be set.\",\n        default=os.getenv(\"GH2JIRA_GH_TOKEN\"),\n    )",
        "detail": "_REPO.GITHUB.codescanning-jira-integration.cli",
        "documentation": {}
    },
    {
        "label": "root",
        "kind": 5,
        "importPath": "_REPO.GITHUB.codescanning-jira-integration.cli",
        "description": "_REPO.GITHUB.codescanning-jira-integration.cli",
        "peekOfCode": "root = logging.getLogger()\nroot.setLevel(logging.DEBUG)\nhandler = logging.StreamHandler(sys.stdout)\nhandler.setLevel(logging.DEBUG)\nroot.addHandler(handler)\ndef fail(msg):\n    print(msg)\n    sys.exit(1)\ndef direction_str_to_num(dstr):\n    if dstr == \"gh2jira\":",
        "detail": "_REPO.GITHUB.codescanning-jira-integration.cli",
        "documentation": {}
    },
    {
        "label": "handler",
        "kind": 5,
        "importPath": "_REPO.GITHUB.codescanning-jira-integration.cli",
        "description": "_REPO.GITHUB.codescanning-jira-integration.cli",
        "peekOfCode": "handler = logging.StreamHandler(sys.stdout)\nhandler.setLevel(logging.DEBUG)\nroot.addHandler(handler)\ndef fail(msg):\n    print(msg)\n    sys.exit(1)\ndef direction_str_to_num(dstr):\n    if dstr == \"gh2jira\":\n        return DIRECTION_G2J\n    elif dstr == \"jira2gh\":",
        "detail": "_REPO.GITHUB.codescanning-jira-integration.cli",
        "documentation": {}
    },
    {
        "label": "GitHub",
        "kind": 6,
        "importPath": "_REPO.GITHUB.codescanning-jira-integration.ghlib",
        "description": "_REPO.GITHUB.codescanning-jira-integration.ghlib",
        "peekOfCode": "class GitHub:\n    def __init__(self, url, token):\n        self.url = url\n        self.token = token\n    def default_headers(self):\n        auth = {\"Authorization\": \"token \" + self.token}\n        auth.update(util.json_accept_header())\n        return auth\n    def getRepository(self, repo_id):\n        return GHRepository(self, repo_id)",
        "detail": "_REPO.GITHUB.codescanning-jira-integration.ghlib",
        "documentation": {}
    },
    {
        "label": "GHRepository",
        "kind": 6,
        "importPath": "_REPO.GITHUB.codescanning-jira-integration.ghlib",
        "description": "_REPO.GITHUB.codescanning-jira-integration.ghlib",
        "peekOfCode": "class GHRepository:\n    def __init__(self, github, repo_id):\n        self.gh = github\n        self.repo_id = repo_id\n    def list_hooks(self):\n        return self.gh.list_hooks_helper(self.repo_id)\n    def create_hook(\n        self,\n        url,\n        secret,",
        "detail": "_REPO.GITHUB.codescanning-jira-integration.ghlib",
        "documentation": {}
    },
    {
        "label": "GHAlert",
        "kind": 6,
        "importPath": "_REPO.GITHUB.codescanning-jira-integration.ghlib",
        "description": "_REPO.GITHUB.codescanning-jira-integration.ghlib",
        "peekOfCode": "class GHAlert:\n    def __init__(self, github_repo, json):\n        self.github_repo = github_repo\n        self.gh = github_repo.gh\n        self.json = json\n    def number(self):\n        return int(self.json[\"number\"])\n    def get_state(self):\n        return parse_alert_state(self.json[\"state\"])\n    def adjust_state(self, state):",
        "detail": "_REPO.GITHUB.codescanning-jira-integration.ghlib",
        "documentation": {}
    },
    {
        "label": "parse_alert_state",
        "kind": 2,
        "importPath": "_REPO.GITHUB.codescanning-jira-integration.ghlib",
        "description": "_REPO.GITHUB.codescanning-jira-integration.ghlib",
        "peekOfCode": "def parse_alert_state(state_string):\n    return state_string not in [\"dismissed\", \"fixed\"]",
        "detail": "_REPO.GITHUB.codescanning-jira-integration.ghlib",
        "documentation": {}
    },
    {
        "label": "WEBHOOK_CONFIG",
        "kind": 5,
        "importPath": "_REPO.GITHUB.codescanning-jira-integration.ghlib",
        "description": "_REPO.GITHUB.codescanning-jira-integration.ghlib",
        "peekOfCode": "WEBHOOK_CONFIG = \"\"\"\n{\n    \"url\": \"{url}\",\n    \"content_type\": \"{content_type}\",\n    \"secret\": \"{secret}\",\n    \"insecure_ssl\": \"{insecure_ssl}\",\n    \"events\": \"{envents}\",\n    \"active\": \"{active}\"\n}\n\"\"\"",
        "detail": "_REPO.GITHUB.codescanning-jira-integration.ghlib",
        "documentation": {}
    },
    {
        "label": "RESULTS_PER_PAGE",
        "kind": 5,
        "importPath": "_REPO.GITHUB.codescanning-jira-integration.ghlib",
        "description": "_REPO.GITHUB.codescanning-jira-integration.ghlib",
        "peekOfCode": "RESULTS_PER_PAGE = 100\nlogger = logging.getLogger(__name__)\nclass GitHub:\n    def __init__(self, url, token):\n        self.url = url\n        self.token = token\n    def default_headers(self):\n        auth = {\"Authorization\": \"token \" + self.token}\n        auth.update(util.json_accept_header())\n        return auth",
        "detail": "_REPO.GITHUB.codescanning-jira-integration.ghlib",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "_REPO.GITHUB.codescanning-jira-integration.ghlib",
        "description": "_REPO.GITHUB.codescanning-jira-integration.ghlib",
        "peekOfCode": "logger = logging.getLogger(__name__)\nclass GitHub:\n    def __init__(self, url, token):\n        self.url = url\n        self.token = token\n    def default_headers(self):\n        auth = {\"Authorization\": \"token \" + self.token}\n        auth.update(util.json_accept_header())\n        return auth\n    def getRepository(self, repo_id):",
        "detail": "_REPO.GITHUB.codescanning-jira-integration.ghlib",
        "documentation": {}
    },
    {
        "label": "Jira",
        "kind": 6,
        "importPath": "_REPO.GITHUB.codescanning-jira-integration.jiralib",
        "description": "_REPO.GITHUB.codescanning-jira-integration.jiralib",
        "peekOfCode": "class Jira:\n    def __init__(self, url, user, token):\n        self.url = url\n        self.user = user\n        self.token = token\n        self.j = JIRA(url, basic_auth=(user, token))\n    def auth(self):\n        return self.user, self.token\n    def getProject(self, projectkey):\n        return JiraProject(self, projectkey)",
        "detail": "_REPO.GITHUB.codescanning-jira-integration.jiralib",
        "documentation": {}
    },
    {
        "label": "JiraProject",
        "kind": 6,
        "importPath": "_REPO.GITHUB.codescanning-jira-integration.jiralib",
        "description": "_REPO.GITHUB.codescanning-jira-integration.jiralib",
        "peekOfCode": "class JiraProject:\n    def __init__(self, jira, projectkey):\n        self.jira = jira\n        self.projectkey = projectkey\n        self.j = self.jira.j\n    def get_state_issue(self, issue_key=\"-\"):\n        if issue_key != \"-\":\n            return self.j.issue(issue_key)\n        issue_search = 'project={jira_project} and description ~ \"{key}\"'.format(\n            jira_project='\"{}\"'.format(self.projectkey), key=STATE_ISSUE_KEY",
        "detail": "_REPO.GITHUB.codescanning-jira-integration.jiralib",
        "documentation": {}
    },
    {
        "label": "JiraIssue",
        "kind": 6,
        "importPath": "_REPO.GITHUB.codescanning-jira-integration.jiralib",
        "description": "_REPO.GITHUB.codescanning-jira-integration.jiralib",
        "peekOfCode": "class JiraIssue:\n    def __init__(self, project, rawissue):\n        self.project = project\n        self.rawissue = rawissue\n        self.j = self.project.j\n    def is_managed(self):\n        if parse_alert_info(self.rawissue.fields.description)[0] is None:\n            return False\n        return True\n    def get_alert_info(self):",
        "detail": "_REPO.GITHUB.codescanning-jira-integration.jiralib",
        "documentation": {}
    },
    {
        "label": "parse_alert_info",
        "kind": 2,
        "importPath": "_REPO.GITHUB.codescanning-jira-integration.jiralib",
        "description": "_REPO.GITHUB.codescanning-jira-integration.jiralib",
        "peekOfCode": "def parse_alert_info(desc):\n    \"\"\"\n    Parse all the fields in an issue's description and return\n    them as a tuple. If parsing fails for one of the fields,\n    return a tuple of None's.\n    \"\"\"\n    failed = None, None, None, None\n    m = re.search(\"REPOSITORY_NAME=(.*)$\", desc, re.MULTILINE)\n    if m is None:\n        return failed",
        "detail": "_REPO.GITHUB.codescanning-jira-integration.jiralib",
        "documentation": {}
    },
    {
        "label": "parse_state",
        "kind": 2,
        "importPath": "_REPO.GITHUB.codescanning-jira-integration.jiralib",
        "description": "_REPO.GITHUB.codescanning-jira-integration.jiralib",
        "peekOfCode": "def parse_state(raw_state):\n    return raw_state != CLOSED_STATUS\ndef repo_id_to_fname(repo_id):\n    return repo_id.replace(\"/\", \"^\") + \".json\"",
        "detail": "_REPO.GITHUB.codescanning-jira-integration.jiralib",
        "documentation": {}
    },
    {
        "label": "repo_id_to_fname",
        "kind": 2,
        "importPath": "_REPO.GITHUB.codescanning-jira-integration.jiralib",
        "description": "_REPO.GITHUB.codescanning-jira-integration.jiralib",
        "peekOfCode": "def repo_id_to_fname(repo_id):\n    return repo_id.replace(\"/\", \"^\") + \".json\"",
        "detail": "_REPO.GITHUB.codescanning-jira-integration.jiralib",
        "documentation": {}
    },
    {
        "label": "CLOSE_TRANSITION",
        "kind": 5,
        "importPath": "_REPO.GITHUB.codescanning-jira-integration.jiralib",
        "description": "_REPO.GITHUB.codescanning-jira-integration.jiralib",
        "peekOfCode": "CLOSE_TRANSITION = \"Done\"\nREOPEN_TRANSITION = \"To Do\"\nCLOSED_STATUS = \"Done\"\n# JIRA Webhook events\nUPDATE_EVENT = \"jira:issue_updated\"\nCREATE_EVENT = \"jira:issue_created\"\nDELETE_EVENT = \"jira:issue_deleted\"\nTITLE_PREFIX = \"[Code Scanning Alert]:\"\nDESC_TEMPLATE = \"\"\"\n{rule_desc}",
        "detail": "_REPO.GITHUB.codescanning-jira-integration.jiralib",
        "documentation": {}
    },
    {
        "label": "REOPEN_TRANSITION",
        "kind": 5,
        "importPath": "_REPO.GITHUB.codescanning-jira-integration.jiralib",
        "description": "_REPO.GITHUB.codescanning-jira-integration.jiralib",
        "peekOfCode": "REOPEN_TRANSITION = \"To Do\"\nCLOSED_STATUS = \"Done\"\n# JIRA Webhook events\nUPDATE_EVENT = \"jira:issue_updated\"\nCREATE_EVENT = \"jira:issue_created\"\nDELETE_EVENT = \"jira:issue_deleted\"\nTITLE_PREFIX = \"[Code Scanning Alert]:\"\nDESC_TEMPLATE = \"\"\"\n{rule_desc}\n{alert_url}",
        "detail": "_REPO.GITHUB.codescanning-jira-integration.jiralib",
        "documentation": {}
    },
    {
        "label": "CLOSED_STATUS",
        "kind": 5,
        "importPath": "_REPO.GITHUB.codescanning-jira-integration.jiralib",
        "description": "_REPO.GITHUB.codescanning-jira-integration.jiralib",
        "peekOfCode": "CLOSED_STATUS = \"Done\"\n# JIRA Webhook events\nUPDATE_EVENT = \"jira:issue_updated\"\nCREATE_EVENT = \"jira:issue_created\"\nDELETE_EVENT = \"jira:issue_deleted\"\nTITLE_PREFIX = \"[Code Scanning Alert]:\"\nDESC_TEMPLATE = \"\"\"\n{rule_desc}\n{alert_url}\n----",
        "detail": "_REPO.GITHUB.codescanning-jira-integration.jiralib",
        "documentation": {}
    },
    {
        "label": "UPDATE_EVENT",
        "kind": 5,
        "importPath": "_REPO.GITHUB.codescanning-jira-integration.jiralib",
        "description": "_REPO.GITHUB.codescanning-jira-integration.jiralib",
        "peekOfCode": "UPDATE_EVENT = \"jira:issue_updated\"\nCREATE_EVENT = \"jira:issue_created\"\nDELETE_EVENT = \"jira:issue_deleted\"\nTITLE_PREFIX = \"[Code Scanning Alert]:\"\nDESC_TEMPLATE = \"\"\"\n{rule_desc}\n{alert_url}\n----\nThis issue was automatically generated from a GitHub alert, and will be automatically resolved once the underlying problem is fixed.\nDO NOT MODIFY DESCRIPTION BELOW LINE.",
        "detail": "_REPO.GITHUB.codescanning-jira-integration.jiralib",
        "documentation": {}
    },
    {
        "label": "CREATE_EVENT",
        "kind": 5,
        "importPath": "_REPO.GITHUB.codescanning-jira-integration.jiralib",
        "description": "_REPO.GITHUB.codescanning-jira-integration.jiralib",
        "peekOfCode": "CREATE_EVENT = \"jira:issue_created\"\nDELETE_EVENT = \"jira:issue_deleted\"\nTITLE_PREFIX = \"[Code Scanning Alert]:\"\nDESC_TEMPLATE = \"\"\"\n{rule_desc}\n{alert_url}\n----\nThis issue was automatically generated from a GitHub alert, and will be automatically resolved once the underlying problem is fixed.\nDO NOT MODIFY DESCRIPTION BELOW LINE.\nREPOSITORY_NAME={repo_id}",
        "detail": "_REPO.GITHUB.codescanning-jira-integration.jiralib",
        "documentation": {}
    },
    {
        "label": "DELETE_EVENT",
        "kind": 5,
        "importPath": "_REPO.GITHUB.codescanning-jira-integration.jiralib",
        "description": "_REPO.GITHUB.codescanning-jira-integration.jiralib",
        "peekOfCode": "DELETE_EVENT = \"jira:issue_deleted\"\nTITLE_PREFIX = \"[Code Scanning Alert]:\"\nDESC_TEMPLATE = \"\"\"\n{rule_desc}\n{alert_url}\n----\nThis issue was automatically generated from a GitHub alert, and will be automatically resolved once the underlying problem is fixed.\nDO NOT MODIFY DESCRIPTION BELOW LINE.\nREPOSITORY_NAME={repo_id}\nALERT_NUMBER={alert_num}",
        "detail": "_REPO.GITHUB.codescanning-jira-integration.jiralib",
        "documentation": {}
    },
    {
        "label": "TITLE_PREFIX",
        "kind": 5,
        "importPath": "_REPO.GITHUB.codescanning-jira-integration.jiralib",
        "description": "_REPO.GITHUB.codescanning-jira-integration.jiralib",
        "peekOfCode": "TITLE_PREFIX = \"[Code Scanning Alert]:\"\nDESC_TEMPLATE = \"\"\"\n{rule_desc}\n{alert_url}\n----\nThis issue was automatically generated from a GitHub alert, and will be automatically resolved once the underlying problem is fixed.\nDO NOT MODIFY DESCRIPTION BELOW LINE.\nREPOSITORY_NAME={repo_id}\nALERT_NUMBER={alert_num}\nREPOSITORY_KEY={repo_key}",
        "detail": "_REPO.GITHUB.codescanning-jira-integration.jiralib",
        "documentation": {}
    },
    {
        "label": "DESC_TEMPLATE",
        "kind": 5,
        "importPath": "_REPO.GITHUB.codescanning-jira-integration.jiralib",
        "description": "_REPO.GITHUB.codescanning-jira-integration.jiralib",
        "peekOfCode": "DESC_TEMPLATE = \"\"\"\n{rule_desc}\n{alert_url}\n----\nThis issue was automatically generated from a GitHub alert, and will be automatically resolved once the underlying problem is fixed.\nDO NOT MODIFY DESCRIPTION BELOW LINE.\nREPOSITORY_NAME={repo_id}\nALERT_NUMBER={alert_num}\nREPOSITORY_KEY={repo_key}\nALERT_KEY={alert_key}",
        "detail": "_REPO.GITHUB.codescanning-jira-integration.jiralib",
        "documentation": {}
    },
    {
        "label": "STATE_ISSUE_SUMMARY",
        "kind": 5,
        "importPath": "_REPO.GITHUB.codescanning-jira-integration.jiralib",
        "description": "_REPO.GITHUB.codescanning-jira-integration.jiralib",
        "peekOfCode": "STATE_ISSUE_SUMMARY = \"[Code Scanning Issue States]\"\nSTATE_ISSUE_KEY = util.make_key(\"gh2jira-state-issue\")\nSTATE_ISSUE_TEMPLATE = \"\"\"\nThis issue was automatically generated and contains states required for the synchronization between GitHub and JIRA.\nDO NOT MODIFY DESCRIPTION BELOW LINE.\nISSUE_KEY={issue_key}\n\"\"\".format(\n    issue_key=STATE_ISSUE_KEY\n)\nlogger = logging.getLogger(__name__)",
        "detail": "_REPO.GITHUB.codescanning-jira-integration.jiralib",
        "documentation": {}
    },
    {
        "label": "STATE_ISSUE_KEY",
        "kind": 5,
        "importPath": "_REPO.GITHUB.codescanning-jira-integration.jiralib",
        "description": "_REPO.GITHUB.codescanning-jira-integration.jiralib",
        "peekOfCode": "STATE_ISSUE_KEY = util.make_key(\"gh2jira-state-issue\")\nSTATE_ISSUE_TEMPLATE = \"\"\"\nThis issue was automatically generated and contains states required for the synchronization between GitHub and JIRA.\nDO NOT MODIFY DESCRIPTION BELOW LINE.\nISSUE_KEY={issue_key}\n\"\"\".format(\n    issue_key=STATE_ISSUE_KEY\n)\nlogger = logging.getLogger(__name__)\nclass Jira:",
        "detail": "_REPO.GITHUB.codescanning-jira-integration.jiralib",
        "documentation": {}
    },
    {
        "label": "STATE_ISSUE_TEMPLATE",
        "kind": 5,
        "importPath": "_REPO.GITHUB.codescanning-jira-integration.jiralib",
        "description": "_REPO.GITHUB.codescanning-jira-integration.jiralib",
        "peekOfCode": "STATE_ISSUE_TEMPLATE = \"\"\"\nThis issue was automatically generated and contains states required for the synchronization between GitHub and JIRA.\nDO NOT MODIFY DESCRIPTION BELOW LINE.\nISSUE_KEY={issue_key}\n\"\"\".format(\n    issue_key=STATE_ISSUE_KEY\n)\nlogger = logging.getLogger(__name__)\nclass Jira:\n    def __init__(self, url, user, token):",
        "detail": "_REPO.GITHUB.codescanning-jira-integration.jiralib",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "_REPO.GITHUB.codescanning-jira-integration.jiralib",
        "description": "_REPO.GITHUB.codescanning-jira-integration.jiralib",
        "peekOfCode": "logger = logging.getLogger(__name__)\nclass Jira:\n    def __init__(self, url, user, token):\n        self.url = url\n        self.user = user\n        self.token = token\n        self.j = JIRA(url, basic_auth=(user, token))\n    def auth(self):\n        return self.user, self.token\n    def getProject(self, projectkey):",
        "detail": "_REPO.GITHUB.codescanning-jira-integration.jiralib",
        "documentation": {}
    },
    {
        "label": "run_server",
        "kind": 2,
        "importPath": "_REPO.GITHUB.codescanning-jira-integration.server",
        "description": "_REPO.GITHUB.codescanning-jira-integration.server",
        "peekOfCode": "def run_server(\n    sync_object, webhook_secret, repository_sync_interval=60 * 60 * 24, port=5000\n):\n    global sync\n    sync = sync_object\n    global secret\n    secret = webhook_secret.encode(\"utf-8\")\n    global repo_sync_interval\n    repo_sync_interval = repository_sync_interval\n    app.run(port=port)",
        "detail": "_REPO.GITHUB.codescanning-jira-integration.server",
        "documentation": {}
    },
    {
        "label": "auth_is_valid",
        "kind": 2,
        "importPath": "_REPO.GITHUB.codescanning-jira-integration.server",
        "description": "_REPO.GITHUB.codescanning-jira-integration.server",
        "peekOfCode": "def auth_is_valid(signature, request_body):\n    if app.debug:\n        return True\n    return hmac.compare_digest(\n        signature.encode(\"utf-8\"),\n        (\"sha256=\" + hmac.new(secret, request_body, hashlib.sha256).hexdigest()).encode(\n            \"utf-8\"\n        ),\n    )\n@app.route(\"/jira\", methods=[\"POST\"])",
        "detail": "_REPO.GITHUB.codescanning-jira-integration.server",
        "documentation": {}
    },
    {
        "label": "jira_webhook",
        "kind": 2,
        "importPath": "_REPO.GITHUB.codescanning-jira-integration.server",
        "description": "_REPO.GITHUB.codescanning-jira-integration.server",
        "peekOfCode": "def jira_webhook():\n    \"\"\"Handle POST requests coming from JIRA, and pass a translated request to GitHub\"\"\"\n    if not hmac.compare_digest(\n        request.args.get(\"secret_token\", \"\").encode(\"utf-8\"), secret\n    ):\n        return jsonify({\"code\": 403, \"error\": \"Unauthorized\"}), 403\n    payload = json.loads(request.data.decode(\"utf-8\"))\n    event = payload[\"webhookEvent\"]\n    desc = payload[\"issue\"][\"fields\"][\"description\"]\n    repo_id, alert_id, _, _ = jiralib.parse_alert_info(desc)",
        "detail": "_REPO.GITHUB.codescanning-jira-integration.server",
        "documentation": {}
    },
    {
        "label": "github_webhook",
        "kind": 2,
        "importPath": "_REPO.GITHUB.codescanning-jira-integration.server",
        "description": "_REPO.GITHUB.codescanning-jira-integration.server",
        "peekOfCode": "def github_webhook():\n    \"\"\"\n    Handle POST requests coming from GitHub, and pass a translated request to JIRA\n    By default, flask runs in single-threaded mode, so we don't need to worry about\n    any race conditions.\n    \"\"\"\n    app.logger.debug(\n        'Received GITHUB webhook for event \"{event}\"'.format(\n            event=request.headers.get(\"X-GitHub-Event\", \"\")\n        )",
        "detail": "_REPO.GITHUB.codescanning-jira-integration.server",
        "documentation": {}
    },
    {
        "label": "sync",
        "kind": 5,
        "importPath": "_REPO.GITHUB.codescanning-jira-integration.server",
        "description": "_REPO.GITHUB.codescanning-jira-integration.server",
        "peekOfCode": "sync = None\nrepo_sync_interval = None\napp = Flask(__name__)\nsync_lock = threading.Lock()\nlast_repo_syncs = {}\nsecret = None\ndef run_server(\n    sync_object, webhook_secret, repository_sync_interval=60 * 60 * 24, port=5000\n):\n    global sync",
        "detail": "_REPO.GITHUB.codescanning-jira-integration.server",
        "documentation": {}
    },
    {
        "label": "repo_sync_interval",
        "kind": 5,
        "importPath": "_REPO.GITHUB.codescanning-jira-integration.server",
        "description": "_REPO.GITHUB.codescanning-jira-integration.server",
        "peekOfCode": "repo_sync_interval = None\napp = Flask(__name__)\nsync_lock = threading.Lock()\nlast_repo_syncs = {}\nsecret = None\ndef run_server(\n    sync_object, webhook_secret, repository_sync_interval=60 * 60 * 24, port=5000\n):\n    global sync\n    sync = sync_object",
        "detail": "_REPO.GITHUB.codescanning-jira-integration.server",
        "documentation": {}
    },
    {
        "label": "app",
        "kind": 5,
        "importPath": "_REPO.GITHUB.codescanning-jira-integration.server",
        "description": "_REPO.GITHUB.codescanning-jira-integration.server",
        "peekOfCode": "app = Flask(__name__)\nsync_lock = threading.Lock()\nlast_repo_syncs = {}\nsecret = None\ndef run_server(\n    sync_object, webhook_secret, repository_sync_interval=60 * 60 * 24, port=5000\n):\n    global sync\n    sync = sync_object\n    global secret",
        "detail": "_REPO.GITHUB.codescanning-jira-integration.server",
        "documentation": {}
    },
    {
        "label": "sync_lock",
        "kind": 5,
        "importPath": "_REPO.GITHUB.codescanning-jira-integration.server",
        "description": "_REPO.GITHUB.codescanning-jira-integration.server",
        "peekOfCode": "sync_lock = threading.Lock()\nlast_repo_syncs = {}\nsecret = None\ndef run_server(\n    sync_object, webhook_secret, repository_sync_interval=60 * 60 * 24, port=5000\n):\n    global sync\n    sync = sync_object\n    global secret\n    secret = webhook_secret.encode(\"utf-8\")",
        "detail": "_REPO.GITHUB.codescanning-jira-integration.server",
        "documentation": {}
    },
    {
        "label": "last_repo_syncs",
        "kind": 5,
        "importPath": "_REPO.GITHUB.codescanning-jira-integration.server",
        "description": "_REPO.GITHUB.codescanning-jira-integration.server",
        "peekOfCode": "last_repo_syncs = {}\nsecret = None\ndef run_server(\n    sync_object, webhook_secret, repository_sync_interval=60 * 60 * 24, port=5000\n):\n    global sync\n    sync = sync_object\n    global secret\n    secret = webhook_secret.encode(\"utf-8\")\n    global repo_sync_interval",
        "detail": "_REPO.GITHUB.codescanning-jira-integration.server",
        "documentation": {}
    },
    {
        "label": "secret",
        "kind": 5,
        "importPath": "_REPO.GITHUB.codescanning-jira-integration.server",
        "description": "_REPO.GITHUB.codescanning-jira-integration.server",
        "peekOfCode": "secret = None\ndef run_server(\n    sync_object, webhook_secret, repository_sync_interval=60 * 60 * 24, port=5000\n):\n    global sync\n    sync = sync_object\n    global secret\n    secret = webhook_secret.encode(\"utf-8\")\n    global repo_sync_interval\n    repo_sync_interval = repository_sync_interval",
        "detail": "_REPO.GITHUB.codescanning-jira-integration.server",
        "documentation": {}
    },
    {
        "label": "Sync",
        "kind": 6,
        "importPath": "_REPO.GITHUB.codescanning-jira-integration.sync",
        "description": "_REPO.GITHUB.codescanning-jira-integration.sync",
        "peekOfCode": "class Sync:\n    def __init__(self, github, jira_project, direction=DIRECTION_BOTH):\n        self.github = github\n        self.jira = jira_project\n        self.direction = direction\n    def alert_created(self, repo_id, alert_num):\n        self.sync(\n            self.github.getRepository(repo_id).get_alert(alert_num),\n            self.jira.fetch_issues(repo_id, alert_num),\n            DIRECTION_G2J,",
        "detail": "_REPO.GITHUB.codescanning-jira-integration.sync",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "_REPO.GITHUB.codescanning-jira-integration.sync",
        "description": "_REPO.GITHUB.codescanning-jira-integration.sync",
        "peekOfCode": "logger = logging.getLogger(__name__)\nDIRECTION_G2J = 1\nDIRECTION_J2G = 2\nDIRECTION_BOTH = 3\nclass Sync:\n    def __init__(self, github, jira_project, direction=DIRECTION_BOTH):\n        self.github = github\n        self.jira = jira_project\n        self.direction = direction\n    def alert_created(self, repo_id, alert_num):",
        "detail": "_REPO.GITHUB.codescanning-jira-integration.sync",
        "documentation": {}
    },
    {
        "label": "DIRECTION_G2J",
        "kind": 5,
        "importPath": "_REPO.GITHUB.codescanning-jira-integration.sync",
        "description": "_REPO.GITHUB.codescanning-jira-integration.sync",
        "peekOfCode": "DIRECTION_G2J = 1\nDIRECTION_J2G = 2\nDIRECTION_BOTH = 3\nclass Sync:\n    def __init__(self, github, jira_project, direction=DIRECTION_BOTH):\n        self.github = github\n        self.jira = jira_project\n        self.direction = direction\n    def alert_created(self, repo_id, alert_num):\n        self.sync(",
        "detail": "_REPO.GITHUB.codescanning-jira-integration.sync",
        "documentation": {}
    },
    {
        "label": "DIRECTION_J2G",
        "kind": 5,
        "importPath": "_REPO.GITHUB.codescanning-jira-integration.sync",
        "description": "_REPO.GITHUB.codescanning-jira-integration.sync",
        "peekOfCode": "DIRECTION_J2G = 2\nDIRECTION_BOTH = 3\nclass Sync:\n    def __init__(self, github, jira_project, direction=DIRECTION_BOTH):\n        self.github = github\n        self.jira = jira_project\n        self.direction = direction\n    def alert_created(self, repo_id, alert_num):\n        self.sync(\n            self.github.getRepository(repo_id).get_alert(alert_num),",
        "detail": "_REPO.GITHUB.codescanning-jira-integration.sync",
        "documentation": {}
    },
    {
        "label": "DIRECTION_BOTH",
        "kind": 5,
        "importPath": "_REPO.GITHUB.codescanning-jira-integration.sync",
        "description": "_REPO.GITHUB.codescanning-jira-integration.sync",
        "peekOfCode": "DIRECTION_BOTH = 3\nclass Sync:\n    def __init__(self, github, jira_project, direction=DIRECTION_BOTH):\n        self.github = github\n        self.jira = jira_project\n        self.direction = direction\n    def alert_created(self, repo_id, alert_num):\n        self.sync(\n            self.github.getRepository(repo_id).get_alert(alert_num),\n            self.jira.fetch_issues(repo_id, alert_num),",
        "detail": "_REPO.GITHUB.codescanning-jira-integration.sync",
        "documentation": {}
    },
    {
        "label": "state_from_json",
        "kind": 2,
        "importPath": "_REPO.GITHUB.codescanning-jira-integration.util",
        "description": "_REPO.GITHUB.codescanning-jira-integration.util",
        "peekOfCode": "def state_from_json(s):\n    # convert string keys into int keys\n    # this is necessary because JSON doesn't allow\n    # int keys and json.dump() automatically converts\n    # int keys into string keys.\n    return {int(k): v for k, v in json.loads(s).items()}\ndef state_to_json(state):\n    return json.dumps(state, indent=2, sort_keys=True)\ndef state_from_file(fpath):\n    if os.path.isfile(fpath):",
        "detail": "_REPO.GITHUB.codescanning-jira-integration.util",
        "documentation": {}
    },
    {
        "label": "state_to_json",
        "kind": 2,
        "importPath": "_REPO.GITHUB.codescanning-jira-integration.util",
        "description": "_REPO.GITHUB.codescanning-jira-integration.util",
        "peekOfCode": "def state_to_json(state):\n    return json.dumps(state, indent=2, sort_keys=True)\ndef state_from_file(fpath):\n    if os.path.isfile(fpath):\n        with open(fpath, \"r\") as f:\n            return state_from_json(f.read())\n    return {}\ndef state_to_file(fpath, state):\n    with open(fpath, \"w\") as f:\n        f.write(state_to_json(state))",
        "detail": "_REPO.GITHUB.codescanning-jira-integration.util",
        "documentation": {}
    },
    {
        "label": "state_from_file",
        "kind": 2,
        "importPath": "_REPO.GITHUB.codescanning-jira-integration.util",
        "description": "_REPO.GITHUB.codescanning-jira-integration.util",
        "peekOfCode": "def state_from_file(fpath):\n    if os.path.isfile(fpath):\n        with open(fpath, \"r\") as f:\n            return state_from_json(f.read())\n    return {}\ndef state_to_file(fpath, state):\n    with open(fpath, \"w\") as f:\n        f.write(state_to_json(state))\ndef make_key(s):\n    sha_1 = hashlib.sha1()",
        "detail": "_REPO.GITHUB.codescanning-jira-integration.util",
        "documentation": {}
    },
    {
        "label": "state_to_file",
        "kind": 2,
        "importPath": "_REPO.GITHUB.codescanning-jira-integration.util",
        "description": "_REPO.GITHUB.codescanning-jira-integration.util",
        "peekOfCode": "def state_to_file(fpath, state):\n    with open(fpath, \"w\") as f:\n        f.write(state_to_json(state))\ndef make_key(s):\n    sha_1 = hashlib.sha1()\n    sha_1.update(s.encode(\"utf-8\"))\n    return sha_1.hexdigest()\ndef make_alert_key(repo_id, alert_num):\n    return make_key(repo_id + \"/\" + str(alert_num))\ndef json_accept_header():",
        "detail": "_REPO.GITHUB.codescanning-jira-integration.util",
        "documentation": {}
    },
    {
        "label": "make_key",
        "kind": 2,
        "importPath": "_REPO.GITHUB.codescanning-jira-integration.util",
        "description": "_REPO.GITHUB.codescanning-jira-integration.util",
        "peekOfCode": "def make_key(s):\n    sha_1 = hashlib.sha1()\n    sha_1.update(s.encode(\"utf-8\"))\n    return sha_1.hexdigest()\ndef make_alert_key(repo_id, alert_num):\n    return make_key(repo_id + \"/\" + str(alert_num))\ndef json_accept_header():\n    return {\"Accept\": \"application/vnd.github.v3+json\"}",
        "detail": "_REPO.GITHUB.codescanning-jira-integration.util",
        "documentation": {}
    },
    {
        "label": "make_alert_key",
        "kind": 2,
        "importPath": "_REPO.GITHUB.codescanning-jira-integration.util",
        "description": "_REPO.GITHUB.codescanning-jira-integration.util",
        "peekOfCode": "def make_alert_key(repo_id, alert_num):\n    return make_key(repo_id + \"/\" + str(alert_num))\ndef json_accept_header():\n    return {\"Accept\": \"application/vnd.github.v3+json\"}",
        "detail": "_REPO.GITHUB.codescanning-jira-integration.util",
        "documentation": {}
    },
    {
        "label": "json_accept_header",
        "kind": 2,
        "importPath": "_REPO.GITHUB.codescanning-jira-integration.util",
        "description": "_REPO.GITHUB.codescanning-jira-integration.util",
        "peekOfCode": "def json_accept_header():\n    return {\"Accept\": \"application/vnd.github.v3+json\"}",
        "detail": "_REPO.GITHUB.codescanning-jira-integration.util",
        "documentation": {}
    },
    {
        "label": "REQUEST_TIMEOUT",
        "kind": 5,
        "importPath": "_REPO.GITHUB.codescanning-jira-integration.util",
        "description": "_REPO.GITHUB.codescanning-jira-integration.util",
        "peekOfCode": "REQUEST_TIMEOUT = 10\ndef state_from_json(s):\n    # convert string keys into int keys\n    # this is necessary because JSON doesn't allow\n    # int keys and json.dump() automatically converts\n    # int keys into string keys.\n    return {int(k): v for k, v in json.loads(s).items()}\ndef state_to_json(state):\n    return json.dumps(state, indent=2, sort_keys=True)\ndef state_from_file(fpath):",
        "detail": "_REPO.GITHUB.codescanning-jira-integration.util",
        "documentation": {}
    },
    {
        "label": "strip_c_style_comment_delimiters",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.parsers.commentutils",
        "description": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.parsers.commentutils",
        "peekOfCode": "def strip_c_style_comment_delimiters(comment: str) -> str:\n    comment_lines = comment.split(\"\\n\")\n    cleaned_lines = []\n    for l in comment_lines:\n        l = l.strip()\n        if l.endswith(\"*/\"):\n            l = l[:-2]\n        if l.startswith(\"*\"):\n            l = l[1:]\n        elif l.startswith(\"/**\"):",
        "detail": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.parsers.commentutils",
        "documentation": {}
    },
    {
        "label": "get_docstring_summary",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.parsers.commentutils",
        "description": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.parsers.commentutils",
        "peekOfCode": "def get_docstring_summary(docstring: str) -> str:\n    \"\"\"Get the first lines of the documentation comment up to the empty lines.\"\"\"\n    if \"\\n\\n\" in docstring:\n        return docstring.split(\"\\n\\n\")[0]\n    elif \"@\" in docstring:\n        return docstring[\n            : docstring.find(\"@\")\n        ]  # This usually is the start of a JavaDoc-style @param comment.\n    return docstring",
        "detail": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.parsers.commentutils",
        "documentation": {}
    },
    {
        "label": "GoParser",
        "kind": 6,
        "importPath": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.parsers.go_parser",
        "description": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.parsers.go_parser",
        "peekOfCode": "class GoParser(LanguageParser):\n    FILTER_PATHS = (\"test\", \"vendor\")\n    @staticmethod\n    def get_definition(tree, blob: str) -> List[Dict[str, Any]]:\n        definitions = []\n        comment_buffer = []\n        for child in tree.root_node.children:\n            if child.type == \"comment\":\n                comment_buffer.append(child)\n            elif child.type in (\"method_declaration\", \"function_declaration\"):",
        "detail": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.parsers.go_parser",
        "documentation": {}
    },
    {
        "label": "JavascriptParser",
        "kind": 6,
        "importPath": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.parsers.javascript_parser",
        "description": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.parsers.javascript_parser",
        "peekOfCode": "class JavascriptParser(LanguageParser):\n    FILTER_PATHS = (\"test\", \"node_modules\")\n    BLACKLISTED_FUNCTION_NAMES = {\"toString\", \"toLocaleString\", \"valueOf\"}\n    @staticmethod\n    def get_docstring(tree, node, blob: str) -> str:\n        docstring = \"\"\n        parent_node = node_parent(tree, node)\n        if parent_node.type == \"variable_declarator\":\n            base_node = node_parent(tree, parent_node)  # Get the variable declaration\n        elif parent_node.type == \"pair\":",
        "detail": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.parsers.javascript_parser",
        "documentation": {}
    },
    {
        "label": "JavaParser",
        "kind": 6,
        "importPath": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.parsers.java_parser",
        "description": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.parsers.java_parser",
        "peekOfCode": "class JavaParser(LanguageParser):\n    FILTER_PATHS = (\"test\", \"tests\")\n    BLACKLISTED_FUNCTION_NAMES = {\n        \"toString\",\n        \"hashCode\",\n        \"equals\",\n        \"finalize\",\n        \"notify\",\n        \"notifyAll\",\n        \"clone\",",
        "detail": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.parsers.java_parser",
        "documentation": {}
    },
    {
        "label": "LanguageParser",
        "kind": 6,
        "importPath": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.parsers.language_parser",
        "description": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.parsers.language_parser",
        "peekOfCode": "class LanguageParser(ABC):\n    @staticmethod\n    @abstractmethod\n    def get_definition(tree, blob: str) -> List[Dict[str, Any]]:\n        pass\n    @staticmethod\n    @abstractmethod\n    def get_class_metadata(class_node, blob):\n        pass\n    @staticmethod",
        "detail": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.parsers.language_parser",
        "documentation": {}
    },
    {
        "label": "tokenize_docstring",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.parsers.language_parser",
        "description": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.parsers.language_parser",
        "peekOfCode": "def tokenize_docstring(docstring: str) -> List[str]:\n    return [\n        t\n        for t in DOCSTRING_REGEX_TOKENIZER.findall(docstring)\n        if t is not None and len(t) > 0\n    ]\ndef tokenize_code(node, blob: str, nodes_to_exclude: Optional[Set] = None) -> List:\n    tokens = []\n    traverse(node, tokens)\n    return [",
        "detail": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.parsers.language_parser",
        "documentation": {}
    },
    {
        "label": "tokenize_code",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.parsers.language_parser",
        "description": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.parsers.language_parser",
        "peekOfCode": "def tokenize_code(node, blob: str, nodes_to_exclude: Optional[Set] = None) -> List:\n    tokens = []\n    traverse(node, tokens)\n    return [\n        match_from_span(token, blob)\n        for token in tokens\n        if nodes_to_exclude is None or token not in nodes_to_exclude\n    ]\ndef traverse(node, results: List) -> None:\n    if node.type == \"string\":",
        "detail": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.parsers.language_parser",
        "documentation": {}
    },
    {
        "label": "traverse",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.parsers.language_parser",
        "description": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.parsers.language_parser",
        "peekOfCode": "def traverse(node, results: List) -> None:\n    if node.type == \"string\":\n        results.append(node)\n        return\n    for n in node.children:\n        traverse(n, results)\n    if not node.children:\n        results.append(node)\ndef nodes_are_equal(n1, n2):\n    return (",
        "detail": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.parsers.language_parser",
        "documentation": {}
    },
    {
        "label": "nodes_are_equal",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.parsers.language_parser",
        "description": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.parsers.language_parser",
        "peekOfCode": "def nodes_are_equal(n1, n2):\n    return (\n        n1.type == n2.type\n        and n1.start_point == n2.start_point\n        and n1.end_point == n2.end_point\n    )\ndef previous_sibling(tree, node):\n    \"\"\"\n    Search for the previous sibling of the node.\n    TODO: C TreeSitter should support this natively, but not its Python bindings yet. Replace later.",
        "detail": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.parsers.language_parser",
        "documentation": {}
    },
    {
        "label": "previous_sibling",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.parsers.language_parser",
        "description": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.parsers.language_parser",
        "peekOfCode": "def previous_sibling(tree, node):\n    \"\"\"\n    Search for the previous sibling of the node.\n    TODO: C TreeSitter should support this natively, but not its Python bindings yet. Replace later.\n    \"\"\"\n    to_visit = [tree.root_node]\n    while len(to_visit) > 0:\n        next_node = to_visit.pop()\n        for i, node_at_i in enumerate(next_node.children):\n            if nodes_are_equal(node, node_at_i):",
        "detail": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.parsers.language_parser",
        "documentation": {}
    },
    {
        "label": "node_parent",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.parsers.language_parser",
        "description": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.parsers.language_parser",
        "peekOfCode": "def node_parent(tree, node):\n    to_visit = [tree.root_node]\n    while len(to_visit) > 0:\n        next_node = to_visit.pop()\n        for child in next_node.children:\n            if nodes_are_equal(child, node):\n                return next_node\n        else:\n            to_visit.extend(next_node.children)\n    raise ValueError(\"Could not find node in tree.\")",
        "detail": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.parsers.language_parser",
        "documentation": {}
    },
    {
        "label": "match_from_span",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.parsers.language_parser",
        "description": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.parsers.language_parser",
        "peekOfCode": "def match_from_span(node, blob: str) -> str:\n    lines = blob.split(\"\\n\")\n    line_start = node.start_point[0]\n    line_end = node.end_point[0]\n    char_start = node.start_point[1]\n    char_end = node.end_point[1]\n    if line_start != line_end:\n        return \"\\n\".join(\n            [lines[line_start][char_start:]]\n            + lines[line_start + 1 : line_end]",
        "detail": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.parsers.language_parser",
        "documentation": {}
    },
    {
        "label": "traverse_type",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.parsers.language_parser",
        "description": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.parsers.language_parser",
        "peekOfCode": "def traverse_type(node, results: List, kind: str) -> None:\n    if node.type == kind:\n        results.append(node)\n    if not node.children:\n        return\n    for n in node.children:\n        traverse_type(n, results, kind)\nclass LanguageParser(ABC):\n    @staticmethod\n    @abstractmethod",
        "detail": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.parsers.language_parser",
        "documentation": {}
    },
    {
        "label": "DOCSTRING_REGEX_TOKENIZER",
        "kind": 5,
        "importPath": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.parsers.language_parser",
        "description": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.parsers.language_parser",
        "peekOfCode": "DOCSTRING_REGEX_TOKENIZER = re.compile(\n    r\"[^\\s,'\\\"`.():\\[\\]=*;>{\\}+-/\\\\]+|\\\\+|\\.+|\\(\\)|{\\}|\\[\\]|\\(+|\\)+|:+|\\[+|\\]+|{+|\\}+|=+|\\*+|;+|>+|\\++|-+|/+\"\n)\ndef tokenize_docstring(docstring: str) -> List[str]:\n    return [\n        t\n        for t in DOCSTRING_REGEX_TOKENIZER.findall(docstring)\n        if t is not None and len(t) > 0\n    ]\ndef tokenize_code(node, blob: str, nodes_to_exclude: Optional[Set] = None) -> List:",
        "detail": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.parsers.language_parser",
        "documentation": {}
    },
    {
        "label": "PhpParser",
        "kind": 6,
        "importPath": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.parsers.php_parser",
        "description": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.parsers.php_parser",
        "peekOfCode": "class PhpParser(LanguageParser):\n    FILTER_PATHS = (\"test\", \"tests\")\n    BLACKLISTED_FUNCTION_NAMES = {\n        \"__construct\",\n        \"__destruct\",\n        \"__call\",\n        \"__callStatic\",\n        \"__get\",\n        \"__set\",\n        \"__isset\",",
        "detail": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.parsers.php_parser",
        "documentation": {}
    },
    {
        "label": "PythonParser",
        "kind": 6,
        "importPath": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.parsers.python_parser",
        "description": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.parsers.python_parser",
        "peekOfCode": "class PythonParser(LanguageParser):\n    FILTER_PATHS = (\"test\",)\n    STOPWORDS = ()\n    # Get function calls\n    @staticmethod\n    def get_context(tree, blob):\n        def _get_import_from(import_from_statement, blob):\n            context = {}\n            mode = \"from\"\n            library = \"\"",
        "detail": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.parsers.python_parser",
        "documentation": {}
    },
    {
        "label": "RubyParser",
        "kind": 6,
        "importPath": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.parsers.ruby_parser",
        "description": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.parsers.ruby_parser",
        "peekOfCode": "class RubyParser(LanguageParser):\n    FILTER_PATHS = (\"test\", \"vendor\")\n    BLACKLISTED_FUNCTION_NAMES = {\n        \"initialize\",\n        \"to_text\",\n        \"display\",\n        \"dup\",\n        \"clone\",\n        \"equal?\",\n        \"==\",",
        "detail": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.parsers.ruby_parser",
        "documentation": {}
    },
    {
        "label": "match_license_file",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.fetch_licenses",
        "description": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.fetch_licenses",
        "peekOfCode": "def match_license_file(filename):\n    for regex in [\n        LEGAL_FILES_REGEX,\n        LICENSE_REGEX + \"\\Z\",\n        LICENSE_REGEX + PREFERRED_EXT_REGEX,\n        COPYING_REGEX + \"\\Z\",\n        COPYING_REGEX + PREFERRED_EXT_REGEX,\n        LICENSE_REGEX + OTHER_EXT_REGEX,\n        COPYING_REGEX + OTHER_EXT_REGEX,\n        LICENSE_REGEX + \"[-_]\",",
        "detail": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.fetch_licenses",
        "documentation": {}
    },
    {
        "label": "flattenlist",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.fetch_licenses",
        "description": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.fetch_licenses",
        "peekOfCode": "def flattenlist(listoflists):\n    return list(chain.from_iterable(listoflists))\ndef fetch_license(nwo):\n    licenses = []\n    tmp_dir = download(nwo)\n    for f in sorted(\n        glob.glob(tmp_dir.name + \"/**/*\", recursive=True), key=lambda x: len(x)\n    ):\n        if not os.path.isdir(f):\n            if match_license_file(f.split(\"/\")[-1]):",
        "detail": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.fetch_licenses",
        "documentation": {}
    },
    {
        "label": "fetch_license",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.fetch_licenses",
        "description": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.fetch_licenses",
        "peekOfCode": "def fetch_license(nwo):\n    licenses = []\n    tmp_dir = download(nwo)\n    for f in sorted(\n        glob.glob(tmp_dir.name + \"/**/*\", recursive=True), key=lambda x: len(x)\n    ):\n        if not os.path.isdir(f):\n            if match_license_file(f.split(\"/\")[-1]):\n                licenses.append(\n                    (",
        "detail": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.fetch_licenses",
        "documentation": {}
    },
    {
        "label": "LEGAL_FILES_REGEX",
        "kind": 5,
        "importPath": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.fetch_licenses",
        "description": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.fetch_licenses",
        "peekOfCode": "LEGAL_FILES_REGEX = \"(AUTHORS|NOTICE|LEGAL)(?:\\..*)?\\Z\"\nPREFERRED_EXT_REGEX = \"\\.[md|markdown|txt|html]\\Z\"\n# Regex to match any extension except .spdx or .header\nOTHER_EXT_REGEX = \"\\.(?!spdx|header|gemspec)[^./]+\\Z\"\n# Regex to match, LICENSE, LICENCE, unlicense, etc.\nLICENSE_REGEX = \"(un)?licen[sc]e\"\n# Regex to match COPYING, COPYRIGHT, etc.\nCOPYING_REGEX = \"copy(ing|right)\"\n# Regex to match OFL.\nOFL_REGEX = \"ofl\"",
        "detail": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.fetch_licenses",
        "documentation": {}
    },
    {
        "label": "PREFERRED_EXT_REGEX",
        "kind": 5,
        "importPath": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.fetch_licenses",
        "description": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.fetch_licenses",
        "peekOfCode": "PREFERRED_EXT_REGEX = \"\\.[md|markdown|txt|html]\\Z\"\n# Regex to match any extension except .spdx or .header\nOTHER_EXT_REGEX = \"\\.(?!spdx|header|gemspec)[^./]+\\Z\"\n# Regex to match, LICENSE, LICENCE, unlicense, etc.\nLICENSE_REGEX = \"(un)?licen[sc]e\"\n# Regex to match COPYING, COPYRIGHT, etc.\nCOPYING_REGEX = \"copy(ing|right)\"\n# Regex to match OFL.\nOFL_REGEX = \"ofl\"\n# BSD + PATENTS patent file",
        "detail": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.fetch_licenses",
        "documentation": {}
    },
    {
        "label": "OTHER_EXT_REGEX",
        "kind": 5,
        "importPath": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.fetch_licenses",
        "description": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.fetch_licenses",
        "peekOfCode": "OTHER_EXT_REGEX = \"\\.(?!spdx|header|gemspec)[^./]+\\Z\"\n# Regex to match, LICENSE, LICENCE, unlicense, etc.\nLICENSE_REGEX = \"(un)?licen[sc]e\"\n# Regex to match COPYING, COPYRIGHT, etc.\nCOPYING_REGEX = \"copy(ing|right)\"\n# Regex to match OFL.\nOFL_REGEX = \"ofl\"\n# BSD + PATENTS patent file\nPATENTS_REGEX = \"patents\"\ndef match_license_file(filename):",
        "detail": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.fetch_licenses",
        "documentation": {}
    },
    {
        "label": "LICENSE_REGEX",
        "kind": 5,
        "importPath": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.fetch_licenses",
        "description": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.fetch_licenses",
        "peekOfCode": "LICENSE_REGEX = \"(un)?licen[sc]e\"\n# Regex to match COPYING, COPYRIGHT, etc.\nCOPYING_REGEX = \"copy(ing|right)\"\n# Regex to match OFL.\nOFL_REGEX = \"ofl\"\n# BSD + PATENTS patent file\nPATENTS_REGEX = \"patents\"\ndef match_license_file(filename):\n    for regex in [\n        LEGAL_FILES_REGEX,",
        "detail": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.fetch_licenses",
        "documentation": {}
    },
    {
        "label": "COPYING_REGEX",
        "kind": 5,
        "importPath": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.fetch_licenses",
        "description": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.fetch_licenses",
        "peekOfCode": "COPYING_REGEX = \"copy(ing|right)\"\n# Regex to match OFL.\nOFL_REGEX = \"ofl\"\n# BSD + PATENTS patent file\nPATENTS_REGEX = \"patents\"\ndef match_license_file(filename):\n    for regex in [\n        LEGAL_FILES_REGEX,\n        LICENSE_REGEX + \"\\Z\",\n        LICENSE_REGEX + PREFERRED_EXT_REGEX,",
        "detail": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.fetch_licenses",
        "documentation": {}
    },
    {
        "label": "OFL_REGEX",
        "kind": 5,
        "importPath": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.fetch_licenses",
        "description": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.fetch_licenses",
        "peekOfCode": "OFL_REGEX = \"ofl\"\n# BSD + PATENTS patent file\nPATENTS_REGEX = \"patents\"\ndef match_license_file(filename):\n    for regex in [\n        LEGAL_FILES_REGEX,\n        LICENSE_REGEX + \"\\Z\",\n        LICENSE_REGEX + PREFERRED_EXT_REGEX,\n        COPYING_REGEX + \"\\Z\",\n        COPYING_REGEX + PREFERRED_EXT_REGEX,",
        "detail": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.fetch_licenses",
        "documentation": {}
    },
    {
        "label": "PATENTS_REGEX",
        "kind": 5,
        "importPath": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.fetch_licenses",
        "description": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.fetch_licenses",
        "peekOfCode": "PATENTS_REGEX = \"patents\"\ndef match_license_file(filename):\n    for regex in [\n        LEGAL_FILES_REGEX,\n        LICENSE_REGEX + \"\\Z\",\n        LICENSE_REGEX + PREFERRED_EXT_REGEX,\n        COPYING_REGEX + \"\\Z\",\n        COPYING_REGEX + PREFERRED_EXT_REGEX,\n        LICENSE_REGEX + OTHER_EXT_REGEX,\n        COPYING_REGEX + OTHER_EXT_REGEX,",
        "detail": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.fetch_licenses",
        "documentation": {}
    },
    {
        "label": "client",
        "kind": 5,
        "importPath": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.fetch_licenses",
        "description": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.fetch_licenses",
        "peekOfCode": "client = Client()\nfor language in LANGUAGE_METADATA.keys():\n    definitions = pickle.load(\n        open(\"../data/{}_dedupe_definitions_v2.pkl\".format(language), \"rb\")\n    )\n    nwos = list(set([d[\"nwo\"] for d in definitions]))\n    futures = client.map(fetch_license, nwos)\n    results = []\n    for r in tqdm(futures):\n        try:",
        "detail": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.fetch_licenses",
        "documentation": {}
    },
    {
        "label": "LANGUAGE_METADATA",
        "kind": 5,
        "importPath": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.language_data",
        "description": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.language_data",
        "peekOfCode": "LANGUAGE_METADATA = {\n    \"python\": {\"platform\": \"pypi\", \"ext\": \"py\", \"language_parser\": PythonParser},\n    \"java\": {\"platform\": \"maven\", \"ext\": \"java\", \"language_parser\": JavaParser},\n    \"go\": {\"platform\": \"go\", \"ext\": \"go\", \"language_parser\": GoParser},\n    \"javascript\": {\"platform\": \"npm\", \"ext\": \"js\", \"language_parser\": JavascriptParser},\n    \"php\": {\"platform\": \"packagist\", \"ext\": \"php\", \"language_parser\": PhpParser},\n    \"ruby\": {\"platform\": \"rubygems\", \"ext\": \"rb\", \"language_parser\": RubyParser},\n}",
        "detail": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.language_data",
        "documentation": {}
    },
    {
        "label": "DataProcessor",
        "kind": 6,
        "importPath": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.process",
        "description": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.process",
        "peekOfCode": "class DataProcessor:\n    PARSER = Parser()\n    def __init__(self, language: str, language_parser: Type[LanguageParser]):\n        self.language = language\n        self.language_parser = language_parser\n    def process_dee(self, nwo, ext) -> List[Dict[str, Any]]:\n        # Process dependees (libraries) to get function implementations\n        indexes = []\n        _, nwo = remap_nwo(nwo)\n        if nwo is None:",
        "detail": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.process",
        "documentation": {}
    },
    {
        "label": "flatten",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.utils",
        "description": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.utils",
        "peekOfCode": "def flatten(l):\n    \"\"\"Flatten list of lists.\n    Args:\n        l: A list of lists\n    Returns: A flattened iterable\n    \"\"\"\n    return itertools.chain.from_iterable(l)\ndef chunks(l: List, n: int):\n    \"\"\"Yield successive n-sized chunks from l.\"\"\"\n    for i in range(0, len(l), n):",
        "detail": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.utils",
        "documentation": {}
    },
    {
        "label": "chunks",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.utils",
        "description": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.utils",
        "peekOfCode": "def chunks(l: List, n: int):\n    \"\"\"Yield successive n-sized chunks from l.\"\"\"\n    for i in range(0, len(l), n):\n        yield l[i : i + n]\ndef remap_nwo(nwo: str) -> Tuple[str, str]:\n    r = requests.get(\"https://github.com/{}\".format(nwo))\n    if r.status_code not in (404, 451, 502):  # DMCA\n        if \"migrated\" not in r.text:\n            if r.history:\n                return (",
        "detail": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.utils",
        "documentation": {}
    },
    {
        "label": "remap_nwo",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.utils",
        "description": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.utils",
        "peekOfCode": "def remap_nwo(nwo: str) -> Tuple[str, str]:\n    r = requests.get(\"https://github.com/{}\".format(nwo))\n    if r.status_code not in (404, 451, 502):  # DMCA\n        if \"migrated\" not in r.text:\n            if r.history:\n                return (\n                    nwo,\n                    \"/\".join(\n                        re.findall(r'\"https://github.com/.+\"', r.history[0].text)[0]\n                        .strip('\"')",
        "detail": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.utils",
        "documentation": {}
    },
    {
        "label": "get_sha",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.utils",
        "description": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.utils",
        "peekOfCode": "def get_sha(tmp_dir: tempfile.TemporaryDirectory, nwo: str):\n    os.chdir(os.path.join(tmp_dir.name, nwo))\n    # git rev-parse HEAD\n    cmd = [\"git\", \"rev-parse\", \"HEAD\"]\n    sha = subprocess.check_output(cmd).strip().decode(\"utf-8\")\n    os.chdir(\"/tmp\")\n    return sha\ndef download(nwo: str):\n    os.environ[\"GIT_TERMINAL_PROMPT\"] = \"0\"\n    tmp_dir = tempfile.TemporaryDirectory()",
        "detail": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.utils",
        "documentation": {}
    },
    {
        "label": "download",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.utils",
        "description": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.utils",
        "peekOfCode": "def download(nwo: str):\n    os.environ[\"GIT_TERMINAL_PROMPT\"] = \"0\"\n    tmp_dir = tempfile.TemporaryDirectory()\n    cmd = [\n        \"git\",\n        \"clone\",\n        \"--depth=1\",\n        \"https://github.com/{}.git\".format(nwo),\n        \"{}/{}\".format(tmp_dir.name, nwo),\n    ]",
        "detail": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.utils",
        "documentation": {}
    },
    {
        "label": "walk",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.utils",
        "description": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.utils",
        "peekOfCode": "def walk(tmp_dir: tempfile.TemporaryDirectory, ext: str):\n    results = []\n    for root, _, files in os.walk(tmp_dir.name):\n        for f in files:\n            if f.endswith(\".\" + ext):\n                results.append(os.path.join(root, f))\n    return results",
        "detail": "_REPO.GITHUB.CodeSearchNet.function_parser.function_parser.utils",
        "documentation": {}
    },
    {
        "label": "languages",
        "kind": 5,
        "importPath": "_REPO.GITHUB.CodeSearchNet.function_parser.script.setup",
        "description": "_REPO.GITHUB.CodeSearchNet.function_parser.script.setup",
        "peekOfCode": "languages = [\n    \"/src/vendor/tree-sitter-python\",\n    \"/src/vendor/tree-sitter-javascript\",\n    # '/src/vendor/tree-sitter-typescript/typescript',\n    # '/src/vendor/tree-sitter-typescript/tsx',\n    \"/src/vendor/tree-sitter-go\",\n    \"/src/vendor/tree-sitter-ruby\",\n    \"/src/vendor/tree-sitter-java\",\n    \"/src/vendor/tree-sitter-cpp\",\n    \"/src/vendor/tree-sitter-php\",",
        "detail": "_REPO.GITHUB.CodeSearchNet.function_parser.script.setup",
        "documentation": {}
    },
    {
        "label": "ParsedCode",
        "kind": 6,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.dataextraction.python.parse_python_data",
        "description": "_REPO.GITHUB.CodeSearchNet.src.dataextraction.python.parse_python_data",
        "peekOfCode": "class ParsedCode(NamedTuple):\n    code_tokens: List[str]\n    comment_tokens: List[str]\ndef tokenize_python_from_string(\n    code: str,\n    func_only: bool = True,\n    report_errors: bool = False,\n    only_ids: bool = False,\n    add_keywords: bool = True,\n) -> ParsedCode:",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.dataextraction.python.parse_python_data",
        "documentation": {}
    },
    {
        "label": "tokenize_python_from_string",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.dataextraction.python.parse_python_data",
        "description": "_REPO.GITHUB.CodeSearchNet.src.dataextraction.python.parse_python_data",
        "peekOfCode": "def tokenize_python_from_string(\n    code: str,\n    func_only: bool = True,\n    report_errors: bool = False,\n    only_ids: bool = False,\n    add_keywords: bool = True,\n) -> ParsedCode:\n    \"\"\"\n    Tokenize Python code given a string.\n    Args:",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.dataextraction.python.parse_python_data",
        "documentation": {}
    },
    {
        "label": "download_files_into_pandas",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.dataextraction.python.parse_python_data",
        "description": "_REPO.GITHUB.CodeSearchNet.src.dataextraction.python.parse_python_data",
        "peekOfCode": "def download_files_into_pandas(i: int = 10) -> pd.DataFrame:\n    \"\"\"Get files from Google Cloud Platform, there are 10 files.\n    Args:\n        i : int between 1 and 10 that specifies how many of the 10 files you\n            want to download.  You should only use this argument for testing.\n    Files are obtained by this query: https://console.cloud.google.com/bigquery?sq=235037502967:58a5d62f75f34d22b0f70d38b9352a85\n    \"\"\"\n    frames = []\n    for i in tqdm(range(i), total=i):\n        success = False",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.dataextraction.python.parse_python_data",
        "documentation": {}
    },
    {
        "label": "load_files_into_pandas",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.dataextraction.python.parse_python_data",
        "description": "_REPO.GITHUB.CodeSearchNet.src.dataextraction.python.parse_python_data",
        "peekOfCode": "def load_files_into_pandas(input_folder: str) -> pd.DataFrame:\n    \"\"\"Get files from a local directory.\n    Args:\n        input_folder: the folder containing the .csv files\n    \"\"\"\n    frames = []\n    for file in os.listdir(input_folder):\n        if not file.endswith(\".csv\"):\n            continue\n        frame = pd.read_csv(os.path.join(input_folder, file), encoding=\"utf-8\")",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.dataextraction.python.parse_python_data",
        "documentation": {}
    },
    {
        "label": "parse_raw_data_into_function_list",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.dataextraction.python.parse_python_data",
        "description": "_REPO.GITHUB.CodeSearchNet.src.dataextraction.python.parse_python_data",
        "peekOfCode": "def parse_raw_data_into_function_list(blob, require_docstring: bool = True):\n    \"\"\"Extract per-function data from a given code blob.\n    Filters out undesirable function types. Keep only the first line of the docstring, and remove all internal comments from\n    the code.\n    Args:\n        blob: String containing some python code.\n    Returns:\n        List of functions represented by dictionaries containing the code, docstring and metadata.\n    \"\"\"\n    parsed_data_list = []",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.dataextraction.python.parse_python_data",
        "documentation": {}
    },
    {
        "label": "listlen",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.dataextraction.python.parse_python_data",
        "description": "_REPO.GITHUB.CodeSearchNet.src.dataextraction.python.parse_python_data",
        "peekOfCode": "def listlen(x):\n    if not isinstance(x, list):\n        return 0\n    return len(x)\ndef run(args):\n    azure_info_path = args.get(\"--azure-info\")\n    output_folder = RichPath.create(args[\"OUTPUT_PATH\"], azure_info_path)\n    # Download / read the data files:\n    if args[\"--input-folder\"] is None:\n        print(\"Downloading data...\")",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.dataextraction.python.parse_python_data",
        "documentation": {}
    },
    {
        "label": "run",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.dataextraction.python.parse_python_data",
        "description": "_REPO.GITHUB.CodeSearchNet.src.dataextraction.python.parse_python_data",
        "peekOfCode": "def run(args):\n    azure_info_path = args.get(\"--azure-info\")\n    output_folder = RichPath.create(args[\"OUTPUT_PATH\"], azure_info_path)\n    # Download / read the data files:\n    if args[\"--input-folder\"] is None:\n        print(\"Downloading data...\")\n        raw_code_data_df = download_files_into_pandas()\n    else:\n        print(\"Loading data...\")\n        raw_code_data_df = load_files_into_pandas(args[\"--input-folder\"])",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.dataextraction.python.parse_python_data",
        "documentation": {}
    },
    {
        "label": "IS_WHITESPACE_REGEX",
        "kind": 5,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.dataextraction.python.parse_python_data",
        "description": "_REPO.GITHUB.CodeSearchNet.src.dataextraction.python.parse_python_data",
        "peekOfCode": "IS_WHITESPACE_REGEX = re.compile(r\"\\s+\")\nclass ParsedCode(NamedTuple):\n    code_tokens: List[str]\n    comment_tokens: List[str]\ndef tokenize_python_from_string(\n    code: str,\n    func_only: bool = True,\n    report_errors: bool = False,\n    only_ids: bool = False,\n    add_keywords: bool = True,",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.dataextraction.python.parse_python_data",
        "documentation": {}
    },
    {
        "label": "jsonl_to_df",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.dataextraction.dedup_split",
        "description": "_REPO.GITHUB.CodeSearchNet.src.dataextraction.dedup_split",
        "peekOfCode": "def jsonl_to_df(input_folder: RichPath) -> pd.DataFrame:\n    \"Concatenates all jsonl files from path and returns them as a single pandas.DataFrame .\"\n    assert input_folder.is_dir(), \"Argument supplied must be a directory\"\n    dfs = []\n    files = list(input_folder.iterate_filtered_files_in_dir(\"*.jsonl.gz\"))\n    assert files, \"There were no jsonl.gz files in the specified directory.\"\n    print(f\"reading files from {input_folder.path}\")\n    for f in tqdm(files, total=len(files)):\n        dfs.append(\n            pd.DataFrame(",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.dataextraction.dedup_split",
        "documentation": {}
    },
    {
        "label": "remove_duplicate_code_df",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.dataextraction.dedup_split",
        "description": "_REPO.GITHUB.CodeSearchNet.src.dataextraction.dedup_split",
        "peekOfCode": "def remove_duplicate_code_df(df: pd.DataFrame) -> pd.DataFrame:\n    \"Resolve near duplicates based upon code_tokens field in data.\"\n    assert \"code_tokens\" in df.columns.values, \"Data must contain field code_tokens\"\n    assert \"language\" in df.columns.values, \"Data must contain field language\"\n    df.reset_index(inplace=True, drop=True)\n    df[\"doc_id\"] = df.index.values\n    dd = DuplicateDetector(min_num_tokens_per_document=10)\n    filter_mask = df.apply(\n        lambda x: dd.add_file(id=x.doc_id, tokens=x.code_tokens, language=x.language),\n        axis=1,",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.dataextraction.dedup_split",
        "documentation": {}
    },
    {
        "label": "label_folds",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.dataextraction.dedup_split",
        "description": "_REPO.GITHUB.CodeSearchNet.src.dataextraction.dedup_split",
        "peekOfCode": "def label_folds(\n    df: pd.DataFrame,\n    train_ratio: float,\n    valid_ratio: float,\n    test_ratio: float,\n    holdout_ratio: float,\n) -> pd.DataFrame:\n    \"Adds a partition column to DataFrame with values: {train, valid, test, holdout}.\"\n    assert (\n        abs(train_ratio + valid_ratio + test_ratio + holdout_ratio - 1) < 1e-5",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.dataextraction.dedup_split",
        "documentation": {}
    },
    {
        "label": "run",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.dataextraction.dedup_split",
        "description": "_REPO.GITHUB.CodeSearchNet.src.dataextraction.dedup_split",
        "peekOfCode": "def run(args):\n    azure_info_path = args.get(\"--azure-info\", None)\n    input_path = RichPath.create(args[\"INPUT_FILENAME\"], azure_info_path)\n    output_folder = RichPath.create(args[\"OUTPUT_FOLDER\"], azure_info_path)\n    train = float(args[\"--train-ratio\"])\n    valid = float(args[\"--valid-ratio\"])\n    test = float(args[\"--test-ratio\"])\n    holdout = float(args[\"--holdout-ratio\"])\n    # get data and process it\n    df = jsonl_to_df(input_path)",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.dataextraction.dedup_split",
        "documentation": {}
    },
    {
        "label": "tokenize_docstring_from_string",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.dataextraction.utils",
        "description": "_REPO.GITHUB.CodeSearchNet.src.dataextraction.utils",
        "peekOfCode": "def tokenize_docstring_from_string(docstr: str) -> List[str]:\n    return [\n        t\n        for t in DOCSTRING_REGEX_TOKENIZER.findall(docstr)\n        if t is not None and len(t) > 0\n    ]",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.dataextraction.utils",
        "documentation": {}
    },
    {
        "label": "DOCSTRING_REGEX_TOKENIZER",
        "kind": 5,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.dataextraction.utils",
        "description": "_REPO.GITHUB.CodeSearchNet.src.dataextraction.utils",
        "peekOfCode": "DOCSTRING_REGEX_TOKENIZER = re.compile(\n    r\"[^\\s,'\\\"`.():\\[\\]=*;>{\\}+-/\\\\]+|\\\\+|\\.+|\\(\\)|{\\}|\\[\\]|\\(+|\\)+|:+|\\[+|\\]+|{+|\\}+|=+|\\*+|;+|>+|\\++|-+|/+\"\n)\ndef tokenize_docstring_from_string(docstr: str) -> List[str]:\n    return [\n        t\n        for t in DOCSTRING_REGEX_TOKENIZER.findall(docstr)\n        if t is not None and len(t) > 0\n    ]",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.dataextraction.utils",
        "documentation": {}
    },
    {
        "label": "BertConfig",
        "kind": 6,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.encoders.utils.bert_self_attention",
        "description": "_REPO.GITHUB.CodeSearchNet.src.encoders.utils.bert_self_attention",
        "peekOfCode": "class BertConfig(object):\n    \"\"\"Configuration for `BertModel`.\"\"\"\n    def __init__(\n        self,\n        vocab_size,\n        hidden_size=768,\n        num_hidden_layers=12,\n        num_attention_heads=12,\n        intermediate_size=3072,\n        hidden_act=\"gelu\",",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.encoders.utils.bert_self_attention",
        "documentation": {}
    },
    {
        "label": "BertModel",
        "kind": 6,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.encoders.utils.bert_self_attention",
        "description": "_REPO.GITHUB.CodeSearchNet.src.encoders.utils.bert_self_attention",
        "peekOfCode": "class BertModel(object):\n    \"\"\"BERT model (\"Bidirectional Embedding Representations from a Transformer\").\n  Example usage:\n  ```python\n  # Already been converted into WordPiece token ids\n  input_ids = tf.constant([[31, 51, 99], [15, 5, 0]])\n  input_mask = tf.constant([[1, 1, 1], [1, 1, 0]])\n  token_type_ids = tf.constant([[0, 0, 1], [0, 2, 0]])\n  config = modeling.BertConfig(vocab_size=32000, hidden_size=512,\n    num_hidden_layers=8, num_attention_heads=6, intermediate_size=1024)",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.encoders.utils.bert_self_attention",
        "documentation": {}
    },
    {
        "label": "get_assigment_map_from_checkpoint",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.encoders.utils.bert_self_attention",
        "description": "_REPO.GITHUB.CodeSearchNet.src.encoders.utils.bert_self_attention",
        "peekOfCode": "def get_assigment_map_from_checkpoint(tvars, init_checkpoint):\n    \"\"\"Compute the union of the current variables and checkpoint variables.\"\"\"\n    assignment_map = {}\n    initialized_variable_names = {}\n    name_to_variable = collections.OrderedDict()\n    for var in tvars:\n        name = var.name\n        m = re.match(\"^(.*):\\\\d+$\", name)\n        if m is not None:\n            name = m.group(1)",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.encoders.utils.bert_self_attention",
        "documentation": {}
    },
    {
        "label": "dropout",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.encoders.utils.bert_self_attention",
        "description": "_REPO.GITHUB.CodeSearchNet.src.encoders.utils.bert_self_attention",
        "peekOfCode": "def dropout(input_tensor, dropout_prob):\n    \"\"\"Perform dropout.\n  Args:\n    input_tensor: float Tensor.\n    dropout_prob: Python float. The probability of dropping out a value (NOT of\n      *keeping* a dimension as in `tf.nn.dropout`).\n  Returns:\n    A version of `input_tensor` with dropout applied.\n  \"\"\"\n    if dropout_prob is None or dropout_prob == 0.0:",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.encoders.utils.bert_self_attention",
        "documentation": {}
    },
    {
        "label": "layer_norm",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.encoders.utils.bert_self_attention",
        "description": "_REPO.GITHUB.CodeSearchNet.src.encoders.utils.bert_self_attention",
        "peekOfCode": "def layer_norm(input_tensor, name=None):\n    \"\"\"Run layer normalization on the last dimension of the tensor.\"\"\"\n    return tf.contrib.layers.layer_norm(\n        inputs=input_tensor, begin_norm_axis=-1, begin_params_axis=-1, scope=name\n    )\ndef layer_norm_and_dropout(input_tensor, dropout_prob, name=None):\n    \"\"\"Runs layer normalization followed by dropout.\"\"\"\n    output_tensor = layer_norm(input_tensor, name)\n    output_tensor = dropout(output_tensor, dropout_prob)\n    return output_tensor",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.encoders.utils.bert_self_attention",
        "documentation": {}
    },
    {
        "label": "layer_norm_and_dropout",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.encoders.utils.bert_self_attention",
        "description": "_REPO.GITHUB.CodeSearchNet.src.encoders.utils.bert_self_attention",
        "peekOfCode": "def layer_norm_and_dropout(input_tensor, dropout_prob, name=None):\n    \"\"\"Runs layer normalization followed by dropout.\"\"\"\n    output_tensor = layer_norm(input_tensor, name)\n    output_tensor = dropout(output_tensor, dropout_prob)\n    return output_tensor\ndef create_initializer(initializer_range=0.02):\n    \"\"\"Creates a `truncated_normal_initializer` with the given range.\"\"\"\n    return tf.truncated_normal_initializer(stddev=initializer_range)\ndef embedding_lookup(\n    input_ids,",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.encoders.utils.bert_self_attention",
        "documentation": {}
    },
    {
        "label": "create_initializer",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.encoders.utils.bert_self_attention",
        "description": "_REPO.GITHUB.CodeSearchNet.src.encoders.utils.bert_self_attention",
        "peekOfCode": "def create_initializer(initializer_range=0.02):\n    \"\"\"Creates a `truncated_normal_initializer` with the given range.\"\"\"\n    return tf.truncated_normal_initializer(stddev=initializer_range)\ndef embedding_lookup(\n    input_ids,\n    vocab_size,\n    embedding_size=128,\n    initializer_range=0.02,\n    word_embedding_name=\"word_embeddings\",\n    use_one_hot_embeddings=False,",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.encoders.utils.bert_self_attention",
        "documentation": {}
    },
    {
        "label": "embedding_lookup",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.encoders.utils.bert_self_attention",
        "description": "_REPO.GITHUB.CodeSearchNet.src.encoders.utils.bert_self_attention",
        "peekOfCode": "def embedding_lookup(\n    input_ids,\n    vocab_size,\n    embedding_size=128,\n    initializer_range=0.02,\n    word_embedding_name=\"word_embeddings\",\n    use_one_hot_embeddings=False,\n):\n    \"\"\"Looks up words embeddings for id tensor.\n  Args:",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.encoders.utils.bert_self_attention",
        "documentation": {}
    },
    {
        "label": "embedding_postprocessor",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.encoders.utils.bert_self_attention",
        "description": "_REPO.GITHUB.CodeSearchNet.src.encoders.utils.bert_self_attention",
        "peekOfCode": "def embedding_postprocessor(\n    input_tensor,\n    use_token_type=False,\n    token_type_ids=None,\n    token_type_vocab_size=16,\n    token_type_embedding_name=\"token_type_embeddings\",\n    use_position_embeddings=True,\n    position_embedding_name=\"position_embeddings\",\n    initializer_range=0.02,\n    max_position_embeddings=512,",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.encoders.utils.bert_self_attention",
        "documentation": {}
    },
    {
        "label": "create_attention_mask_from_input_mask",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.encoders.utils.bert_self_attention",
        "description": "_REPO.GITHUB.CodeSearchNet.src.encoders.utils.bert_self_attention",
        "peekOfCode": "def create_attention_mask_from_input_mask(from_tensor, to_mask):\n    \"\"\"Create 3D attention mask from a 2D tensor mask.\n  Args:\n    from_tensor: 2D or 3D Tensor of shape [batch_size, from_seq_length, ...].\n    to_mask: int32 Tensor of shape [batch_size, to_seq_length].\n  Returns:\n    float Tensor of shape [batch_size, from_seq_length, to_seq_length].\n  \"\"\"\n    from_shape = get_shape_list(from_tensor, expected_rank=[2, 3])\n    batch_size = from_shape[0]",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.encoders.utils.bert_self_attention",
        "documentation": {}
    },
    {
        "label": "attention_layer",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.encoders.utils.bert_self_attention",
        "description": "_REPO.GITHUB.CodeSearchNet.src.encoders.utils.bert_self_attention",
        "peekOfCode": "def attention_layer(\n    from_tensor,\n    to_tensor,\n    attention_mask=None,\n    num_attention_heads=1,\n    size_per_head=512,\n    query_act=None,\n    key_act=None,\n    value_act=None,\n    attention_probs_dropout_prob=0.0,",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.encoders.utils.bert_self_attention",
        "documentation": {}
    },
    {
        "label": "transformer_model",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.encoders.utils.bert_self_attention",
        "description": "_REPO.GITHUB.CodeSearchNet.src.encoders.utils.bert_self_attention",
        "peekOfCode": "def transformer_model(\n    input_tensor,\n    attention_mask=None,\n    hidden_size=768,\n    num_hidden_layers=12,\n    num_attention_heads=12,\n    intermediate_size=3072,\n    intermediate_act_fn=get_activation(\"gelu\"),\n    hidden_dropout_prob=0.1,\n    attention_probs_dropout_prob=0.1,",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.encoders.utils.bert_self_attention",
        "documentation": {}
    },
    {
        "label": "get_shape_list",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.encoders.utils.bert_self_attention",
        "description": "_REPO.GITHUB.CodeSearchNet.src.encoders.utils.bert_self_attention",
        "peekOfCode": "def get_shape_list(tensor, expected_rank=None, name=None):\n    \"\"\"Returns a list of the shape of tensor, preferring static dimensions.\n  Args:\n    tensor: A tf.Tensor object to find the shape of.\n    expected_rank: (optional) int. The expected rank of `tensor`. If this is\n      specified and the `tensor` has a different rank, and exception will be\n      thrown.\n    name: Optional name of the tensor for the error message.\n  Returns:\n    A list of dimensions of the shape of tensor. All static dimensions will",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.encoders.utils.bert_self_attention",
        "documentation": {}
    },
    {
        "label": "reshape_to_matrix",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.encoders.utils.bert_self_attention",
        "description": "_REPO.GITHUB.CodeSearchNet.src.encoders.utils.bert_self_attention",
        "peekOfCode": "def reshape_to_matrix(input_tensor):\n    \"\"\"Reshapes a >= rank 2 tensor to a rank 2 tensor (i.e., a matrix).\"\"\"\n    ndims = input_tensor.shape.ndims\n    if ndims < 2:\n        raise ValueError(\n            \"Input tensor must have at least rank 2. Shape = %s\" % (input_tensor.shape)\n        )\n    if ndims == 2:\n        return input_tensor\n    width = input_tensor.shape[-1]",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.encoders.utils.bert_self_attention",
        "documentation": {}
    },
    {
        "label": "reshape_from_matrix",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.encoders.utils.bert_self_attention",
        "description": "_REPO.GITHUB.CodeSearchNet.src.encoders.utils.bert_self_attention",
        "peekOfCode": "def reshape_from_matrix(output_tensor, orig_shape_list):\n    \"\"\"Reshapes a rank 2 tensor back to its original rank >= 2 tensor.\"\"\"\n    if len(orig_shape_list) == 2:\n        return output_tensor\n    output_shape = get_shape_list(output_tensor)\n    orig_dims = orig_shape_list[0:-1]\n    width = output_shape[-1]\n    return tf.reshape(output_tensor, orig_dims + [width])\ndef assert_rank(tensor, expected_rank, name=None):\n    \"\"\"Raises an exception if the tensor rank is not of the expected rank.",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.encoders.utils.bert_self_attention",
        "documentation": {}
    },
    {
        "label": "assert_rank",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.encoders.utils.bert_self_attention",
        "description": "_REPO.GITHUB.CodeSearchNet.src.encoders.utils.bert_self_attention",
        "peekOfCode": "def assert_rank(tensor, expected_rank, name=None):\n    \"\"\"Raises an exception if the tensor rank is not of the expected rank.\n  Args:\n    tensor: A tf.Tensor to check the rank of.\n    expected_rank: Python integer or list of integers, expected rank.\n    name: Optional name of the tensor for the error message.\n  Raises:\n    ValueError: If the expected shape doesn't match the actual shape.\n  \"\"\"\n    if name is None:",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.encoders.utils.bert_self_attention",
        "documentation": {}
    },
    {
        "label": "ConvSelfAttentionEncoder",
        "kind": 6,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.encoders.conv_self_att_encoder",
        "description": "_REPO.GITHUB.CodeSearchNet.src.encoders.conv_self_att_encoder",
        "peekOfCode": "class ConvSelfAttentionEncoder(MaskedSeqEncoder):\n    @classmethod\n    def get_default_hyperparameters(cls) -> Dict[str, Any]:\n        encoder_hypers = {\n            \"1dcnn_position_encoding\": \"none\",  # One of {'none', 'learned'}\n            \"1dcnn_layer_list\": [128, 128],\n            \"1dcnn_kernel_width\": [8, 8],  # Has to have same length as 1dcnn_layer_list\n            \"1dcnn_add_residual_connections\": True,\n            \"1dcnn_activation\": \"tanh\",\n            \"self_attention_activation\": \"gelu\",",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.encoders.conv_self_att_encoder",
        "documentation": {}
    },
    {
        "label": "ConvolutionSeqEncoder",
        "kind": 6,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.encoders.conv_seq_encoder",
        "description": "_REPO.GITHUB.CodeSearchNet.src.encoders.conv_seq_encoder",
        "peekOfCode": "class ConvolutionSeqEncoder(MaskedSeqEncoder):\n    @classmethod\n    def get_default_hyperparameters(cls) -> Dict[str, Any]:\n        encoder_hypers = {\n            \"1dcnn_position_encoding\": \"learned\",  # One of {'none', 'learned'}\n            \"1dcnn_layer_list\": [128, 128, 128],\n            \"1dcnn_kernel_width\": [\n                16,\n                16,\n                16,",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.encoders.conv_seq_encoder",
        "documentation": {}
    },
    {
        "label": "QueryType",
        "kind": 6,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.encoders.encoder",
        "description": "_REPO.GITHUB.CodeSearchNet.src.encoders.encoder",
        "peekOfCode": "class QueryType(Enum):\n    DOCSTRING = \"docstring_as_query\"\n    FUNCTION_NAME = \"func_name_as_query\"\nclass Encoder(ABC):\n    @classmethod\n    @abstractmethod\n    def get_default_hyperparameters(cls) -> Dict[str, Any]:\n        \"\"\"\n        Returns:\n             Default set of hyperparameters for encoder.",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.encoders.encoder",
        "documentation": {}
    },
    {
        "label": "Encoder",
        "kind": 6,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.encoders.encoder",
        "description": "_REPO.GITHUB.CodeSearchNet.src.encoders.encoder",
        "peekOfCode": "class Encoder(ABC):\n    @classmethod\n    @abstractmethod\n    def get_default_hyperparameters(cls) -> Dict[str, Any]:\n        \"\"\"\n        Returns:\n             Default set of hyperparameters for encoder.\n             Note that at use, the hyperparameters names will be prefixed with '${label}_' for the\n             chosen encoder label.\n        \"\"\"",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.encoders.encoder",
        "documentation": {}
    },
    {
        "label": "MaskedSeqEncoder",
        "kind": 6,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.encoders.masked_seq_encoder",
        "description": "_REPO.GITHUB.CodeSearchNet.src.encoders.masked_seq_encoder",
        "peekOfCode": "class MaskedSeqEncoder(SeqEncoder):\n    @classmethod\n    def get_default_hyperparameters(cls) -> Dict[str, Any]:\n        encoder_hypers = {}\n        hypers = super().get_default_hyperparameters()\n        hypers.update(encoder_hypers)\n        return hypers\n    def __init__(\n        self, label: str, hyperparameters: Dict[str, Any], metadata: Dict[str, Any]\n    ):",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.encoders.masked_seq_encoder",
        "documentation": {}
    },
    {
        "label": "NBoWEncoder",
        "kind": 6,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.encoders.nbow_seq_encoder",
        "description": "_REPO.GITHUB.CodeSearchNet.src.encoders.nbow_seq_encoder",
        "peekOfCode": "class NBoWEncoder(MaskedSeqEncoder):\n    @classmethod\n    def get_default_hyperparameters(cls) -> Dict[str, Any]:\n        encoder_hypers = {\"nbow_pool_mode\": \"weighted_mean\"}\n        hypers = super().get_default_hyperparameters()\n        hypers.update(encoder_hypers)\n        return hypers\n    def __init__(\n        self, label: str, hyperparameters: Dict[str, Any], metadata: Dict[str, Any]\n    ):",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.encoders.nbow_seq_encoder",
        "documentation": {}
    },
    {
        "label": "RNNEncoder",
        "kind": 6,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.encoders.rnn_seq_encoder",
        "description": "_REPO.GITHUB.CodeSearchNet.src.encoders.rnn_seq_encoder",
        "peekOfCode": "class RNNEncoder(SeqEncoder):\n    @classmethod\n    def get_default_hyperparameters(cls) -> Dict[str, Any]:\n        encoder_hypers = {\n            \"rnn_num_layers\": 2,\n            \"rnn_hidden_dim\": 64,\n            \"rnn_cell_type\": \"LSTM\",  # One of [LSTM, GRU, RNN]\n            \"rnn_is_bidirectional\": True,\n            \"rnn_dropout_keep_rate\": 0.8,\n            \"rnn_recurrent_dropout_keep_rate\": 1.0,",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.encoders.rnn_seq_encoder",
        "documentation": {}
    },
    {
        "label": "SelfAttentionEncoder",
        "kind": 6,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.encoders.self_att_encoder",
        "description": "_REPO.GITHUB.CodeSearchNet.src.encoders.self_att_encoder",
        "peekOfCode": "class SelfAttentionEncoder(MaskedSeqEncoder):\n    @classmethod\n    def get_default_hyperparameters(cls) -> Dict[str, Any]:\n        encoder_hypers = {\n            \"self_attention_activation\": \"gelu\",\n            \"self_attention_hidden_size\": 128,\n            \"self_attention_intermediate_size\": 512,\n            \"self_attention_num_layers\": 3,\n            \"self_attention_num_heads\": 8,\n            \"self_attention_pool_mode\": \"weighted_mean\",",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.encoders.self_att_encoder",
        "documentation": {}
    },
    {
        "label": "SeqEncoder",
        "kind": 6,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.encoders.seq_encoder",
        "description": "_REPO.GITHUB.CodeSearchNet.src.encoders.seq_encoder",
        "peekOfCode": "class SeqEncoder(Encoder):\n    @classmethod\n    def get_default_hyperparameters(cls) -> Dict[str, Any]:\n        encoder_hypers = {\n            \"token_vocab_size\": 10000,\n            \"token_vocab_count_threshold\": 10,\n            \"token_embedding_size\": 128,\n            \"use_subtokens\": False,\n            \"mark_subtoken_end\": False,\n            \"max_num_tokens\": 200,",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.encoders.seq_encoder",
        "documentation": {}
    },
    {
        "label": "ConvolutionalModel",
        "kind": 6,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.models.conv_model",
        "description": "_REPO.GITHUB.CodeSearchNet.src.models.conv_model",
        "peekOfCode": "class ConvolutionalModel(Model):\n    @classmethod\n    def get_default_hyperparameters(cls) -> Dict[str, Any]:\n        hypers = {}\n        for label in [\"code\", \"query\"]:\n            hypers.update(\n                {\n                    f\"{label}_{key}\": value\n                    for key, value in ConvolutionSeqEncoder.get_default_hyperparameters().items()\n                }",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.models.conv_model",
        "documentation": {}
    },
    {
        "label": "ConvSelfAttentionModel",
        "kind": 6,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.models.conv_self_att_model",
        "description": "_REPO.GITHUB.CodeSearchNet.src.models.conv_self_att_model",
        "peekOfCode": "class ConvSelfAttentionModel(Model):\n    @classmethod\n    def get_default_hyperparameters(cls) -> Dict[str, Any]:\n        hypers = {}\n        for label in [\"code\", \"query\"]:\n            hypers.update(\n                {\n                    f\"{label}_{key}\": value\n                    for key, value in ConvSelfAttentionEncoder.get_default_hyperparameters().items()\n                }",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.models.conv_self_att_model",
        "documentation": {}
    },
    {
        "label": "RepresentationType",
        "kind": 6,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.models.model",
        "description": "_REPO.GITHUB.CodeSearchNet.src.models.model",
        "peekOfCode": "class RepresentationType(Enum):\n    CODE = auto()\n    QUERY = auto()\ndef get_data_files_from_directory(\n    data_dirs: List[RichPath], max_files_per_dir: Optional[int] = None\n) -> List[RichPath]:\n    files = []  # type: List[str]\n    for data_dir in data_dirs:\n        dir_files = data_dir.get_filtered_files_in_dir(\"*.jsonl.gz\")\n        if max_files_per_dir:",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.models.model",
        "documentation": {}
    },
    {
        "label": "Model",
        "kind": 6,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.models.model",
        "description": "_REPO.GITHUB.CodeSearchNet.src.models.model",
        "peekOfCode": "class Model(ABC):\n    @classmethod\n    @abstractmethod\n    def get_default_hyperparameters(cls) -> Dict[str, Any]:\n        return {\n            \"batch_size\": 200,\n            \"optimizer\": \"Adam\",\n            \"seed\": 0,\n            \"dropout_keep_rate\": 0.9,\n            \"learning_rate\": 0.01,",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.models.model",
        "documentation": {}
    },
    {
        "label": "get_data_files_from_directory",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.models.model",
        "description": "_REPO.GITHUB.CodeSearchNet.src.models.model",
        "peekOfCode": "def get_data_files_from_directory(\n    data_dirs: List[RichPath], max_files_per_dir: Optional[int] = None\n) -> List[RichPath]:\n    files = []  # type: List[str]\n    for data_dir in data_dirs:\n        dir_files = data_dir.get_filtered_files_in_dir(\"*.jsonl.gz\")\n        if max_files_per_dir:\n            dir_files = sorted(dir_files)[: int(max_files_per_dir)]\n        files += dir_files\n    np.random.shuffle(",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.models.model",
        "documentation": {}
    },
    {
        "label": "parse_data_file",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.models.model",
        "description": "_REPO.GITHUB.CodeSearchNet.src.models.model",
        "peekOfCode": "def parse_data_file(\n    hyperparameters: Dict[str, Any],\n    code_encoder_class: Type[Encoder],\n    per_code_language_metadata: Dict[str, Dict[str, Any]],\n    query_encoder_class: Type[Encoder],\n    query_metadata: Dict[str, Any],\n    is_test: bool,\n    data_file: RichPath,\n) -> Dict[str, List[Tuple[bool, Dict[str, Any]]]]:\n    results: DefaultDict[str, List] = defaultdict(list)",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.models.model",
        "documentation": {}
    },
    {
        "label": "LoadedSamples",
        "kind": 5,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.models.model",
        "description": "_REPO.GITHUB.CodeSearchNet.src.models.model",
        "peekOfCode": "LoadedSamples = Dict[str, List[Dict[str, Any]]]\nSampleId = Tuple[str, int]\nclass RepresentationType(Enum):\n    CODE = auto()\n    QUERY = auto()\ndef get_data_files_from_directory(\n    data_dirs: List[RichPath], max_files_per_dir: Optional[int] = None\n) -> List[RichPath]:\n    files = []  # type: List[str]\n    for data_dir in data_dirs:",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.models.model",
        "documentation": {}
    },
    {
        "label": "SampleId",
        "kind": 5,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.models.model",
        "description": "_REPO.GITHUB.CodeSearchNet.src.models.model",
        "peekOfCode": "SampleId = Tuple[str, int]\nclass RepresentationType(Enum):\n    CODE = auto()\n    QUERY = auto()\ndef get_data_files_from_directory(\n    data_dirs: List[RichPath], max_files_per_dir: Optional[int] = None\n) -> List[RichPath]:\n    files = []  # type: List[str]\n    for data_dir in data_dirs:\n        dir_files = data_dir.get_filtered_files_in_dir(\"*.jsonl.gz\")",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.models.model",
        "documentation": {}
    },
    {
        "label": "NeuralBoWModel",
        "kind": 6,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.models.nbow_model",
        "description": "_REPO.GITHUB.CodeSearchNet.src.models.nbow_model",
        "peekOfCode": "class NeuralBoWModel(Model):\n    @classmethod\n    def get_default_hyperparameters(cls) -> Dict[str, Any]:\n        hypers = {}\n        for label in [\"code\", \"query\"]:\n            hypers.update(\n                {\n                    f\"{label}_{key}\": value\n                    for key, value in NBoWEncoder.get_default_hyperparameters().items()\n                }",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.models.nbow_model",
        "documentation": {}
    },
    {
        "label": "RNNModel",
        "kind": 6,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.models.rnn_model",
        "description": "_REPO.GITHUB.CodeSearchNet.src.models.rnn_model",
        "peekOfCode": "class RNNModel(Model):\n    @classmethod\n    def get_default_hyperparameters(cls) -> Dict[str, Any]:\n        hypers = {}\n        for label in [\"code\", \"query\"]:\n            hypers.update(\n                {\n                    f\"{label}_{key}\": value\n                    for key, value in RNNEncoder.get_default_hyperparameters().items()\n                }",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.models.rnn_model",
        "documentation": {}
    },
    {
        "label": "SelfAttentionModel",
        "kind": 6,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.models.self_att_model",
        "description": "_REPO.GITHUB.CodeSearchNet.src.models.self_att_model",
        "peekOfCode": "class SelfAttentionModel(Model):\n    @classmethod\n    def get_default_hyperparameters(cls) -> Dict[str, Any]:\n        hypers = {}\n        for label in [\"code\", \"query\"]:\n            hypers.update(\n                {\n                    f\"{label}_{key}\": value\n                    for key, value in SelfAttentionEncoder.get_default_hyperparameters().items()\n                }",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.models.self_att_model",
        "documentation": {}
    },
    {
        "label": "BpeVocabulary",
        "kind": 6,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.utils.bpevocabulary",
        "description": "_REPO.GITHUB.CodeSearchNet.src.utils.bpevocabulary",
        "peekOfCode": "class BpeVocabulary(typing.Sized):\n    \"\"\"\n    Encodes white-space separated text using byte-pair encoding.  See https://arxiv.org/abs/1508.07909 for details.\n    \"\"\"\n    def __init__(\n        self,\n        vocab_size: int = 8192,\n        pct_bpe: float = 0.2,\n        ngram_min: int = 2,\n        ngram_max: int = 8,",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.utils.bpevocabulary",
        "documentation": {}
    },
    {
        "label": "DEFAULT_EOW",
        "kind": 5,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.utils.bpevocabulary",
        "description": "_REPO.GITHUB.CodeSearchNet.src.utils.bpevocabulary",
        "peekOfCode": "DEFAULT_EOW = \"__eow\"\nDEFAULT_SOW = \"__sow\"\nDEFAULT_UNK = \"__unk\"\nDEFAULT_PAD = \"__pad\"\nclass BpeVocabulary(typing.Sized):\n    \"\"\"\n    Encodes white-space separated text using byte-pair encoding.  See https://arxiv.org/abs/1508.07909 for details.\n    \"\"\"\n    def __init__(\n        self,",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.utils.bpevocabulary",
        "documentation": {}
    },
    {
        "label": "DEFAULT_SOW",
        "kind": 5,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.utils.bpevocabulary",
        "description": "_REPO.GITHUB.CodeSearchNet.src.utils.bpevocabulary",
        "peekOfCode": "DEFAULT_SOW = \"__sow\"\nDEFAULT_UNK = \"__unk\"\nDEFAULT_PAD = \"__pad\"\nclass BpeVocabulary(typing.Sized):\n    \"\"\"\n    Encodes white-space separated text using byte-pair encoding.  See https://arxiv.org/abs/1508.07909 for details.\n    \"\"\"\n    def __init__(\n        self,\n        vocab_size: int = 8192,",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.utils.bpevocabulary",
        "documentation": {}
    },
    {
        "label": "DEFAULT_UNK",
        "kind": 5,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.utils.bpevocabulary",
        "description": "_REPO.GITHUB.CodeSearchNet.src.utils.bpevocabulary",
        "peekOfCode": "DEFAULT_UNK = \"__unk\"\nDEFAULT_PAD = \"__pad\"\nclass BpeVocabulary(typing.Sized):\n    \"\"\"\n    Encodes white-space separated text using byte-pair encoding.  See https://arxiv.org/abs/1508.07909 for details.\n    \"\"\"\n    def __init__(\n        self,\n        vocab_size: int = 8192,\n        pct_bpe: float = 0.2,",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.utils.bpevocabulary",
        "documentation": {}
    },
    {
        "label": "DEFAULT_PAD",
        "kind": 5,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.utils.bpevocabulary",
        "description": "_REPO.GITHUB.CodeSearchNet.src.utils.bpevocabulary",
        "peekOfCode": "DEFAULT_PAD = \"__pad\"\nclass BpeVocabulary(typing.Sized):\n    \"\"\"\n    Encodes white-space separated text using byte-pair encoding.  See https://arxiv.org/abs/1508.07909 for details.\n    \"\"\"\n    def __init__(\n        self,\n        vocab_size: int = 8192,\n        pct_bpe: float = 0.2,\n        ngram_min: int = 2,",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.utils.bpevocabulary",
        "documentation": {}
    },
    {
        "label": "run",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.utils.embeddingvis",
        "description": "_REPO.GITHUB.CodeSearchNet.src.utils.embeddingvis",
        "peekOfCode": "def run(arguments) -> None:\n    azure_info_path = arguments.get(\"--azure-info\", None)\n    model_path = RichPath.create(\n        arguments[\"MODEL_PATH\"], azure_info_path=azure_info_path\n    )\n    model = model_restore_helper.restore(path=model_path, is_train=False)\n    if arguments[\"--query\"]:\n        embeddings, elements = model.get_query_token_embeddings()\n    else:\n        embeddings, elements = model.get_code_token_embeddings(arguments[\"--language\"])",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.utils.embeddingvis",
        "documentation": {}
    },
    {
        "label": "save_file_pickle",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.utils.general_utils",
        "description": "_REPO.GITHUB.CodeSearchNet.src.utils.general_utils",
        "peekOfCode": "def save_file_pickle(fname: str, obj: Any) -> None:\n    with open(fname, \"wb\") as f:\n        pickle.dump(obj, f)\ndef load_file_pickle(fname: str) -> None:\n    with open(fname, \"rb\") as f:\n        obj = pickle.load(f)\n        return obj\ndef chunkify(df: pd.DataFrame, n: int) -> List[pd.DataFrame]:\n    \"turn pandas.dataframe into equal size n chunks.\"\n    return [df[i::n] for i in range(n)]",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.utils.general_utils",
        "documentation": {}
    },
    {
        "label": "load_file_pickle",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.utils.general_utils",
        "description": "_REPO.GITHUB.CodeSearchNet.src.utils.general_utils",
        "peekOfCode": "def load_file_pickle(fname: str) -> None:\n    with open(fname, \"rb\") as f:\n        obj = pickle.load(f)\n        return obj\ndef chunkify(df: pd.DataFrame, n: int) -> List[pd.DataFrame]:\n    \"turn pandas.dataframe into equal size n chunks.\"\n    return [df[i::n] for i in range(n)]",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.utils.general_utils",
        "documentation": {}
    },
    {
        "label": "chunkify",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.utils.general_utils",
        "description": "_REPO.GITHUB.CodeSearchNet.src.utils.general_utils",
        "peekOfCode": "def chunkify(df: pd.DataFrame, n: int) -> List[pd.DataFrame]:\n    \"turn pandas.dataframe into equal size n chunks.\"\n    return [df[i::n] for i in range(n)]",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.utils.general_utils",
        "documentation": {}
    },
    {
        "label": "run",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.utils.jsonl2iddata",
        "description": "_REPO.GITHUB.CodeSearchNet.src.utils.jsonl2iddata",
        "peekOfCode": "def run(arguments):\n    azure_info_path = arguments.get(\"--azure-info\", None)\n    input_folder = RichPath.create(arguments[\"INPUT_PATH\"], azure_info_path)\n    output_folder = RichPath.create(arguments[\"OUTPUT_PATH\"], azure_info_path)\n    with ChunkWriter(\n        output_folder,\n        file_prefix=\"codedata\",\n        max_chunk_size=500,\n        file_suffix=\".jsonl.gz\",\n    ) as chunked_writer:",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.utils.jsonl2iddata",
        "documentation": {}
    },
    {
        "label": "to_string",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.utils.nearestneighbor",
        "description": "_REPO.GITHUB.CodeSearchNet.src.utils.nearestneighbor",
        "peekOfCode": "def to_string(code: str, language: str) -> str:\n    lexer = get_lexer_by_name(language, stripall=True)\n    formatter = TerminalFormatter(linenos=True)\n    return highlight(code, lexer, formatter)\ndef run(arguments) -> None:\n    azure_info_path = arguments.get(\"--azure-info\", None)\n    data_path = RichPath.create(arguments[\"DATA_PATH\"], azure_info_path)\n    assert data_path.is_dir(), \"%s is not a folder\" % (data_path,)\n    hypers_override = arguments.get(\"--hypers-override\")\n    if hypers_override is not None:",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.utils.nearestneighbor",
        "documentation": {}
    },
    {
        "label": "run",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.utils.nearestneighbor",
        "description": "_REPO.GITHUB.CodeSearchNet.src.utils.nearestneighbor",
        "peekOfCode": "def run(arguments) -> None:\n    azure_info_path = arguments.get(\"--azure-info\", None)\n    data_path = RichPath.create(arguments[\"DATA_PATH\"], azure_info_path)\n    assert data_path.is_dir(), \"%s is not a folder\" % (data_path,)\n    hypers_override = arguments.get(\"--hypers-override\")\n    if hypers_override is not None:\n        hypers_override = json.loads(hypers_override)\n    else:\n        hypers_override = {}\n    model_path = RichPath.create(",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.utils.nearestneighbor",
        "documentation": {}
    },
    {
        "label": "df_to_jsonl",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.utils.pkldf2jsonl",
        "description": "_REPO.GITHUB.CodeSearchNet.src.utils.pkldf2jsonl",
        "peekOfCode": "def df_to_jsonl(\n    df: pd.DataFrame, RichPath_obj: RichPath, i: int, basefilename=\"codedata\"\n) -> str:\n    dest_filename = f\"{basefilename}_{str(i).zfill(5)}.jsonl.gz\"\n    RichPath_obj.join(dest_filename).save_as_compressed_file(\n        df.to_dict(orient=\"records\")\n    )\n    return str(RichPath_obj.join(dest_filename))\ndef chunked_save_df_to_jsonl(\n    df: pd.DataFrame,",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.utils.pkldf2jsonl",
        "documentation": {}
    },
    {
        "label": "chunked_save_df_to_jsonl",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.utils.pkldf2jsonl",
        "description": "_REPO.GITHUB.CodeSearchNet.src.utils.pkldf2jsonl",
        "peekOfCode": "def chunked_save_df_to_jsonl(\n    df: pd.DataFrame,\n    output_folder: RichPath,\n    num_chunks: int = None,\n    parallel: bool = True,\n) -> None:\n    \"Chunk DataFrame (n chunks = num cores) and save as jsonl files.\"\n    df.reset_index(drop=True, inplace=True)\n    # parallel saving to jsonl files on azure\n    n = cpu_count() if num_chunks is None else num_chunks",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.utils.pkldf2jsonl",
        "documentation": {}
    },
    {
        "label": "run_jobs_in_parallel",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.utils.py_utils",
        "description": "_REPO.GITHUB.CodeSearchNet.src.utils.py_utils",
        "peekOfCode": "def run_jobs_in_parallel(\n    all_jobs: List[JobType],\n    worker_fn: Callable[[int, JobType], Iterable[ResultType]],\n    received_result_callback: Callable[[ResultType], None],\n    finished_callback: Callable[[], None],\n    result_queue_size: int = 100,\n) -> None:\n    \"\"\"\n    Runs jobs in parallel and uses callbacks to collect results.\n    :param all_jobs: Job descriptions; one at a time will be parsed into worker_fn.",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.utils.py_utils",
        "documentation": {}
    },
    {
        "label": "JobType",
        "kind": 5,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.utils.py_utils",
        "description": "_REPO.GITHUB.CodeSearchNet.src.utils.py_utils",
        "peekOfCode": "JobType = TypeVar(\"JobType\")\nResultType = TypeVar(\"ResultType\")\ndef __parallel_queue_worker(\n    worker_id: int,\n    job_queue: multiprocessing.Queue,\n    result_queue: multiprocessing.Queue,\n    worker_fn: Callable[[int, JobType], Iterable[ResultType]],\n):\n    while True:\n        job = job_queue.get()",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.utils.py_utils",
        "documentation": {}
    },
    {
        "label": "ResultType",
        "kind": 5,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.utils.py_utils",
        "description": "_REPO.GITHUB.CodeSearchNet.src.utils.py_utils",
        "peekOfCode": "ResultType = TypeVar(\"ResultType\")\ndef __parallel_queue_worker(\n    worker_id: int,\n    job_queue: multiprocessing.Queue,\n    result_queue: multiprocessing.Queue,\n    worker_fn: Callable[[int, JobType], Iterable[ResultType]],\n):\n    while True:\n        job = job_queue.get()\n        # \"None\" is the signal for last job, put that back in for other workers and stop:",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.utils.py_utils",
        "documentation": {}
    },
    {
        "label": "Repo",
        "kind": 6,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.utils.repo_helper",
        "description": "_REPO.GITHUB.CodeSearchNet.src.utils.repo_helper",
        "peekOfCode": "class Repo:\n    \"\"\"\n    Because we don't have a good way to query the content of live repos.\n    Example usage:\n    # Instantiate object and retrieve code from repo: tensorflow/tensorflow\n    > rc = Repo(org='tensorflow', repo_name='tensorflow', dest_path='/some/existing/folder')\n    > rc.clone()  # gets the code by cloning if does not exist, or optionally pull the latest code.\n    # returns list of Path objects in repo that end in '.py'\n    > rc.get_filenames_with_extension('.py')\n    \"\"\"",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.utils.repo_helper",
        "documentation": {}
    },
    {
        "label": "NoisyIdentityInitializer",
        "kind": 6,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.utils.tfutils",
        "description": "_REPO.GITHUB.CodeSearchNet.src.utils.tfutils",
        "peekOfCode": "class NoisyIdentityInitializer(Initializer):\n    def __init__(self, noise: float = 1e-1):\n        self.__noise = noise\n        self.__identity_initializer = tf.initializers.identity()\n        self.__noise_initializer = tf.initializers.random_uniform(\n            minval=-self.__noise, maxval=self.__noise\n        )\n    def set_config(self):\n        return {\"noise\": self.__noise}\n    def __call__(self, shape, dtype=None, partition_info=None):",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.utils.tfutils",
        "documentation": {}
    },
    {
        "label": "convert_and_pad_token_sequence",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.utils.tfutils",
        "description": "_REPO.GITHUB.CodeSearchNet.src.utils.tfutils",
        "peekOfCode": "def convert_and_pad_token_sequence(\n    token_vocab: Union[Vocabulary, BpeVocabulary],\n    token_sequence: List[str],\n    output_tensor_size: int,\n    pad_from_left: bool = False,\n) -> Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Tensorise token sequence with padding; returning a mask for used elements as well.\n    Args:\n        token_vocab: Vocabulary or BPE encoder to use. We assume that token_vocab[0] is the padding symbol.",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.utils.tfutils",
        "documentation": {}
    },
    {
        "label": "write_to_feed_dict",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.utils.tfutils",
        "description": "_REPO.GITHUB.CodeSearchNet.src.utils.tfutils",
        "peekOfCode": "def write_to_feed_dict(feed_dict: Dict[tf.Tensor, Any], placeholder, val) -> None:\n    if len(val) == 0:\n        ph_shape = [\n            dim if dim is not None else 0 for dim in placeholder.shape.as_list()\n        ]\n        feed_dict[placeholder] = np.empty(ph_shape)\n    else:\n        feed_dict[placeholder] = val\nclass NoisyIdentityInitializer(Initializer):\n    def __init__(self, noise: float = 1e-1):",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.utils.tfutils",
        "documentation": {}
    },
    {
        "label": "get_activation",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.utils.tfutils",
        "description": "_REPO.GITHUB.CodeSearchNet.src.utils.tfutils",
        "peekOfCode": "def get_activation(activation_fun: Optional[str]):\n    if activation_fun is None:\n        return None\n    activation_fun = activation_fun.lower()\n    if activation_fun == \"linear\":\n        return None\n    if activation_fun == \"tanh\":\n        return tf.tanh\n    if activation_fun == \"relu\":\n        return tf.nn.relu",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.utils.tfutils",
        "documentation": {}
    },
    {
        "label": "pool_sequence_embedding",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.utils.tfutils",
        "description": "_REPO.GITHUB.CodeSearchNet.src.utils.tfutils",
        "peekOfCode": "def pool_sequence_embedding(\n    pool_mode: str,\n    sequence_token_embeddings: tf.Tensor,\n    sequence_lengths: tf.Tensor,\n    sequence_token_masks: tf.Tensor,\n) -> tf.Tensor:\n    \"\"\"\n    Takes a batch of sequences of token embeddings and applies a pooling function,\n    returning one representation for each sequence.\n    Args:",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.utils.tfutils",
        "documentation": {}
    },
    {
        "label": "BIG_NUMBER",
        "kind": 5,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.utils.tfutils",
        "description": "_REPO.GITHUB.CodeSearchNet.src.utils.tfutils",
        "peekOfCode": "BIG_NUMBER = 1e7\ndef convert_and_pad_token_sequence(\n    token_vocab: Union[Vocabulary, BpeVocabulary],\n    token_sequence: List[str],\n    output_tensor_size: int,\n    pad_from_left: bool = False,\n) -> Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Tensorise token sequence with padding; returning a mask for used elements as well.\n    Args:",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.utils.tfutils",
        "documentation": {}
    },
    {
        "label": "square_to_condensed",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.utils.visutils",
        "description": "_REPO.GITHUB.CodeSearchNet.src.utils.visutils",
        "peekOfCode": "def square_to_condensed(i, j, n):\n    assert i != j, \"no diagonal elements in condensed matrix\"\n    if i < j:\n        i, j = j, i\n    return int(n * j - j * (j + 1) / 2 + i - 1 - j)",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.utils.visutils",
        "documentation": {}
    },
    {
        "label": "to_highlighted_html",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.error_analysis",
        "description": "_REPO.GITHUB.CodeSearchNet.src.error_analysis",
        "peekOfCode": "def to_highlighted_html(code: str, language: str) -> str:\n    lexer = get_lexer_by_name(language, stripall=True)\n    formatter = HtmlFormatter(linenos=True)\n    return highlight(code, lexer, formatter)\ndef generate_html_error_report(\n    tester: MrrSearchTester,\n    data: List[Dict[str, Any]],\n    max_num_examples: Optional[int],\n    outfile: str,\n    filter_language: Optional[str] = None,",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.error_analysis",
        "documentation": {}
    },
    {
        "label": "generate_html_error_report",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.error_analysis",
        "description": "_REPO.GITHUB.CodeSearchNet.src.error_analysis",
        "peekOfCode": "def generate_html_error_report(\n    tester: MrrSearchTester,\n    data: List[Dict[str, Any]],\n    max_num_examples: Optional[int],\n    outfile: str,\n    filter_language: Optional[str] = None,\n) -> None:\n    error_log = []  # type: List[MrrSearchTester.QueryResult]\n    # Sample the data if requested\n    data = sample_data(data=data, max_num_examples=max_num_examples)",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.error_analysis",
        "documentation": {}
    },
    {
        "label": "sample_data",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.error_analysis",
        "description": "_REPO.GITHUB.CodeSearchNet.src.error_analysis",
        "peekOfCode": "def sample_data(\n    data: List[Dict[str, Any]], max_num_examples: Optional[int]\n) -> List[Dict[str, Any]]:\n    \"\"\"\n    Sample max_num_examples from the data.\n    Args:\n        data: List[Dict[str, Any]]\n        max_num_examples:  either an int or if a string will attempt conversion to an int.\n    Returns:\n        data: List[Dict[str, Any]]",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.error_analysis",
        "documentation": {}
    },
    {
        "label": "run",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.error_analysis",
        "description": "_REPO.GITHUB.CodeSearchNet.src.error_analysis",
        "peekOfCode": "def run(arguments):\n    max_num_examples = (\n        int(arguments.get(\"--max-num-examples\"))\n        if arguments.get(\"--max-num-examples\")\n        else None\n    )\n    azure_info_path = arguments.get(\"--azure-info\", None)\n    test_data_dirs = expand_data_path(arguments[\"DATA_PATH\"], azure_info_path)\n    if arguments[\"--hypers-override\"] is not None:\n        hypers_override = json.loads(arguments[\"--hypers-override\"])",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.error_analysis",
        "documentation": {}
    },
    {
        "label": "HEADER",
        "kind": 5,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.error_analysis",
        "description": "_REPO.GITHUB.CodeSearchNet.src.error_analysis",
        "peekOfCode": "HEADER = f\"\"\"\n<!doctype html>\n<html lang=\"en\">\n  <head>\n    <!-- Required meta tags -->\n    <meta charset=\"utf-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1, shrink-to-fit=no\">\n    <!-- Bootstrap CSS -->\n    <link rel=\"stylesheet\" href=\"https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/css/bootstrap.min.css\" integrity=\"sha384-MCw98/SFnGE8fJT3GXwEOngsV7Zt27NXFoaoApmYm81iuXoPkFOJwJ8ERdknLPMO\" crossorigin=\"anonymous\">\n    <title>Error Analysis</title>",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.error_analysis",
        "documentation": {}
    },
    {
        "label": "FOOTER",
        "kind": 5,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.error_analysis",
        "description": "_REPO.GITHUB.CodeSearchNet.src.error_analysis",
        "peekOfCode": "FOOTER = \"\"\"\n</body></html>\n\"\"\"\ndef to_highlighted_html(code: str, language: str) -> str:\n    lexer = get_lexer_by_name(language, stripall=True)\n    formatter = HtmlFormatter(linenos=True)\n    return highlight(code, lexer, formatter)\ndef generate_html_error_report(\n    tester: MrrSearchTester,\n    data: List[Dict[str, Any]],",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.error_analysis",
        "documentation": {}
    },
    {
        "label": "get_model_class_from_name",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.model_restore_helper",
        "description": "_REPO.GITHUB.CodeSearchNet.src.model_restore_helper",
        "peekOfCode": "def get_model_class_from_name(model_name: str) -> Type[Model]:\n    model_name = model_name.lower()\n    if model_name in [\"neuralbow\", \"neuralbowmodel\"]:\n        return NeuralBoWModel\n    elif model_name in [\"rnn\", \"rnnmodel\"]:\n        return RNNModel\n    elif model_name in {\"selfatt\", \"selfattention\", \"selfattentionmodel\"}:\n        return SelfAttentionModel\n    elif model_name in {\"1dcnn\", \"convolutionalmodel\"}:\n        return ConvolutionalModel",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.model_restore_helper",
        "documentation": {}
    },
    {
        "label": "restore",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.model_restore_helper",
        "description": "_REPO.GITHUB.CodeSearchNet.src.model_restore_helper",
        "peekOfCode": "def restore(\n    path: RichPath, is_train: bool, hyper_overrides: Optional[Dict[str, Any]] = None\n) -> Model:\n    saved_data = path.read_as_pickle()\n    if hyper_overrides is not None:\n        saved_data[\"hyperparameters\"].update(hyper_overrides)\n    model_class = get_model_class_from_name(saved_data[\"model_type\"])\n    model = model_class(saved_data[\"hyperparameters\"], saved_data.get(\"run_name\"))\n    model.query_metadata.update(saved_data[\"query_metadata\"])\n    for (language, language_metadata) in saved_data[",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.model_restore_helper",
        "documentation": {}
    },
    {
        "label": "MrrSearchTester",
        "kind": 6,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.model_test",
        "description": "_REPO.GITHUB.CodeSearchNet.src.model_test",
        "peekOfCode": "class MrrSearchTester:\n    def __init__(\n        self,\n        model_path: RichPath,\n        test_batch_size: int = 1000,\n        distance_metric: str = \"cosine\",\n        quiet: bool = False,\n        hypers_override: Optional[Dict[str, Any]] = None,\n    ) -> None:\n        self.__model = model_restore_helper.restore(",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.model_test",
        "documentation": {}
    },
    {
        "label": "compute_ranks",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.model_test",
        "description": "_REPO.GITHUB.CodeSearchNet.src.model_test",
        "peekOfCode": "def compute_ranks(\n    src_representations: np.ndarray,\n    tgt_representations: np.ndarray,\n    distance_metric: str,\n) -> Tuple[np.array, np.array]:\n    distances = cdist(src_representations, tgt_representations, metric=distance_metric)\n    # By construction the diagonal contains the correct elements\n    correct_elements = np.expand_dims(np.diag(distances), axis=-1)\n    return np.sum(distances <= correct_elements, axis=-1), distances\nclass MrrSearchTester:",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.model_test",
        "documentation": {}
    },
    {
        "label": "expand_data_path",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.model_test",
        "description": "_REPO.GITHUB.CodeSearchNet.src.model_test",
        "peekOfCode": "def expand_data_path(data_path: str, azure_info_path: Optional[str]) -> List[RichPath]:\n    \"\"\"\n    Args:\n        data_path: A path to either a file or a directory. If it's a file, we interpret it as a list of\n            data directories.\n    Returns:\n        List of data directories (potentially just data_path)\n    \"\"\"\n    data_rpath = RichPath.create(data_path, azure_info_path)\n    if data_rpath.is_dir():",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.model_test",
        "documentation": {}
    },
    {
        "label": "filter_untokenizable_code",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.model_test",
        "description": "_REPO.GITHUB.CodeSearchNet.src.model_test",
        "peekOfCode": "def filter_untokenizable_code(data: Iterable[Dict[str, Any]]) -> List[Dict[str, Any]]:\n    \"\"\"Filter out data where field code_tokens is empty.\"\"\"\n    return [d for d in data if d[\"code_tokens\"]]\ndef log_row_count_diff(\n    original_data: Iterable[Any], filtered_data: Iterable[Any], label: str\n) -> None:\n    \"\"\"Compute the difference between row counts and log appropriately.\"\"\"\n    original_row_count = len(list(original_data))\n    filtered_row_count = len(list(filtered_data))\n    assert original_row_count > 0, \"original_data does not contain any rows.\"",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.model_test",
        "documentation": {}
    },
    {
        "label": "log_row_count_diff",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.model_test",
        "description": "_REPO.GITHUB.CodeSearchNet.src.model_test",
        "peekOfCode": "def log_row_count_diff(\n    original_data: Iterable[Any], filtered_data: Iterable[Any], label: str\n) -> None:\n    \"\"\"Compute the difference between row counts and log appropriately.\"\"\"\n    original_row_count = len(list(original_data))\n    filtered_row_count = len(list(filtered_data))\n    assert original_row_count > 0, \"original_data does not contain any rows.\"\n    assert (\n        filtered_row_count <= original_row_count\n    ), f\"filtered_data {filtered_row_count:,} has a larger row count than original_data {original_row_count:,}.\"",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.model_test",
        "documentation": {}
    },
    {
        "label": "get_dataset_from",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.model_test",
        "description": "_REPO.GITHUB.CodeSearchNet.src.model_test",
        "peekOfCode": "def get_dataset_from(\n    data_dirs: List[RichPath],\n    use_func_names: bool = False,\n    max_files_per_dir: Optional[int] = None,\n) -> List[Dict[str, Any]]:\n    data_files = sorted(get_data_files_from_directory(data_dirs, max_files_per_dir))\n    data = list(chain(*chain(list(f.read_by_file_suffix()) for f in data_files)))\n    if use_func_names:\n        # This task tries to match the function name to the code, by setting the function name as the query\n        for sample in data:",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.model_test",
        "documentation": {}
    },
    {
        "label": "compute_evaluation_metrics",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.model_test",
        "description": "_REPO.GITHUB.CodeSearchNet.src.model_test",
        "peekOfCode": "def compute_evaluation_metrics(\n    model_path: RichPath,\n    arguments,\n    azure_info_path: str,\n    valid_data_dirs: List[RichPath],\n    test_data_dirs: List[RichPath],\n    max_files_per_dir: Optional[int] = None,\n):\n    tester = MrrSearchTester(\n        model_path,",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.model_test",
        "documentation": {}
    },
    {
        "label": "query_model",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.predict",
        "description": "_REPO.GITHUB.CodeSearchNet.src.predict",
        "peekOfCode": "def query_model(query, model, indices, language, topk=100):\n    query_embedding = model.get_query_representations(\n        [\n            {\n                \"docstring_tokens\": tokenize_docstring_from_string(query),\n                \"language\": language,\n            }\n        ]\n    )[0]\n    idxs, distances = indices.get_nns_by_vector(",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.predict",
        "documentation": {}
    },
    {
        "label": "load_relevances",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.relevanceeval",
        "description": "_REPO.GITHUB.CodeSearchNet.src.relevanceeval",
        "peekOfCode": "def load_relevances(filepath: str) -> Dict[str, Dict[str, Dict[str, float]]]:\n    relevance_annotations = pd.read_csv(filepath)\n    per_query_language = relevance_annotations.pivot_table(\n        index=[\"Query\", \"Language\", \"GitHubUrl\"], values=\"Relevance\", aggfunc=np.mean\n    )\n    # Map language -> query -> url -> float\n    relevances = defaultdict(\n        lambda: defaultdict(dict)\n    )  # type: Dict[str, Dict[str, Dict[str, float]]]\n    for (query, language, url), relevance in per_query_language[\"Relevance\"].items():",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.relevanceeval",
        "documentation": {}
    },
    {
        "label": "load_predictions",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.relevanceeval",
        "description": "_REPO.GITHUB.CodeSearchNet.src.relevanceeval",
        "peekOfCode": "def load_predictions(\n    filepath: str, max_urls_per_language: int = 300\n) -> Dict[str, Dict[str, List[str]]]:\n    prediction_data = pd.read_csv(filepath)\n    # Map language -> query -> Ranked List of URL\n    predictions = defaultdict(lambda: defaultdict(list))\n    for _, row in prediction_data.iterrows():\n        predictions[row[\"language\"].lower()][row[\"query\"].lower()].append(row[\"url\"])\n    for query_data in predictions.values():\n        for query, ranked_urls in query_data.items():",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.relevanceeval",
        "documentation": {}
    },
    {
        "label": "coverage_per_language",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.relevanceeval",
        "description": "_REPO.GITHUB.CodeSearchNet.src.relevanceeval",
        "peekOfCode": "def coverage_per_language(\n    predictions: Dict[str, List[str]],\n    relevance_scores: Dict[str, Dict[str, float]],\n    with_positive_relevance: bool = False,\n) -> float:\n    \"\"\"\n    Compute the % of annotated URLs that appear in the algorithm's predictions.\n    \"\"\"\n    num_annotations = 0\n    num_covered = 0",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.relevanceeval",
        "documentation": {}
    },
    {
        "label": "ndcg",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.relevanceeval",
        "description": "_REPO.GITHUB.CodeSearchNet.src.relevanceeval",
        "peekOfCode": "def ndcg(\n    predictions: Dict[str, List[str]],\n    relevance_scores: Dict[str, Dict[str, float]],\n    ignore_rank_of_non_annotated_urls: bool = True,\n) -> float:\n    num_results = 0\n    ndcg_sum = 0\n    for query, query_relevance_annotations in relevance_scores.items():\n        current_rank = 1\n        query_dcg = 0",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.relevanceeval",
        "documentation": {}
    },
    {
        "label": "run",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.relevanceeval",
        "description": "_REPO.GITHUB.CodeSearchNet.src.relevanceeval",
        "peekOfCode": "def run(arguments):\n    relevance_scores = load_relevances(arguments[\"RELEVANCE_ANNOTATIONS_CSV_PATH\"])\n    predictions = load_predictions(arguments[\"MODEL_PREDICTIONS_CSV\"])\n    languages_predicted = sorted(set(predictions.keys()))\n    # Now Compute the various evaluation results\n    print(\"% of URLs in predictions that exist in the annotation dataset:\")\n    for language in languages_predicted:\n        print(\n            f\"\\t{language}: {coverage_per_language(predictions[language], relevance_scores[language])*100:.2f}%\"\n        )",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.relevanceeval",
        "documentation": {}
    },
    {
        "label": "run",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.test",
        "description": "_REPO.GITHUB.CodeSearchNet.src.test",
        "peekOfCode": "def run(arguments):\n    azure_info_path = arguments.get(\"--azure-info\", None)\n    # if you do not pass arguments for train/valid/test data default to files checked into repo.\n    if not arguments[\"VALID_DATA_PATH\"]:\n        dir_path = Path(__file__).parent.absolute()\n        print(dir_path)\n        arguments[\"VALID_DATA_PATH\"] = str(dir_path / \"data_dirs_valid.txt\")\n        arguments[\"TEST_DATA_PATH\"] = str(dir_path / \"data_dirs_test.txt\")\n    valid_data_dirs = test.expand_data_path(\n        arguments[\"VALID_DATA_PATH\"], azure_info_path",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.test",
        "documentation": {}
    },
    {
        "label": "run_train",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.train",
        "description": "_REPO.GITHUB.CodeSearchNet.src.train",
        "peekOfCode": "def run_train(\n    model_class: Type[Model],\n    train_data_dirs: List[RichPath],\n    valid_data_dirs: List[RichPath],\n    save_folder: str,\n    hyperparameters: Dict[str, Any],\n    azure_info_path: Optional[str],\n    run_name: str,\n    quiet: bool = False,\n    max_files_per_dir: Optional[int] = None,",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.train",
        "documentation": {}
    },
    {
        "label": "make_run_id",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.train",
        "description": "_REPO.GITHUB.CodeSearchNet.src.train",
        "peekOfCode": "def make_run_id(arguments: Dict[str, Any]) -> str:\n    \"\"\"Choose a run ID, based on the --save-name parameter, the PHILLY_JOB_ID and the current time.\"\"\"\n    philly_id = os.environ.get(\"PHILLY_JOB_ID\")\n    if philly_id is not None:\n        return philly_id\n    user_save_name = arguments.get(\"--run-name\")\n    if user_save_name is not None:\n        user_save_name = (\n            user_save_name[: -len(\".pkl\")]\n            if user_save_name.endswith(\".pkl\")",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.train",
        "documentation": {}
    },
    {
        "label": "run",
        "kind": 2,
        "importPath": "_REPO.GITHUB.CodeSearchNet.src.train",
        "description": "_REPO.GITHUB.CodeSearchNet.src.train",
        "peekOfCode": "def run(arguments, tag_in_vcs=False) -> None:\n    azure_info_path = arguments.get(\"--azure-info\", None)\n    testrun = arguments.get(\"--testrun\")\n    max_files_per_dir = arguments.get(\"--max-files-per-dir\")\n    dir_path = Path(__file__).parent.absolute()\n    # if you do not pass arguments for train/valid/test data default to files checked into repo.\n    if not arguments[\"TRAIN_DATA_PATH\"]:\n        arguments[\"TRAIN_DATA_PATH\"] = str(dir_path / \"data_dirs_train.txt\")\n        arguments[\"VALID_DATA_PATH\"] = str(dir_path / \"data_dirs_valid.txt\")\n        arguments[\"TEST_DATA_PATH\"] = str(dir_path / \"data_dirs_test.txt\")",
        "detail": "_REPO.GITHUB.CodeSearchNet.src.train",
        "documentation": {}
    },
    {
        "label": "run_fake_ingest",
        "kind": 2,
        "importPath": "_REPO.GITHUB.collectd-elasticsearch.tests.integration.sink",
        "description": "_REPO.GITHUB.collectd-elasticsearch.tests.integration.sink",
        "peekOfCode": "def run_fake_ingest(metric_data):\n    class FakeCollectdIngest(BaseHTTPRequestHandler):\n        def do_POST(self):\n            body = self.rfile.read(int(self.headers.getheader('Content-Length')))\n            metric_data.extend(json.loads(body))\n            self.send_response(200)\n            self.send_header(\"Content-Type\", \"text/ascii\")\n            self.send_header(\"Content-Length\", \"2\")\n            self.end_headers()\n            self.wfile.write(\"OK\")",
        "detail": "_REPO.GITHUB.collectd-elasticsearch.tests.integration.sink",
        "documentation": {}
    },
    {
        "label": "serve_metric_data",
        "kind": 2,
        "importPath": "_REPO.GITHUB.collectd-elasticsearch.tests.integration.sink",
        "description": "_REPO.GITHUB.collectd-elasticsearch.tests.integration.sink",
        "peekOfCode": "def serve_metric_data(metric_data):\n    class MetricDataSpewer(BaseHTTPRequestHandler):\n        def do_GET(self):\n            data = json.dumps(metric_data)\n            self.send_response(200)\n            self.send_header(\"Content-Type\", \"application/json\")\n            self.send_header(\"Content-Length\", str(len(data)))\n            self.end_headers()\n            print data\n            self.rfile.write(data)",
        "detail": "_REPO.GITHUB.collectd-elasticsearch.tests.integration.sink",
        "documentation": {}
    },
    {
        "label": "get_metric_data",
        "kind": 2,
        "importPath": "_REPO.GITHUB.collectd-elasticsearch.tests.integration.test",
        "description": "_REPO.GITHUB.collectd-elasticsearch.tests.integration.test",
        "peekOfCode": "def get_metric_data():\n    # Use httplib instead of requests so we don't have to install stuff with pip\n    conn = httplib.HTTPConnection(\"fake_sfx\", 8080)\n    conn.request(\"GET\", \"/\")\n    resp = conn.getresponse()\n    conn.close()\n    return json.loads(resp.read())\ndef wait_for_metrics_from_each_cluster():\n    start = time()\n    for cluster in ['es-' + v for v in VERSIONS_TESTED]:",
        "detail": "_REPO.GITHUB.collectd-elasticsearch.tests.integration.test",
        "documentation": {}
    },
    {
        "label": "wait_for_metrics_from_each_cluster",
        "kind": 2,
        "importPath": "_REPO.GITHUB.collectd-elasticsearch.tests.integration.test",
        "description": "_REPO.GITHUB.collectd-elasticsearch.tests.integration.test",
        "peekOfCode": "def wait_for_metrics_from_each_cluster():\n    start = time()\n    for cluster in ['es-' + v for v in VERSIONS_TESTED]:\n        print 'Waiting for metrics from cluster %s...' % (cluster,)\n        eventually_true(lambda: any([cluster in m.get('plugin_instance') for m in get_metric_data()]),\n                        TIMEOUT_SECS - (time() - start))\n        print 'Found!'\ndef eventually_true(f, timeout_secs):\n    start = time()\n    while True:",
        "detail": "_REPO.GITHUB.collectd-elasticsearch.tests.integration.test",
        "documentation": {}
    },
    {
        "label": "eventually_true",
        "kind": 2,
        "importPath": "_REPO.GITHUB.collectd-elasticsearch.tests.integration.test",
        "description": "_REPO.GITHUB.collectd-elasticsearch.tests.integration.test",
        "peekOfCode": "def eventually_true(f, timeout_secs):\n    start = time()\n    while True:\n        try:\n            assert f()\n        except AssertionError:\n            if time() - start > timeout_secs:\n                raise\n            sleep(0.5)\n        else:",
        "detail": "_REPO.GITHUB.collectd-elasticsearch.tests.integration.test",
        "documentation": {}
    },
    {
        "label": "VERSIONS_TESTED",
        "kind": 5,
        "importPath": "_REPO.GITHUB.collectd-elasticsearch.tests.integration.test",
        "description": "_REPO.GITHUB.collectd-elasticsearch.tests.integration.test",
        "peekOfCode": "VERSIONS_TESTED = [\n    '1.7.6',\n    '2.4.5',\n    '5.3.2',\n]\nTIMEOUT_SECS = 60\ndef get_metric_data():\n    # Use httplib instead of requests so we don't have to install stuff with pip\n    conn = httplib.HTTPConnection(\"fake_sfx\", 8080)\n    conn.request(\"GET\", \"/\")",
        "detail": "_REPO.GITHUB.collectd-elasticsearch.tests.integration.test",
        "documentation": {}
    },
    {
        "label": "TIMEOUT_SECS",
        "kind": 5,
        "importPath": "_REPO.GITHUB.collectd-elasticsearch.tests.integration.test",
        "description": "_REPO.GITHUB.collectd-elasticsearch.tests.integration.test",
        "peekOfCode": "TIMEOUT_SECS = 60\ndef get_metric_data():\n    # Use httplib instead of requests so we don't have to install stuff with pip\n    conn = httplib.HTTPConnection(\"fake_sfx\", 8080)\n    conn.request(\"GET\", \"/\")\n    resp = conn.getresponse()\n    conn.close()\n    return json.loads(resp.read())\ndef wait_for_metrics_from_each_cluster():\n    start = time()",
        "detail": "_REPO.GITHUB.collectd-elasticsearch.tests.integration.test",
        "documentation": {}
    },
    {
        "label": "EsSimulatorHandler",
        "kind": 6,
        "importPath": "_REPO.GITHUB.collectd-elasticsearch.tests.simulate",
        "description": "_REPO.GITHUB.collectd-elasticsearch.tests.simulate",
        "peekOfCode": "class EsSimulatorHandler(BaseHTTPRequestHandler):\n    def do_GET(self):\n        self.send_response(200)\n        self.send_header('Content-type', 'application/json')\n        self.end_headers()\n        self.serve_path(self.path)\n        return\n    def serve_path(self, path):\n        file_path = os.path.join(base_path, path[1:])\n        if os.path.isdir(file_path):",
        "detail": "_REPO.GITHUB.collectd-elasticsearch.tests.simulate",
        "documentation": {}
    },
    {
        "label": "PORT_NUMBER",
        "kind": 5,
        "importPath": "_REPO.GITHUB.collectd-elasticsearch.tests.simulate",
        "description": "_REPO.GITHUB.collectd-elasticsearch.tests.simulate",
        "peekOfCode": "PORT_NUMBER = 9200\nif len(sys.argv) == 2:\n    base_path = sys.argv[1]\n    if os.path.isdir(base_path):\n        print \"simulating ES server from %s\" % base_path\n    else:\n        print \"invalid or missing directory %s\" % base_path\n        sys.exit(1)\nelse:\n    print \"usage: ./simulate.py directory_path. Example ./simulate.py \\",
        "detail": "_REPO.GITHUB.collectd-elasticsearch.tests.simulate",
        "documentation": {}
    },
    {
        "label": "load_file",
        "kind": 2,
        "importPath": "_REPO.GITHUB.collectd-elasticsearch.tools.generate_defaults",
        "description": "_REPO.GITHUB.collectd-elasticsearch.tools.generate_defaults",
        "peekOfCode": "def load_file(file):\n    \"\"\" Converts an array of file paths into an array of json defined objects\n    :param file: An array of filepath strings\n    :return: An array of loaded json objects\n    \"\"\"\n    CONFIGS = []\n    with open(file, 'r') as f:\n        j = json.load(f)\n    f.close()\n    CONFIGS.append(j)",
        "detail": "_REPO.GITHUB.collectd-elasticsearch.tools.generate_defaults",
        "documentation": {}
    },
    {
        "label": "process_json_minimal",
        "kind": 2,
        "importPath": "_REPO.GITHUB.collectd-elasticsearch.tools.generate_defaults",
        "description": "_REPO.GITHUB.collectd-elasticsearch.tools.generate_defaults",
        "peekOfCode": "def process_json_minimal(conf):\n    \"\"\" Processes an array of SignalFx Default Dashboard json objects\n    :param conf: An array of json loaded objects\n    :return: A string representation of a python dictionary named \"DEFAULTS\"\n    \"\"\"\n    d = set()\n    DEFAULTS = \"DEFAULTS = {\\n\"\n    DEFAULTS += \"    # AUTOMATICALLY GENERATED METRIC NAMES\\n\"\n    DEFAULTS += \"    # TO INCLUDE BY DEFAULT\\n\"\n    # Iterate over each file passed in",
        "detail": "_REPO.GITHUB.collectd-elasticsearch.tools.generate_defaults",
        "documentation": {}
    },
    {
        "label": "save_file",
        "kind": 2,
        "importPath": "_REPO.GITHUB.collectd-elasticsearch.tools.generate_defaults",
        "description": "_REPO.GITHUB.collectd-elasticsearch.tools.generate_defaults",
        "peekOfCode": "def save_file(text, file):\n    \"\"\"Saves the supplied string to a file\n    :param text: The string that should be written out\n    :param file: The path and file name to write out\n    \"\"\"\n    f = open(file, 'w')\n    f.write(text)\n    f.close()\ndef run(files):\n    \"\"\"Main function of the script.",
        "detail": "_REPO.GITHUB.collectd-elasticsearch.tools.generate_defaults",
        "documentation": {}
    },
    {
        "label": "run",
        "kind": 2,
        "importPath": "_REPO.GITHUB.collectd-elasticsearch.tools.generate_defaults",
        "description": "_REPO.GITHUB.collectd-elasticsearch.tools.generate_defaults",
        "peekOfCode": "def run(files):\n    \"\"\"Main function of the script.\n    \"\"\"\n    config = []\n    for file in files:\n        try:\n            # Load the json files\n            config += load_file(file)\n            print \"LOADED: %s\" % file\n        except Exception as e:",
        "detail": "_REPO.GITHUB.collectd-elasticsearch.tools.generate_defaults",
        "documentation": {}
    },
    {
        "label": "Cluster",
        "kind": 6,
        "importPath": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "description": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "peekOfCode": "class Cluster(object):\n    def __init__(self):\n        self.collection_interval = 10\n        self.es_host = \"localhost\"\n        self.es_port = 9200\n        self.es_url_scheme = \"http\"\n        self.es_username = \"\"\n        self.es_password = \"\"\n        self.es_cluster = None\n        self.es_version = None",
        "detail": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "documentation": {}
    },
    {
        "label": "CollectdMock",
        "kind": 6,
        "importPath": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "description": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "peekOfCode": "class CollectdMock(object):\n    def __init__(self):\n        self.value_mock = CollectdValuesMock\n    def debug(self, msg):\n        print 'DEBUG: {0}'.format(msg)\n    def info(self, msg):\n        print 'INFO: {0}'.format(msg)\n    def notice(self, msg):\n        print 'NOTICE: {0}'.format(msg)\n    def warning(self, msg):",
        "detail": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "documentation": {}
    },
    {
        "label": "CollectdValuesMock",
        "kind": 6,
        "importPath": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "description": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "peekOfCode": "class CollectdValuesMock(object):\n    def dispatch(self):\n        print self\n    def __str__(self):\n        attrs = []\n        for name in dir(self):\n            if not name.startswith('_') and name is not 'dispatch':\n                attrs.append(\"{0}={1}\".format(name, getattr(self, name)))\n        return \"<CollectdValues {0}>\".format(' '.join(attrs))\nclass CollectdLogHandler(logging.Handler):",
        "detail": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "documentation": {}
    },
    {
        "label": "CollectdLogHandler",
        "kind": 6,
        "importPath": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "description": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "peekOfCode": "class CollectdLogHandler(logging.Handler):\n    \"\"\"Log handler to forward statements to collectd\n    A custom log handler that forwards log messages raised\n    at level debug, info, notice, warning, and error\n    to collectd's built in logging.  Suppresses extraneous\n    info and debug statements using a \"verbose\" boolean\n    Inherits from logging.Handler\n    Arguments\n        plugin -- name of the plugin (default 'unknown')\n        verbose -- enable/disable verbose messages (default False)",
        "detail": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "documentation": {}
    },
    {
        "label": "CollectdLogger",
        "kind": 6,
        "importPath": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "description": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "peekOfCode": "class CollectdLogger(logging.Logger):\n    \"\"\"Logs all collectd log levels via python's logging library\n    Custom python logger that forwards log statements at\n    level: debug, info, notice, warning, error\n    Inherits from logging.Logger\n    Arguments\n    name -- name of the logger\n    level -- log level to filter by\n    \"\"\"\n    def __init__(self, name, level=logging.NOTSET):",
        "detail": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "documentation": {}
    },
    {
        "label": "read_callback",
        "kind": 2,
        "importPath": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "description": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "peekOfCode": "def read_callback():\n    \"\"\"called by collectd to gather stats. It is called per collection\n    interval.\n    If this method throws, the plugin will be skipped for an increasing amount\n    of time until it returns normally again\"\"\"\n    log.info('Read callback called')\n    for c in CLUSTERS:\n        c.fetch_stats()\ndef str_to_bool(value):\n    \"\"\"Python 2.x does not have a casting mechanism for booleans.  The built in",
        "detail": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "documentation": {}
    },
    {
        "label": "str_to_bool",
        "kind": 2,
        "importPath": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "description": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "peekOfCode": "def str_to_bool(value):\n    \"\"\"Python 2.x does not have a casting mechanism for booleans.  The built in\n    bool() will return true for any string with a length greater than 0.  It\n    does not cast a string with the text \"true\" or \"false\" to the\n    corresponding bool value.  This method is a casting function.  It is\n    insensitive to case and leading/trailing spaces.  An Exception is raised\n    if a cast can not be made.\n    \"\"\"\n    if str(value).strip().lower() == \"true\":\n        return True",
        "detail": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "documentation": {}
    },
    {
        "label": "configure_callback",
        "kind": 2,
        "importPath": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "description": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "peekOfCode": "def configure_callback(conf):\n    \"\"\"called by collectd to configure the plugin. This is called only once\"\"\"\n    c = Cluster()\n    for node in conf.children:\n        if node.key == 'Host':\n            c.es_host = node.values[0]\n        elif node.key == 'Port':\n            c.es_port = int(node.values[0])\n        elif node.key == 'Protocol':\n            c.es_url_scheme = node.values[0]",
        "detail": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "documentation": {}
    },
    {
        "label": "remove_deprecated_elements",
        "kind": 2,
        "importPath": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "description": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "peekOfCode": "def remove_deprecated_elements(deprecated, elements, version):\n    \"\"\"Remove deprecated items from a list or dictionary\"\"\"\n    # Attempt to parse the major, minor, and revision\n    (major, minor, revision) = version.split('.')\n    # Sanitize alphas and betas from revision number\n    revision = revision.split('-')[0]\n    # Iterate over deprecation lists and remove any keys that were deprecated\n    # prior to the current version\n    for dep in deprecated:\n        if (major >= dep['major']) \\",
        "detail": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "documentation": {}
    },
    {
        "label": "sanitize_type_instance",
        "kind": 2,
        "importPath": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "description": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "peekOfCode": "def sanitize_type_instance(index_name):\n    \"\"\"\n    collectd limit the character set in type_instance to ascii and forbids\n    the '/' character. This method does a lossy conversion to ascii and\n    replaces the reserved character with '_'\n    \"\"\"\n    ascii_index_name = index_name.encode('ascii', 'ignore')\n    # '/' is reserved, so we substitute it with '_' instead\n    return ascii_index_name.replace('/', '_')\ndef dig_it_up(obj, path):",
        "detail": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "documentation": {}
    },
    {
        "label": "dig_it_up",
        "kind": 2,
        "importPath": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "description": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "peekOfCode": "def dig_it_up(obj, path):\n    try:\n        if type(path) in (str, unicode):\n            path = path.split('.')\n        return reduce(lambda x, y: x[y], path, obj)\n    except:\n        return False\n# The following classes are there to launch the plugin manually\n# with something like ./elasticsearch_collectd.py for development\n# purposes. They basically mock the calls on the \"collectd\" symbol",
        "detail": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "documentation": {}
    },
    {
        "label": "configure_test",
        "kind": 2,
        "importPath": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "description": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "peekOfCode": "def configure_test(cluster):\n    \"\"\"Configure the plugin for testing\"\"\"\n    # Ensure all possible threadpools are eligible for collection\n    cluster.configured_thread_pools = set(['generic', 'index', 'get',\n                                           'snapshot', 'bulk', 'warmer',\n                                           'flush', 'search', 'refresh',\n                                           'suggest', 'percolate',\n                                           'management', 'listener',\n                                           'fetch_shard_store',\n                                           'fetch_shard_started',",
        "detail": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "documentation": {}
    },
    {
        "label": "PREFIX",
        "kind": 5,
        "importPath": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "description": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "peekOfCode": "PREFIX = \"elasticsearch\"\nCLUSTERS = []\nDEFAULTS = set([\n    # AUTOMATICALLY GENERATED METRIC NAMES\n    # TO INCLUDE BY DEFAULT\n    \"indices.total.docs.deleted\",\n    \"indices.total.fielddata.memory-size\",\n    \"indices.merges.total\",\n    \"cluster.number-of-nodes\",\n    \"process.open_file_descriptors\",",
        "detail": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "documentation": {}
    },
    {
        "label": "CLUSTERS",
        "kind": 5,
        "importPath": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "description": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "peekOfCode": "CLUSTERS = []\nDEFAULTS = set([\n    # AUTOMATICALLY GENERATED METRIC NAMES\n    # TO INCLUDE BY DEFAULT\n    \"indices.total.docs.deleted\",\n    \"indices.total.fielddata.memory-size\",\n    \"indices.merges.total\",\n    \"cluster.number-of-nodes\",\n    \"process.open_file_descriptors\",\n    \"indices.total.merges.total\",",
        "detail": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "documentation": {}
    },
    {
        "label": "DEFAULTS",
        "kind": 5,
        "importPath": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "description": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "peekOfCode": "DEFAULTS = set([\n    # AUTOMATICALLY GENERATED METRIC NAMES\n    # TO INCLUDE BY DEFAULT\n    \"indices.total.docs.deleted\",\n    \"indices.total.fielddata.memory-size\",\n    \"indices.merges.total\",\n    \"cluster.number-of-nodes\",\n    \"process.open_file_descriptors\",\n    \"indices.total.merges.total\",\n    \"indices.total.store.size\",",
        "detail": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "documentation": {}
    },
    {
        "label": "CLUSTER_STATUS",
        "kind": 5,
        "importPath": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "description": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "peekOfCode": "CLUSTER_STATUS = {'green': 0, 'yellow': 1, 'red': 2}\nStat = collections.namedtuple('Stat', ('type', 'path'))\n# DICT: ElasticSearch 1.0.0\nNODE_STATS = {\n    # STORE\n    'indices.store.throttle-time':\n        Stat(\"counter\", \"nodes.%s.indices.store.throttle_time_in_millis\"),\n    # SEARCH\n    'indices.search.open-contexts':\n        Stat(\"gauge\", \"nodes.%s.indices.search.open_contexts\"),",
        "detail": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "documentation": {}
    },
    {
        "label": "Stat",
        "kind": 5,
        "importPath": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "description": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "peekOfCode": "Stat = collections.namedtuple('Stat', ('type', 'path'))\n# DICT: ElasticSearch 1.0.0\nNODE_STATS = {\n    # STORE\n    'indices.store.throttle-time':\n        Stat(\"counter\", \"nodes.%s.indices.store.throttle_time_in_millis\"),\n    # SEARCH\n    'indices.search.open-contexts':\n        Stat(\"gauge\", \"nodes.%s.indices.search.open_contexts\"),\n    # CACHE",
        "detail": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "documentation": {}
    },
    {
        "label": "NODE_STATS",
        "kind": 5,
        "importPath": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "description": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "peekOfCode": "NODE_STATS = {\n    # STORE\n    'indices.store.throttle-time':\n        Stat(\"counter\", \"nodes.%s.indices.store.throttle_time_in_millis\"),\n    # SEARCH\n    'indices.search.open-contexts':\n        Stat(\"gauge\", \"nodes.%s.indices.search.open_contexts\"),\n    # CACHE\n    'indices.cache.field.eviction':\n        Stat(\"counter\", \"nodes.%s.indices.fielddata.evictions\"),",
        "detail": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "documentation": {}
    },
    {
        "label": "DEPRECATED_NODE_STATS",
        "kind": 5,
        "importPath": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "description": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "peekOfCode": "DEPRECATED_NODE_STATS = [\n    {\n        'major': 2,\n        'minor': 0,\n        'revision': 0,\n        'keys': ['process.mem.share_in_bytes'],\n    },\n    {\n        'major': 5,\n        'minor': 0,",
        "detail": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "documentation": {}
    },
    {
        "label": "DEPRECATED_THREAD_POOLS",
        "kind": 5,
        "importPath": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "description": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "peekOfCode": "DEPRECATED_THREAD_POOLS = [\n    {\n        'major': 2,\n        'minor': 0,\n        'revision': 0,\n        'keys': ['merge', 'optimize']\n    },\n    {\n        'major': 5,\n        'minor': 0,",
        "detail": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "documentation": {}
    },
    {
        "label": "NODE_STATS_ES_2",
        "kind": 5,
        "importPath": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "description": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "peekOfCode": "NODE_STATS_ES_2 = {\n    'indices.cache.filter.evictions':\n        Stat(\"counter\", \"nodes.%s.indices.query_cache.evictions\"),\n    'indices.cache.filter.size':\n        Stat(\"gauge\", \"nodes.%s.indices.query_cache.cache_size\"),\n    'indices.cache.filter.hit-count':\n        Stat(\"counter\", \"nodes.%s.indices.query_cache.hit_count\"),\n    'indices.cache.filter.miss-count':\n        Stat(\"counter\", \"nodes.%s.indices.query_cache.miss_count\"),\n    'indices.cache.filter.cache-count':",
        "detail": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "documentation": {}
    },
    {
        "label": "INDEX_STATS_ES_1_3",
        "kind": 5,
        "importPath": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "description": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "peekOfCode": "INDEX_STATS_ES_1_3 = {\n    # SEGMENTS\n    \"indices[index={index_name}].primaries.segments.index-writer-memory\":\n        Stat(\"gauge\", \"primaries.segments.index_writer_memory_in_bytes\"),\n    \"indices[index={index_name}].primaries.segments.version-map-memory\":\n        Stat(\"gauge\", \"primaries.segments.version_map_memory_in_bytes\"),\n}\n# ElasticSearch 1.1.0\nINDEX_STATS_ES_1_1 = {\n    # SUGGEST",
        "detail": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "documentation": {}
    },
    {
        "label": "INDEX_STATS_ES_1_1",
        "kind": 5,
        "importPath": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "description": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "peekOfCode": "INDEX_STATS_ES_1_1 = {\n    # SUGGEST\n    \"indices[index={index_name}].primaries.suggest.total\":\n        Stat(\"counter\", \"primaries.suggest.total\"),\n    \"indices[index={index_name}].primaries.suggest.time\":\n        Stat(\"counter\", \"primaries.suggest.time_in_millis\"),\n    \"indices[index={index_name}].primaries.suggest.current\":\n        Stat(\"gauge\", \"primaries.suggest.current\"),\n}\n# ElasticSearch 1.0.0",
        "detail": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "documentation": {}
    },
    {
        "label": "INDEX_STATS",
        "kind": 5,
        "importPath": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "description": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "peekOfCode": "INDEX_STATS = {\n    # PRIMARIES\n    # TRANSLOG\n    \"indices[index={index_name}].primaries.translog.size\":\n        Stat(\"gauge\", \"primaries.translog.size_in_bytes\"),\n    \"indices[index={index_name}].primaries.translog.operations\":\n        Stat(\"counter\", \"primaries.translog.operations\"),\n    # SEGMENTS\n    \"indices[index={index_name}].primaries.segments.memory\":\n        Stat(\"gauge\", \"primaries.segments.memory_in_bytes\"),",
        "detail": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "documentation": {}
    },
    {
        "label": "CLUSTER_STATS",
        "kind": 5,
        "importPath": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "description": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "peekOfCode": "CLUSTER_STATS = {\n    'cluster.active-primary-shards': Stat(\"gauge\", \"active_primary_shards\"),\n    'cluster.active-shards': Stat(\"gauge\", \"active_shards\"),\n    'cluster.initializing-shards': Stat(\"gauge\", \"initializing_shards\"),\n    'cluster.number-of-data_nodes': Stat(\"gauge\", \"number_of_data_nodes\"),\n    'cluster.number-of-nodes': Stat(\"gauge\", \"number_of_nodes\"),\n    'cluster.relocating-shards': Stat(\"gauge\", \"relocating_shards\"),\n    'cluster.unassigned-shards': Stat(\"gauge\", \"unassigned_shards\"),\n    'cluster.status': Stat(\"gauge\", \"status\"),\n}",
        "detail": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "documentation": {}
    },
    {
        "label": "THREAD_POOL_METRICS",
        "kind": 5,
        "importPath": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "description": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "peekOfCode": "THREAD_POOL_METRICS = {\n    \"gauge\": ['threads', 'queue', 'active', 'largest'],\n    \"counter\": ['completed', 'rejected'],\n}\n# collectd callbacks\ndef read_callback():\n    \"\"\"called by collectd to gather stats. It is called per collection\n    interval.\n    If this method throws, the plugin will be skipped for an increasing amount\n    of time until it returns normally again\"\"\"",
        "detail": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "documentation": {}
    },
    {
        "label": "log",
        "kind": 5,
        "importPath": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "description": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "peekOfCode": "log = logging.getLogger(__name__)\nlog.setLevel(logging.DEBUG)\nlog.propagate = False\nhandle = CollectdLogHandler(PREFIX)\nlog.addHandler(handle)\ndef configure_test(cluster):\n    \"\"\"Configure the plugin for testing\"\"\"\n    # Ensure all possible threadpools are eligible for collection\n    cluster.configured_thread_pools = set(['generic', 'index', 'get',\n                                           'snapshot', 'bulk', 'warmer',",
        "detail": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "documentation": {}
    },
    {
        "label": "log.propagate",
        "kind": 5,
        "importPath": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "description": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "peekOfCode": "log.propagate = False\nhandle = CollectdLogHandler(PREFIX)\nlog.addHandler(handle)\ndef configure_test(cluster):\n    \"\"\"Configure the plugin for testing\"\"\"\n    # Ensure all possible threadpools are eligible for collection\n    cluster.configured_thread_pools = set(['generic', 'index', 'get',\n                                           'snapshot', 'bulk', 'warmer',\n                                           'flush', 'search', 'refresh',\n                                           'suggest', 'percolate',",
        "detail": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "documentation": {}
    },
    {
        "label": "handle",
        "kind": 5,
        "importPath": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "description": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "peekOfCode": "handle = CollectdLogHandler(PREFIX)\nlog.addHandler(handle)\ndef configure_test(cluster):\n    \"\"\"Configure the plugin for testing\"\"\"\n    # Ensure all possible threadpools are eligible for collection\n    cluster.configured_thread_pools = set(['generic', 'index', 'get',\n                                           'snapshot', 'bulk', 'warmer',\n                                           'flush', 'search', 'refresh',\n                                           'suggest', 'percolate',\n                                           'management', 'listener',",
        "detail": "_REPO.GITHUB.collectd-elasticsearch.elasticsearch_collectd",
        "documentation": {}
    },
    {
        "label": "find_open_prs_for_repo",
        "kind": 2,
        "importPath": "_REPO.GITHUB.docs..github.actions-scripts.fr-add-docs-reviewers-requests",
        "description": "_REPO.GITHUB.docs..github.actions-scripts.fr-add-docs-reviewers-requests",
        "peekOfCode": "def find_open_prs_for_repo(repo_id: str, num_prs: int):\n    \"\"\"Return data about a specified number of open PRs for a specified repo\n  Arguments:\n  repo_id: The node ID of the repo to search\n  num_prs: The max number of PRs to return\n  Returns:\n  Returns a JSON object of this structure:\n  {\n    \"data\": {\n    \"node\": {",
        "detail": "_REPO.GITHUB.docs..github.actions-scripts.fr-add-docs-reviewers-requests",
        "documentation": {}
    },
    {
        "label": "add_prs_to_board",
        "kind": 2,
        "importPath": "_REPO.GITHUB.docs..github.actions-scripts.fr-add-docs-reviewers-requests",
        "description": "_REPO.GITHUB.docs..github.actions-scripts.fr-add-docs-reviewers-requests",
        "peekOfCode": "def add_prs_to_board(prs_to_add: list, column_id: str):\n    \"\"\"Adds PRs to a column of a project board\n  Arguments:\n  prs_to_add: A list of PR node IDs\n  column_id: The node ID of the column to add the PRs to\n  Returns:\n  Nothing\n  \"\"\"\n    logger.info(f\"adding: {prs_to_add}\")\n    mutation = \"\"\"mutation($pr_id: ID!, $column_id: ID!) {",
        "detail": "_REPO.GITHUB.docs..github.actions-scripts.fr-add-docs-reviewers-requests",
        "documentation": {}
    },
    {
        "label": "filter_prs",
        "kind": 2,
        "importPath": "_REPO.GITHUB.docs..github.actions-scripts.fr-add-docs-reviewers-requests",
        "description": "_REPO.GITHUB.docs..github.actions-scripts.fr-add-docs-reviewers-requests",
        "peekOfCode": "def filter_prs(data, reviewer_id: str, project_id):\n    \"\"\"Given data about the draft state, reviewers, and project boards for PRs,\n  return just the PRs that are:\n  - not draft\n  - are requesting a review for the specified team\n  - are not already on the specified project board\n  Arguments:\n  data: A JSON object of this structure:\n    {\n      \"data\": {",
        "detail": "_REPO.GITHUB.docs..github.actions-scripts.fr-add-docs-reviewers-requests",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "_REPO.GITHUB.docs..github.actions-scripts.fr-add-docs-reviewers-requests",
        "description": "_REPO.GITHUB.docs..github.actions-scripts.fr-add-docs-reviewers-requests",
        "peekOfCode": "def main():\n    query_data = find_open_prs_for_repo(github_repo_id, num_prs_to_search)\n    prs_to_add = filter_prs(query_data, docs_reviewers_id, docs_project_id)\n    add_prs_to_board(prs_to_add, docs_column_id)\nif __name__ == \"__main__\":\n    main()",
        "detail": "_REPO.GITHUB.docs..github.actions-scripts.fr-add-docs-reviewers-requests",
        "documentation": {}
    },
    {
        "label": "endpoint",
        "kind": 5,
        "importPath": "_REPO.GITHUB.docs..github.actions-scripts.fr-add-docs-reviewers-requests",
        "description": "_REPO.GITHUB.docs..github.actions-scripts.fr-add-docs-reviewers-requests",
        "peekOfCode": "endpoint = \"https://api.github.com/graphql\"\n# ID of the github/github repo\ngithub_repo_id = \"MDEwOlJlcG9zaXRvcnkz\"\n# ID of the docs-reviewers team\ndocs_reviewers_id = \"MDQ6VGVhbTQzMDMxMzk=\"\n# ID of the \"Docs content first responder\" board\ndocs_project_id = \"MDc6UHJvamVjdDQ1NzI0ODI=\"\n# ID of the \"OpenAPI review requests\" column on the  \"Docs content first responder\" board\ndocs_column_id = \"PC_lAPNJr_OAEXFQs4A2OFq\"\n# 100 is an educated guess of how many PRs are opened in a day on the github/github repo",
        "detail": "_REPO.GITHUB.docs..github.actions-scripts.fr-add-docs-reviewers-requests",
        "documentation": {}
    },
    {
        "label": "github_repo_id",
        "kind": 5,
        "importPath": "_REPO.GITHUB.docs..github.actions-scripts.fr-add-docs-reviewers-requests",
        "description": "_REPO.GITHUB.docs..github.actions-scripts.fr-add-docs-reviewers-requests",
        "peekOfCode": "github_repo_id = \"MDEwOlJlcG9zaXRvcnkz\"\n# ID of the docs-reviewers team\ndocs_reviewers_id = \"MDQ6VGVhbTQzMDMxMzk=\"\n# ID of the \"Docs content first responder\" board\ndocs_project_id = \"MDc6UHJvamVjdDQ1NzI0ODI=\"\n# ID of the \"OpenAPI review requests\" column on the  \"Docs content first responder\" board\ndocs_column_id = \"PC_lAPNJr_OAEXFQs4A2OFq\"\n# 100 is an educated guess of how many PRs are opened in a day on the github/github repo\n# If we are missing PRs, either increase this number or increase the frequency at which this script is run\nnum_prs_to_search = 100",
        "detail": "_REPO.GITHUB.docs..github.actions-scripts.fr-add-docs-reviewers-requests",
        "documentation": {}
    },
    {
        "label": "docs_reviewers_id",
        "kind": 5,
        "importPath": "_REPO.GITHUB.docs..github.actions-scripts.fr-add-docs-reviewers-requests",
        "description": "_REPO.GITHUB.docs..github.actions-scripts.fr-add-docs-reviewers-requests",
        "peekOfCode": "docs_reviewers_id = \"MDQ6VGVhbTQzMDMxMzk=\"\n# ID of the \"Docs content first responder\" board\ndocs_project_id = \"MDc6UHJvamVjdDQ1NzI0ODI=\"\n# ID of the \"OpenAPI review requests\" column on the  \"Docs content first responder\" board\ndocs_column_id = \"PC_lAPNJr_OAEXFQs4A2OFq\"\n# 100 is an educated guess of how many PRs are opened in a day on the github/github repo\n# If we are missing PRs, either increase this number or increase the frequency at which this script is run\nnum_prs_to_search = 100\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)",
        "detail": "_REPO.GITHUB.docs..github.actions-scripts.fr-add-docs-reviewers-requests",
        "documentation": {}
    },
    {
        "label": "docs_project_id",
        "kind": 5,
        "importPath": "_REPO.GITHUB.docs..github.actions-scripts.fr-add-docs-reviewers-requests",
        "description": "_REPO.GITHUB.docs..github.actions-scripts.fr-add-docs-reviewers-requests",
        "peekOfCode": "docs_project_id = \"MDc6UHJvamVjdDQ1NzI0ODI=\"\n# ID of the \"OpenAPI review requests\" column on the  \"Docs content first responder\" board\ndocs_column_id = \"PC_lAPNJr_OAEXFQs4A2OFq\"\n# 100 is an educated guess of how many PRs are opened in a day on the github/github repo\n# If we are missing PRs, either increase this number or increase the frequency at which this script is run\nnum_prs_to_search = 100\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\ndef find_open_prs_for_repo(repo_id: str, num_prs: int):\n    \"\"\"Return data about a specified number of open PRs for a specified repo",
        "detail": "_REPO.GITHUB.docs..github.actions-scripts.fr-add-docs-reviewers-requests",
        "documentation": {}
    },
    {
        "label": "docs_column_id",
        "kind": 5,
        "importPath": "_REPO.GITHUB.docs..github.actions-scripts.fr-add-docs-reviewers-requests",
        "description": "_REPO.GITHUB.docs..github.actions-scripts.fr-add-docs-reviewers-requests",
        "peekOfCode": "docs_column_id = \"PC_lAPNJr_OAEXFQs4A2OFq\"\n# 100 is an educated guess of how many PRs are opened in a day on the github/github repo\n# If we are missing PRs, either increase this number or increase the frequency at which this script is run\nnum_prs_to_search = 100\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\ndef find_open_prs_for_repo(repo_id: str, num_prs: int):\n    \"\"\"Return data about a specified number of open PRs for a specified repo\n  Arguments:\n  repo_id: The node ID of the repo to search",
        "detail": "_REPO.GITHUB.docs..github.actions-scripts.fr-add-docs-reviewers-requests",
        "documentation": {}
    },
    {
        "label": "num_prs_to_search",
        "kind": 5,
        "importPath": "_REPO.GITHUB.docs..github.actions-scripts.fr-add-docs-reviewers-requests",
        "description": "_REPO.GITHUB.docs..github.actions-scripts.fr-add-docs-reviewers-requests",
        "peekOfCode": "num_prs_to_search = 100\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\ndef find_open_prs_for_repo(repo_id: str, num_prs: int):\n    \"\"\"Return data about a specified number of open PRs for a specified repo\n  Arguments:\n  repo_id: The node ID of the repo to search\n  num_prs: The max number of PRs to return\n  Returns:\n  Returns a JSON object of this structure:",
        "detail": "_REPO.GITHUB.docs..github.actions-scripts.fr-add-docs-reviewers-requests",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "_REPO.GITHUB.docs..github.actions-scripts.fr-add-docs-reviewers-requests",
        "description": "_REPO.GITHUB.docs..github.actions-scripts.fr-add-docs-reviewers-requests",
        "peekOfCode": "logger = logging.getLogger(__name__)\ndef find_open_prs_for_repo(repo_id: str, num_prs: int):\n    \"\"\"Return data about a specified number of open PRs for a specified repo\n  Arguments:\n  repo_id: The node ID of the repo to search\n  num_prs: The max number of PRs to return\n  Returns:\n  Returns a JSON object of this structure:\n  {\n    \"data\": {",
        "detail": "_REPO.GITHUB.docs..github.actions-scripts.fr-add-docs-reviewers-requests",
        "documentation": {}
    }
]